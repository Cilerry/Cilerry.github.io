<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Kafka基础（一） | RedLeavesBlog</title><meta name="keywords" content="kafka"><meta name="author" content="Snow Monster"><meta name="copyright" content="Snow Monster"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="Kafka概述定义Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 消息队列1.2.1传统消息队列的应用场景  使用消息队列的好处 1）解耦 允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。 2）可恢复性 系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka基础（一）">
<meta property="og:url" content="http://www.red0819.top/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/index.html">
<meta property="og:site_name" content="RedLeavesBlog">
<meta property="og:description" content="Kafka概述定义Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 消息队列1.2.1传统消息队列的应用场景  使用消息队列的好处 1）解耦 允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。 2）可恢复性 系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.red0819.top/wordPic/timg.jpg">
<meta property="article:published_time" content="2018-08-18T02:59:54.000Z">
<meta property="article:modified_time" content="2020-09-23T08:41:22.534Z">
<meta property="article:author" content="Snow Monster">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.red0819.top/wordPic/timg.jpg"><link rel="shortcut icon" href="/img/logo.png"><link rel="canonical" href="http://www.red0819.top/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="yandex-verification" content="{&quot;theme_color&quot;:{&quot;enable&quot;:true,&quot;main&quot;:&quot;\t#191970&quot;,&quot;paginator&quot;:&quot;#00c4b6&quot;,&quot;button_hover&quot;:&quot;#FF7242&quot;,&quot;text_selection&quot;:&quot;#00c4b6&quot;,&quot;link_color&quot;:&quot;#99a9bf&quot;,&quot;meta_color&quot;:&quot;#858585&quot;,&quot;hr_color&quot;:&quot;#A4D8FA&quot;,&quot;code_foreground&quot;:&quot;#F47466&quot;,&quot;code_background&quot;:&quot;rgba(27, 31, 35, .05)&quot;,&quot;toc_color&quot;:&quot;#00c4b6&quot;,&quot;blockquote_padding_color&quot;:&quot;#49b1f5&quot;,&quot;blockquote_background_color&quot;:&quot;#49b1f5&quot;}}"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '4.2.1',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-09-23 16:41:22'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
  }
}

var autoChangeMode = 'false'
var t = saveToLocal.get('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (saveToLocal.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="RedLeavesBlog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/AF67D2ECB3B0F647193CD90F94294167.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">28</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">21</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka概述"><span class="toc-number">1.</span> <span class="toc-text">Kafka概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#定义"><span class="toc-number">1.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#消息队列"><span class="toc-number">1.2.</span> <span class="toc-text">消息队列</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka基础架构"><span class="toc-number">1.3.</span> <span class="toc-text">Kafka基础架构</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka快速入门"><span class="toc-number">2.</span> <span class="toc-text">Kafka快速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#安装部署"><span class="toc-number">2.1.</span> <span class="toc-text">安装部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka命令行操作"><span class="toc-number">2.2.</span> <span class="toc-text">Kafka命令行操作</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka架构深入"><span class="toc-number">3.</span> <span class="toc-text">Kafka架构深入</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka工作流程及文件存储机制"><span class="toc-number">3.1.</span> <span class="toc-text">Kafka工作流程及文件存储机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka生产者"><span class="toc-number">3.2.</span> <span class="toc-text">Kafka生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#分区策略"><span class="toc-number">3.2.1.</span> <span class="toc-text">分区策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据可靠性保证"><span class="toc-number">3.2.2.</span> <span class="toc-text">数据可靠性保证</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka消费者"><span class="toc-number">3.3.</span> <span class="toc-text">Kafka消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消费方式"><span class="toc-number">3.3.1.</span> <span class="toc-text">消费方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分区分配策略"><span class="toc-number">3.3.2.</span> <span class="toc-text">分区分配策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#offset的维护"><span class="toc-number">3.3.3.</span> <span class="toc-text">offset的维护</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#消费者组案例"><span class="toc-number">3.3.4.</span> <span class="toc-text">消费者组案例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-高效读写数据"><span class="toc-number">3.4.</span> <span class="toc-text">Kafka 高效读写数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Zookeeper在Kafka中的作用"><span class="toc-number">3.5.</span> <span class="toc-text">Zookeeper在Kafka中的作用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka-API"><span class="toc-number">4.</span> <span class="toc-text">Kafka API</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer-API"><span class="toc-number">4.1.</span> <span class="toc-text">Producer API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消息发送流程"><span class="toc-number">4.1.1.</span> <span class="toc-text">消息发送流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#异步发送API"><span class="toc-number">4.1.2.</span> <span class="toc-text">异步发送API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#同步发送API"><span class="toc-number">4.1.3.</span> <span class="toc-text">同步发送API</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer-API"><span class="toc-number">4.2.</span> <span class="toc-text">Consumer API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#自动提交offset"><span class="toc-number">4.2.1.</span> <span class="toc-text">自动提交offset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#手动提交offset"><span class="toc-number">4.2.2.</span> <span class="toc-text">手动提交offset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#自定义存储offset"><span class="toc-number">4.2.3.</span> <span class="toc-text">自定义存储offset</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义Interceptor"><span class="toc-number">4.3.</span> <span class="toc-text">自定义Interceptor</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#拦截器原理"><span class="toc-number">4.3.1.</span> <span class="toc-text">拦截器原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#拦截器案例"><span class="toc-number">4.3.2.</span> <span class="toc-text">拦截器案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka监控"><span class="toc-number">5.</span> <span class="toc-text">Kafka监控</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaManager"><span class="toc-number">5.1.</span> <span class="toc-text">KafkaManager</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaMonitor"><span class="toc-number">5.2.</span> <span class="toc-text">KafkaMonitor</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Eagle"><span class="toc-number">5.3.</span> <span class="toc-text">Kafka Eagle</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(/wordPic/timg.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">RedLeavesBlog</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Kafka基础（一）</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2018-08-18T02:59:54.000Z" title="undefined 2018-08-18 10:59:54">2018-08-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/bigdata/">大数据</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>35分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="Kafka概述"><a href="#Kafka概述" class="headerlink" title="Kafka概述"></a>Kafka概述</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。</p>
<h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><p>1.2.1传统消息队列的应用场景</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps78.png" alt="img"></p>
<p>使用消息队列的好处</p>
<p>1）解耦</p>
<p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
<p>2）可恢复性</p>
<p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p>
<p>3）缓冲</p>
<p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p>
<p>4）灵活性 &amp; 峰值处理能力</p>
<p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p>
<p>5）异步通信</p>
<p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p>
<p>1.2.2消息队列的两种模式</p>
<p>（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</p>
<p>消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。</p>
<p>消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/image-20200923160439670.png" alt="image-20200923160439670"></p>
<p>（2）发布/订阅模式（一对多，消费者消费数据之后不会清除消息）</p>
<p>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/image-20200923160453224.png" alt="image-20200923160453224"></p>
<h2 id="Kafka基础架构"><a href="#Kafka基础架构" class="headerlink" title="Kafka基础架构"></a>Kafka基础架构</h2><p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps91.png" alt="img"></p>
<p>1）Producer ：消息生产者，就是向kafka broker发消息的客户端；</p>
<p>2）Consumer ：消息消费者，向kafka broker取消息的客户端；</p>
<p>3）Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>4）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</p>
<p>5）Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic；</p>
<p>6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列；</p>
<p>7）Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</p>
<p>8）leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</p>
<p>9）follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader。</p>
<h1 id="Kafka快速入门"><a href="#Kafka快速入门" class="headerlink" title="Kafka快速入门"></a>Kafka快速入门</h1><h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><p>jar包下载</p>
<p><a href="http://kafka.apache.org/downloads.html" target="_blank" rel="noopener">http://kafka.apache.org/downloads.html</a></p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/image-20200923160526719.png" alt="image-20200923160526719"></p>
<p>2.1.3集群部署</p>
<p>1）解压安装包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 software]$ tar -zxvf kafka_2.11-0.11.0.0.tgz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure>

<p>2）修改解压后的文件名称</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 module]$ mv kafka_2.11-0.11.0.0&#x2F; kafka</span><br></pre></td></tr></table></figure>

<p>3）在/opt/module/kafka目录下创建logs文件夹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ mkdir logs</span><br></pre></td></tr></table></figure>

<p>4）修改配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ cd config&#x2F;</span><br><span class="line">[red@hadoop102 config]$ vi server.properties</span><br></pre></td></tr></table></figure>

<p>输入以下内容：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#broker的全局唯一编号，不能重复</span></span><br><span class="line"></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#删除topic功能使能</span></span><br><span class="line"></span><br><span class="line"><span class="meta">delete.topic.enable</span>=<span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#处理网络请求的线程数量</span></span><br><span class="line"></span><br><span class="line"><span class="meta">num.network.threads</span>=<span class="string">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#用来处理磁盘IO的线程数量</span></span><br><span class="line"></span><br><span class="line"><span class="meta">num.io.threads</span>=<span class="string">8</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#发送套接字的缓冲区大小</span></span><br><span class="line"></span><br><span class="line"><span class="meta">socket.send.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#接收套接字的缓冲区大小</span></span><br><span class="line"></span><br><span class="line"><span class="meta">socket.receive.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#请求套接字的缓冲区大小</span></span><br><span class="line"></span><br><span class="line"><span class="meta">socket.request.max.bytes</span>=<span class="string">104857600</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#kafka运行日志存放的路径</span></span><br><span class="line"></span><br><span class="line"><span class="meta">log.dirs</span>=<span class="string">/opt/module/kafka/logs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#topic在当前broker上的分区个数</span></span><br><span class="line"></span><br><span class="line"><span class="meta">num.partitions</span>=<span class="string">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#用来恢复和清理data下数据的线程数量</span></span><br><span class="line"></span><br><span class="line"><span class="meta">num.recovery.threads.per.data.dir</span>=<span class="string">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#segment文件保留的最长时间，超时将被删除</span></span><br><span class="line"></span><br><span class="line"><span class="meta">log.retention.hours</span>=<span class="string">168</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置连接Zookeeper集群地址</span></span><br><span class="line"></span><br><span class="line"><span class="meta">zookeeper.connect</span>=<span class="string">hadoop102:2181,hadoop103:2181,hadoop104:2181</span></span><br></pre></td></tr></table></figure>

<p>5）配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 module]$ sudo vi &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">KAFKA_HOME</span></span><br><span class="line"></span><br><span class="line">export KAFKA_HOME=/opt/module/kafka</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 module]$ source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>

<p>6）分发安装包</p>
<p>​    注意：分发之后记得配置其他机器的环境变量</p>
<p>7）分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2</p>
<p>​    注：broker.id不得重复</p>
<p>8）启动集群</p>
<p>依次在hadoop102、hadoop103、hadoop104节点上启动kafka</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-server-start.sh -daemon config&#x2F;server.properties</span><br><span class="line"></span><br><span class="line">[red@hadoop103 kafka]$ bin&#x2F;kafka-server-start.sh -daemon config&#x2F;server.properties</span><br><span class="line"></span><br><span class="line">[red@hadoop104 kafka]$ bin&#x2F;kafka-server-start.sh -daemon config&#x2F;server.properties</span><br></pre></td></tr></table></figure>

<p>9）关闭集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-server-stop.sh stop</span><br><span class="line"></span><br><span class="line">[red@hadoop103 kafka]$ bin&#x2F;kafka-server-stop.sh stop</span><br><span class="line"></span><br><span class="line">[red@hadoop104 kafka]$ bin&#x2F;kafka-server-stop.sh stop</span><br></pre></td></tr></table></figure>

<h2 id="Kafka命令行操作"><a href="#Kafka命令行操作" class="headerlink" title="Kafka命令行操作"></a>Kafka命令行操作</h2><p>1）查看当前服务器中的所有topic</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --list</span><br></pre></td></tr></table></figure>

<p>2）创建topic</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 3 --partitions 1 --topic first</span><br></pre></td></tr></table></figure>

<p>选项说明：</p>
<blockquote>
<p>–topic 定义topic名</p>
<p>–replication-factor  定义副本数</p>
<p>–partitions  定义分区数</p>
</blockquote>
<p>3）删除topic</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first</span><br></pre></td></tr></table></figure>

<p>需要server.properties中设置delete.topic.enable=true否则只是标记删除。</p>
<p>4）发送消息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-console-producer.sh --broker-list hadoop102:9092 --topic first</span><br><span class="line"></span><br><span class="line">&gt;hello world</span><br><span class="line"></span><br><span class="line">&gt;red  red</span><br></pre></td></tr></table></figure>

<p>5）消费消息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line"></span><br><span class="line">--zookeeper hadoop102:2181 --topic first</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line"></span><br><span class="line">--bootstrap-server hadoop102:9092 --topic first</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line"></span><br><span class="line">--bootstrap-server hadoop102:9092 --from-beginning --topic first</span><br></pre></td></tr></table></figure>

<blockquote>
<p>–from-beginning：会把主题中以往所有的数据都读取出来。</p>
</blockquote>
<p>6）查看某个Topic的详情</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --describe --topic first</span><br></pre></td></tr></table></figure>

<p>7）修改分区数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --alter --topic first --partitions 6</span><br></pre></td></tr></table></figure>



<h1 id="Kafka架构深入"><a href="#Kafka架构深入" class="headerlink" title="Kafka架构深入"></a>Kafka架构深入</h1><h2 id="Kafka工作流程及文件存储机制"><a href="#Kafka工作流程及文件存储机制" class="headerlink" title="Kafka工作流程及文件存储机制"></a>Kafka工作流程及文件存储机制</h2><p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps92.png" alt="img"></p>
<p>Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</p>
<p>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps118.png" alt="img"></p>
<p>由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment。每个segment对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。</p>
<blockquote>
<p>00000000000000000000.index</p>
<p>00000000000000000000.log</p>
<p>00000000000000170410.index</p>
<p>00000000000000170410.log</p>
<p>00000000000000239430.index</p>
<p>00000000000000239430.log</p>
</blockquote>
<p>index和log文件以当前segment的第一条消息的offset命名。下图为index文件和log文件的结构示意图。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps133.png" alt="img"></p>
<p>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。</p>
<h2 id="Kafka生产者"><a href="#Kafka生产者" class="headerlink" title="Kafka生产者"></a>Kafka生产者</h2><h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><p>1）分区的原因</p>
<p>（1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</p>
<p>（2）可以提高并发，因为可以以Partition为单位读写了。</p>
<p>2）分区的原则</p>
<p>我们需要将producer发送的数据封装成一个ProducerRecord对象。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/image-20200923161400221.png" alt="image-20200923161400221"></p>
<p>（1）指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</p>
<p>（2）没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</p>
<p>（3）既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</p>
<h3 id="数据可靠性保证"><a href="#数据可靠性保证" class="headerlink" title="数据可靠性保证"></a>数据可靠性保证</h3><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps134.png" alt="img"></p>
<p>1）副本数据同步策略</p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>半数以上完成同步，就发送ack</td>
<td>延迟低</td>
<td>选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td>
</tr>
<tr>
<td>全部完成同步，才发送ack</td>
<td>选举新的leader时，容忍n台节点的故障，需要n+1个副本</td>
<td>延迟高</td>
</tr>
</tbody></table>
<p>Kafka选择了第二种方案，原因如下：</p>
<p>1.同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</p>
<p>2.虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</p>
<p>2）ISR</p>
<p>​    采用第二种方案之后，设想以下情景：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？</p>
<p>​    Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给producer发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</p>
<p>3）ack应答机制</p>
<p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。</p>
<p>所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p>
<p>acks参数配置：</p>
<p>acks：</p>
<p>0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；</p>
<p>1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据；</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps135.png" alt="img"></p>
<p>-1（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps136.png" alt="img"></p>
<p>4）故障处理细节</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps137.png" alt="img"></p>
<p>LEO：指的是每个副本最大的offset；</p>
<p>HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。</p>
<p>（1）follower故障</p>
<p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</p>
<p>（2）leader故障</p>
<p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</p>
<p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>
<h2 id="Kafka消费者"><a href="#Kafka消费者" class="headerlink" title="Kafka消费者"></a>Kafka消费者</h2><h3 id="消费方式"><a href="#消费方式" class="headerlink" title="消费方式"></a>消费方式</h3><p>consumer采用pull（拉）模式从broker中读取数据。</p>
<p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p>
<p>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</p>
<h3 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h3><p>一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费。</p>
<p>Kafka有两种分配策略，一是RoundRobin，一是Range。</p>
<p>1）RoundRobin</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps138.png" alt="img"></p>
<p>2）Range</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps139.png" alt="img"></p>
<h3 id="offset的维护"><a href="#offset的维护" class="headerlink" title="offset的维护"></a>offset的维护</h3><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p>
<p> <img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/image-20200923161454891.png" alt="image-20200923161454891"></p>
<p>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p>
<p>1）修改配置文件consumer.properties</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">exclude.internal.topics</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure>

<p>2）读取offset</p>
<p>0.11.0.0之前版本:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config&#x2F;consumer.properties --from-beginning</span><br></pre></td></tr></table></figure>

<p>0.11.0.0之后版本(含):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config&#x2F;consumer.properties --from-beginning</span><br></pre></td></tr></table></figure>



<h3 id="消费者组案例"><a href="#消费者组案例" class="headerlink" title="消费者组案例"></a>消费者组案例</h3><p>1）需求：测试同一个消费者组中的消费者，同一时刻只能有一个消费者消费。</p>
<p>2）案例实操</p>
<p>​    （1）在hadoop102、hadoop103上修改/opt/module/kafka/config/consumer.properties配置文件中的group.id属性为任意组名。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop103 config]$ vi consumer.properties</span><br><span class="line"></span><br><span class="line">group.id&#x3D;red</span><br></pre></td></tr></table></figure>

<p>​    （2）在hadoop102、hadoop103上分别启动消费者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line"></span><br><span class="line">--zookeeper hadoop102:2181 --topic first --consumer.config config&#x2F;consumer.properties</span><br><span class="line"></span><br><span class="line">[red@hadoop103 kafka]$ bin&#x2F;kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --consumer.config config&#x2F;consumer.properties</span><br></pre></td></tr></table></figure>

<p>​    （3）在hadoop104上启动生产者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop104 kafka]$ bin&#x2F;kafka-console-producer.sh \</span><br><span class="line"></span><br><span class="line">--broker-list hadoop102:9092 --topic first</span><br><span class="line"></span><br><span class="line">&gt;hello world</span><br></pre></td></tr></table></figure>

<p>​    （4）查看hadoop102和hadoop103的接收者。</p>
<p>​     同一时刻只有一个消费者接收到消息。</p>
<h2 id="Kafka-高效读写数据"><a href="#Kafka-高效读写数据" class="headerlink" title="Kafka 高效读写数据"></a>Kafka 高效读写数据</h2><p>1）顺序写磁盘</p>
<p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<p>2）零复制技术</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps140.png" alt="img"></p>
<h2 id="Zookeeper在Kafka中的作用"><a href="#Zookeeper在Kafka中的作用" class="headerlink" title="Zookeeper在Kafka中的作用"></a>Zookeeper在Kafka中的作用</h2><p>Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</p>
<p>Controller的管理工作都是依赖于Zookeeper的。</p>
<p>​    以下为partition的leader选举过程：</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps152.png" alt="img"></p>
<h1 id="Kafka-API"><a href="#Kafka-API" class="headerlink" title="Kafka API"></a>Kafka API</h1><h2 id="Producer-API"><a href="#Producer-API" class="headerlink" title="Producer API"></a>Producer API</h2><h3 id="消息发送流程"><a href="#消息发送流程" class="headerlink" title="消息发送流程"></a>消息发送流程</h3><p>Kafka的Producer发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker。</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps179.png" alt="img"></p>
<p>相关参数：</p>
<p>batch.size：只有数据积累到batch.size之后，sender才会发送数据。</p>
<p>linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。</p>
<h3 id="异步发送API"><a href="#异步发送API" class="headerlink" title="异步发送API"></a>异步发送API</h3><p>1）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>0.11.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>2）编写代码</p>
<p>需要用到的类：</p>
<blockquote>
<p>KafkaProducer：需要创建一个生产者对象，用来发送数据</p>
<p>ProducerConfig：获取所需的一系列配置参数</p>
<p>ProducerRecord：每条数据都要封装成一个ProducerRecord对象</p>
</blockquote>
<p>1.不带回调函数的API</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment">//kafka集群，broker-list</span></span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment">//重试次数</span></span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"retries"</span>, <span class="number">1</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment">//批次大小</span></span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment">//等待时间</span></span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment">//RecordAccumulator缓冲区大小</span></span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">      producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first"</span>, Integer.toString(i), Integer.toString(i)));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    producer.close();</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2.带回调函数的API</p>
<p>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是RecordMetadata和Exception，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p>
<p>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);<span class="comment">//kafka集群，broker-list</span></span><br><span class="line"></span><br><span class="line">   props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line"></span><br><span class="line">   props.put(<span class="string">"retries"</span>, <span class="number">1</span>);<span class="comment">//重试次数</span></span><br><span class="line"></span><br><span class="line">   props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>);<span class="comment">//批次大小</span></span><br><span class="line"></span><br><span class="line">   props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);<span class="comment">//等待时间</span></span><br><span class="line"></span><br><span class="line">   props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);<span class="comment">//RecordAccumulator缓冲区大小</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">   props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">   Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">      producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first"</span>, Integer.toString(i), Integer.toString(i)), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//回调函数，该方法会在Producer收到ack时调用，为异步调用</span></span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">         <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">           System.out.println(<span class="string">"success-&gt;"</span> + metadata.offset());</span><br><span class="line">         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           exception.printStackTrace();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">   &#125;</span><br><span class="line">    producer.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="同步发送API"><a href="#同步发送API" class="headerlink" title="同步发送API"></a>同步发送API</h3><p>​    同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。</p>
<p>由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方发即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);<span class="comment">//kafka集群，broker-list</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"retries"</span>, <span class="number">1</span>);<span class="comment">//重试次数</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>);<span class="comment">//批次大小</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);<span class="comment">//等待时间</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);<span class="comment">//RecordAccumulator缓冲区大小</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">​      producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first"</span>, Integer.toString(i), Integer.toString(i))).get();</span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    producer.close();</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Consumer-API"><a href="#Consumer-API" class="headerlink" title="Consumer API"></a>Consumer API</h2><p>Consumer消费数据时的可靠性是很容易保证的，因为数据在Kafka中是持久化的，故不用担心数据丢失问题。</p>
<p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p>
<p>所以offset的维护是Consumer消费数据是必须考虑的问题。</p>
<h3 id="自动提交offset"><a href="#自动提交offset" class="headerlink" title="自动提交offset"></a>自动提交offset</h3><p>1）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>0.11.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>2）编写代码</p>
<p>需要用到的类：</p>
<blockquote>
<p>KafkaConsumer：需要创建一个消费者对象，用来消费数据</p>
<p>ConsumerConfig：获取所需的一系列配置参数</p>
<p>ConsuemrRecord：每条数据都要封装成一个ConsumerRecord对象</p>
</blockquote>
<p><strong><font color="red">为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。</font></strong> </p>
<p>自动提交offset的相关参数：</p>
<blockquote>
<p>enable.auto.commit：是否开启自动提交offset功能</p>
<p>auto.commit.interval.ms：自动提交offset的时间间隔</p>
</blockquote>
<p>以下为自动提交offset的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">​    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">​    consumer.subscribe(Arrays.asList(<span class="string">"first"</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">​      ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">​      <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</span><br><span class="line"></span><br><span class="line">​        System.out.printf(<span class="string">"offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.value());</span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="手动提交offset"><a href="#手动提交offset" class="headerlink" title="手动提交offset"></a>手动提交offset</h3><p>虽然自动提交offset十分简介便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。</p>
<p>手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。两者的相同点是，都会将本次poll的一批数据最高的偏移量提交；不同点是，commitSync阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。</p>
<p>1）同步提交offset</p>
<p>由于同步提交offset有失败重试机制，故更加可靠，以下为同步提交offset的示例。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka.consumer;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomComsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">//Kafka集群</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">//消费者组，只要group.id相同，就属于同一个消费者组</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>);<span class="comment">//关闭自动提交offset</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    consumer.subscribe(Arrays.asList(<span class="string">"first"</span>));<span class="comment">//消费者订阅主题</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">//消费者拉取数据</span></span><br><span class="line"></span><br><span class="line">​      ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​      <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​        System.out.printf(<span class="string">"offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.value());</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​      &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">//同步提交，当前线程会阻塞直到offset提交成功</span></span><br><span class="line"></span><br><span class="line">​      consumer.commitSync();</span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2）异步提交offset</p>
<p>虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会收到很大的影响。因此更多的情况下，会选用异步提交offset的方式。</p>
<p>以下为异步提交offset的示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka.consumer;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="comment">//Kafka集群</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="comment">//消费者组，只要group.id相同，就属于同一个消费者组</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>); </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="comment">//关闭自动提交offset</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">​    consumer.subscribe(Arrays.asList(<span class="string">"first"</span>));<span class="comment">//消费者订阅主题</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">​      ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);<span class="comment">//消费者拉取数据</span></span><br><span class="line"></span><br><span class="line">​      <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line"></span><br><span class="line">​        System.out.printf(<span class="string">"offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.value());</span><br><span class="line"></span><br><span class="line">​      &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">//异步提交</span></span><br><span class="line"></span><br><span class="line">​      consumer.commitAsync(<span class="keyword">new</span> OffsetCommitCallback() &#123;</span><br><span class="line"></span><br><span class="line">​        <span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​          <span class="keyword">if</span> (exception != <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">​            System.err.println(<span class="string">"Commit failed for"</span> + offsets);</span><br><span class="line"></span><br><span class="line">​          &#125;</span><br><span class="line"></span><br><span class="line">​        &#125;</span><br><span class="line"></span><br><span class="line">​      &#125;); </span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>3）</strong> 数据漏消费和重复消费分析</p>
<p>无论是同步提交还是异步提交offset，都有可能会造成数据的漏消费或者重复消费。先提交offset后消费，有可能造成数据的漏消费；而先消费后提交offset，有可能会造成数据的重复消费。</p>
<h3 id="自定义存储offset"><a href="#自定义存储offset" class="headerlink" title="自定义存储offset"></a>自定义存储offset</h3><p>Kafka 0.9版本之前，offset存储在zookeeper，0.9版本及之后，默认将offset存储在Kafka的一个内置的topic中。除此之外，Kafka还可以选择自定义存储offset。</p>
<p>offset的维护是相当繁琐的，因为需要考虑到消费者的Rebalace。</p>
<p>当有新的消费者加入消费者组、已有的消费者推出消费者组或者所订阅的主题的分区发生变化，就会触发到分区的重新分配，重新分配的过程叫做Rebalance。</p>
<p>消费者发生Rebalance之后，每个消费者消费的分区就会发生变化。因此消费者要首先获取到自己被重新分配到的分区，并且定位到每个分区最近提交的offset位置继续消费。</p>
<p>要实现自定义存储offset，需要借助ConsumerRebalanceListener，以下为示例代码，其中提交和获取offset的方法，需要根据所选的offset存储系统自行实现。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka.consumer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line"> <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;TopicPartition, Long&gt; currentOffset = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//创建配置信息</span></span><br><span class="line"></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line"><span class="comment">//Kafka集群</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>); </span><br><span class="line"></span><br><span class="line"><span class="comment">//消费者组，只要group.id相同，就属于同一个消费者组</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>); </span><br><span class="line"></span><br><span class="line"><span class="comment">//关闭自动提交offset</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>);</span><br><span class="line"></span><br><span class="line">​    <span class="comment">//Key和Value的反序列化类</span></span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">​    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">​    <span class="comment">//创建一个消费者</span></span><br><span class="line"></span><br><span class="line">​    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">​    <span class="comment">//消费者订阅主题</span></span><br><span class="line"></span><br><span class="line">​    consumer.subscribe(Arrays.asList(<span class="string">"first"</span>), <span class="keyword">new</span> ConsumerRebalanceListener() &#123;</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​      <span class="comment">//该方法会在Rebalance之前调用</span></span><br><span class="line"></span><br><span class="line">​      <span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​        commitOffset(currentOffset);</span><br><span class="line"></span><br><span class="line">​      &#125;</span><br><span class="line"></span><br><span class="line">​      <span class="comment">//该方法会在Rebalance之后调用</span></span><br><span class="line"></span><br><span class="line">​      <span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​        currentOffset.clear();</span><br><span class="line"></span><br><span class="line">​        <span class="keyword">for</span> (TopicPartition partition : partitions) &#123;</span><br><span class="line"></span><br><span class="line">​          consumer.seek(partition, getOffset(partition));<span class="comment">//定位到最近提交的offset位置继续消费</span></span><br><span class="line"></span><br><span class="line">​        &#125;</span><br><span class="line"></span><br><span class="line">​      &#125;</span><br><span class="line"></span><br><span class="line">​    &#125;);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">​      ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);<span class="comment">//消费者拉取数据</span></span><br><span class="line"></span><br><span class="line">​      <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line"></span><br><span class="line">​        System.out.printf(<span class="string">"offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.value());</span><br><span class="line"></span><br><span class="line">​        currentOffset.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()), record.offset());</span><br><span class="line"></span><br><span class="line">​      &#125;</span><br><span class="line"></span><br><span class="line">​      commitOffset(currentOffset);<span class="comment">//异步提交</span></span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取某分区的最新offset</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getOffset</span><span class="params">(TopicPartition partition)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//提交该消费者所有分区的offset</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">commitOffset</span><span class="params">(Map&lt;TopicPartition, Long&gt; currentOffset)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="自定义Interceptor"><a href="#自定义Interceptor" class="headerlink" title="自定义Interceptor"></a>自定义Interceptor</h2><h3 id="拦截器原理"><a href="#拦截器原理" class="headerlink" title="拦截器原理"></a>拦截器原理</h3><p>Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。</p>
<p>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</p>
<p>（1）configure(configs)</p>
<p>获取配置信息和初始化数据时调用。</p>
<p>（2）onSend(ProducerRecord)：</p>
<p>该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。</p>
<p>（3）onAcknowledgement(RecordMetadata, Exception)：</p>
<p>该方法会在消息从RecordAccumulator成功发送到Kafka Broker之后，或者在发送过程中失败时调用。并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率。</p>
<p>（4）close：</p>
<p>关闭interceptor，主要用于执行一些资源清理工作</p>
<p>如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个interceptor，则producer将按照指定顺序调用它们，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</p>
<h3 id="拦截器案例"><a href="#拦截器案例" class="headerlink" title="拦截器案例"></a>拦截器案例</h3><p>1）需求：</p>
<p>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。</p>
<p>2）案例实操</p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/wps200.png" alt="img"></p>
<p>（1）增加时间戳拦截器</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​		<span class="comment">// 创建一个新的record，把时间戳写入消息体的最前部</span></span><br><span class="line"></span><br><span class="line">​		<span class="keyword">return</span> <span class="keyword">new</span> ProducerRecord(record.topic(), record.partition(), record.timestamp(), record.key(),</span><br><span class="line"></span><br><span class="line">​				System.currentTimeMillis() + <span class="string">","</span> + record.value().toString());</span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CounterInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> errorCounter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> successCounter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​		</span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​		 <span class="keyword">return</span> record;</span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​		<span class="comment">// 统计成功和失败的次数</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">​      successCounter++;</span><br><span class="line"></span><br><span class="line">​    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">​      errorCounter++;</span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">​    <span class="comment">// 保存结果</span></span><br><span class="line"></span><br><span class="line">​    System.out.println(<span class="string">"Successful sent: "</span> + successCounter);</span><br><span class="line"></span><br><span class="line">​    System.out.println(<span class="string">"Failed sent: "</span> + errorCounter);</span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）producer主程序</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterceptorProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">​		<span class="comment">// 1 设置配置信息</span></span><br><span class="line"></span><br><span class="line">​		Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"retries"</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>);</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">​		props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">​		</span><br><span class="line"></span><br><span class="line">​		<span class="comment">// 2 构建拦截链</span></span><br><span class="line"></span><br><span class="line">​		List&lt;String&gt; interceptors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">​		interceptors.add(<span class="string">"com.red.kafka.interceptor.TimeInterceptor"</span>); 	interceptors.add(<span class="string">"com.red.kafka.interceptor.CounterInterceptor"</span>); </span><br><span class="line"></span><br><span class="line">​		props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br><span class="line"></span><br><span class="line">​		 </span><br><span class="line"></span><br><span class="line">​		String topic = <span class="string">"first"</span>;</span><br><span class="line"></span><br><span class="line">​		Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">​		</span><br><span class="line"></span><br><span class="line">​		<span class="comment">// 3 发送消息</span></span><br><span class="line"></span><br><span class="line">​		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">​			</span><br><span class="line"></span><br><span class="line">​		  ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, <span class="string">"message"</span> + i);</span><br><span class="line"></span><br><span class="line">​		  producer.send(record);</span><br><span class="line"></span><br><span class="line">​		&#125;</span><br><span class="line"></span><br><span class="line">​		 </span><br><span class="line"></span><br><span class="line">​		<span class="comment">// 4 一定要关闭producer，这样才会调用interceptor的close方法</span></span><br><span class="line"></span><br><span class="line">​		producer.close();</span><br><span class="line"></span><br><span class="line">​	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>3）测试</p>
<p>（1）在kafka上启动消费者，然后运行客户端java程序。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line"></span><br><span class="line">--bootstrap-server hadoop102:9092 --from-beginning --topic first</span><br></pre></td></tr></table></figure>

<blockquote>
<p>1501904047034,message0</p>
<p>1501904047225,message1</p>
<p>1501904047230,message2</p>
<p>1501904047234,message3</p>
<p>1501904047236,message4</p>
<p>1501904047240,message5</p>
<p>1501904047243,message6</p>
<p>1501904047246,message7</p>
<p>1501904047249,message8</p>
<p>1501904047252,message9</p>
</blockquote>
<h1 id="Kafka监控"><a href="#Kafka监控" class="headerlink" title="Kafka监控"></a>Kafka监控</h1><h2 id="KafkaManager"><a href="#KafkaManager" class="headerlink" title="KafkaManager"></a>KafkaManager</h2><p>1.上传压缩包kafka-manager-1.3.3.15.zip到集群</p>
<p>2.解压到/opt/module</p>
<p>3.修改配置文件conf/application.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-manager.zkhosts="kafka-manager-zookeeper:2181"</span><br></pre></td></tr></table></figure>

<p>修改为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-manager.zkhosts="hadoop102:2181,hadoop103:2181,hadoop104:2181"</span><br></pre></td></tr></table></figure>

<p>4.启动kafka-manager</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-manager</span><br></pre></td></tr></table></figure>

<p>5.登录hadoop102:9000页面查看详细信息</p>
<h2 id="KafkaMonitor"><a href="#KafkaMonitor" class="headerlink" title="KafkaMonitor"></a>KafkaMonitor</h2><p>1.上传jar包KafkaOffsetMonitor-assembly-0.2.0.jar到集群</p>
<p>2.在/opt/module/下创建kafka-offset-console文件夹</p>
<p>3.将上传的jar包放入刚创建的目录下</p>
<p>4.在/opt/module/kafka-offset-console目录下创建启动脚本start.sh，内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">java -Xms512M -Xmx512M -Xss1024K -XX:PermSize=256M -XX:MaxPermSize=512M -cp KafkaOffsetMonitor-assembly-0.2.0.jar \</span><br><span class="line"></span><br><span class="line">com.quantifind.kafka.offsetapp.OffsetGetterWeb \</span><br><span class="line"></span><br><span class="line">--zk hadoop102:2181,hadoop103:2181,hadoop104:2181 \</span><br><span class="line"></span><br><span class="line">--port 8086 \</span><br><span class="line"></span><br><span class="line">--refresh 10.seconds \</span><br><span class="line"></span><br><span class="line">--retain 7.days  1&gt;mobile-logs/stdout.log  2&gt;mobile-logs/stderr.log &amp;</span><br></pre></td></tr></table></figure>

<p>5.在/opt/module/kafka-offset-console目录下创建mobile-logs文件夹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir &#x2F;opt&#x2F;module&#x2F;kafka-offset-console&#x2F;mobile-logs</span><br></pre></td></tr></table></figure>

<p>6.启动KafkaMonitor</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;start.sh</span><br></pre></td></tr></table></figure>

<p>7.登录页面hadoop102:8086端口查看详情</p>
<h2 id="Kafka-Eagle"><a href="#Kafka-Eagle" class="headerlink" title="Kafka Eagle"></a>Kafka Eagle</h2><p>1.修改kafka启动命令</p>
<p>修改kafka-server-start.sh命令中</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">"x<span class="variable">$KAFKA_HEAP_OPTS</span>"</span> = <span class="string">"x"</span> ]; <span class="keyword">then</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">export</span> KAFKA_HEAP_OPTS=<span class="string">"-Xmx1G -Xms1G"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p>为</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">"x<span class="variable">$KAFKA_HEAP_OPTS</span>"</span> = <span class="string">"x"</span> ]; <span class="keyword">then</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">export</span> KAFKA_HEAP_OPTS=<span class="string">"-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70"</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">export</span> JMX_PORT=<span class="string">"9999"</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p><font color="red">注意：修改之后在启动Kafka之前要分发之其他节点</font></p>
<p>2.上传压缩包kafka-eagle-bin-1.3.7.tar.gz到集群/opt/software目录</p>
<p>3.解压到本地</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 software]$ tar -zxvf kafka-eagle-bin-1.3.7.tar.gz</span><br></pre></td></tr></table></figure>

<p>4.进入刚才解压的目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka-eagle-bin-1.3.7]$ ll</span><br></pre></td></tr></table></figure>

<blockquote>
<p>总用量 82932</p>
<p>-rw-rw-r–. 1 red red 84920710 8月  13 23:00 kafka-eagle-web-1.3.7-bin.tar.gz</p>
</blockquote>
<p>5.将kafka-eagle-web-1.3.7-bin.tar.gz解压至/opt/module</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 kafka-eagle-bin-1.3.7]$ tar -zxvf kafka-eagle-web-1.3.7-bin.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure>

<p>6.修改名称</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 module]$ mv kafka-eagle-web-1.3.7&#x2F; eagle</span><br></pre></td></tr></table></figure>

<p>7.给启动文件执行权限</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 eagle]$ cd bin&#x2F;</span><br><span class="line"></span><br><span class="line">[red@hadoop102 bin]$ ll</span><br></pre></td></tr></table></figure>

<blockquote>
<p>总用量 12</p>
<p>-rw-r–r–. 1 red red 1848 8月  22 2017 ke.bat</p>
<p>-rw-r–r–. 1 red red 7190 7月  30 20:12 ke.sh</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 bin]$ chmod 777 ke.sh</span><br></pre></td></tr></table></figure>

<p>8.修改配置文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># multi zookeeper&amp;kafka cluster list</span></span><br><span class="line"></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.zk.cluster.alias</span>=<span class="string">cluster1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">cluster1.zk.list</span>=<span class="string">hadoop102:2181,hadoop103:2181,hadoop104:2181</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kafka offset storage</span></span><br><span class="line"></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="meta">cluster1.kafka.eagle.offset.storage</span>=<span class="string">kafka</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># enable kafka metrics</span></span><br><span class="line"></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.metrics.charts</span>=<span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.sql.fix.error</span>=<span class="string">false</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kafka jdbc driver address</span></span><br><span class="line"></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.driver</span>=<span class="string">com.mysql.jdbc.Driver</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.url</span>=<span class="string">jdbc:mysql://hadoop102:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.username</span>=<span class="string">root</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka.eagle.password</span>=<span class="string">000000</span></span><br></pre></td></tr></table></figure>



<p>9.添加环境变量</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">export</span> <span class="string">KE_HOME=/opt/module/eagle</span></span><br><span class="line"></span><br><span class="line"><span class="attr">export</span> <span class="string">PATH=$PATH:$KE_HOME/bin</span></span><br></pre></td></tr></table></figure>

<p>注意：source /etc/profile</p>
<p>10.启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 eagle]$ bin&#x2F;ke.sh start</span><br></pre></td></tr></table></figure>

<blockquote>
<p>… …</p>
<p>… …</p>
<p>*Kafka Eagle Service has started success.</p>
<p>* Welcome, Now you can visit ‘<a href="http://192.168.9.102:8048/ke&#39;" target="_blank" rel="noopener">http://192.168.9.102:8048/ke&#39;</a></p>
<p>* Account:admin ,Password:123456</p>
<hr>
<p>* <Usage> ke.sh [start|status|stop|restart|stats] </Usage></p>
<p>* <Usage> <a href="https://www.kafka-eagle.org/" target="_blank" rel="noopener">https://www.kafka-eagle.org/</a> </Usage></p>
</blockquote>
<p>[red@hadoop102 eagle]$</p>
<p><font color="red">注意：启动之前需要先启动ZK以及KAFKA</font></p>
<p>11.登录页面查看监控数据</p>
<p><a href="http://192.168.9.102:8048/ke" target="_blank" rel="noopener">http://192.168.9.102:8048/ke</a></p>
<p><img src="/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/image-20200923164007494.png" alt="image-20200923164007494"></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Snow Monster</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.red0819.top/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/">http://www.red0819.top/bigdata/Kafka%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.red0819.top" target="_blank">RedLeavesBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a></div><div class="post_share"><div class="social-share" data-image="/wordPic/timg.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/hexo/hexo%E5%8D%9A%E5%AE%A2%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/"><img class="prev-cover" src="/wordPic/hexo-logo.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">hexo博客的一些坑</div></div></a></div><div class="next-post pull-right"><a href="/computernetwork/TCP%E9%AB%98%E6%95%88%E7%BC%96%E7%A8%8B/"><img class="next-cover" src="/wordPic/timg.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">TCP高效编程</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer" style="background-image: url(/wordPic/timg.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2020 By Snow Monster</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener">Butterfly</a></div><div class="footer_custom_text">努力充实自己大脑中，欢迎投喂知识！</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: 'BlwHhRwsSAJShGHGJeX8d6qB-gzGzoHsz',
      appKey: 'fGlkNKWjBKmGkMSND7jvpsRI',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script></div></body></html>