<!DOCTYPE html>
<html lang="zh-CN">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="Snow Monster" />


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="Snow MonsterBlog">
<meta property="og:url" content="http://www.red0819.top/index.html">
<meta property="og:site_name" content="Snow MonsterBlog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Snow Monster">
<meta name="twitter:card" content="summary">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Snow MonsterBlog" type="application/atom+xml">



    <link rel="shortcut icon" href="/img/logo.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">



<link rel="stylesheet" href="/css/style.css">



    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Snow MonsterBlog</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






<meta name="generator" content="Hexo 4.2.1"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/yanmoai.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Snow Monster</a></h1>
        </hgroup>

        
        <p class="header-subtitle">我らが征くは星の大海</p>
        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="/jqh0819@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa CSDN" href="https://mp.csdn.net/console/article" target="_blank" rel="noopener" title="CSDN"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/First-Test/" rel="tag">First_Test</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL%E5%9F%BA%E7%A1%80/" rel="tag">SQL基础</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkStreaming/" rel="tag">SparkStreaming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/socket/" rel="tag">socket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%9D%E8%AF%95/" rel="tag">尝试</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/" target="_blank" rel="noopener">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/" target="_blank" rel="noopener">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">欲知后事如何，且听我下回分说</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Snow Monster</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/yanmoai.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Snow Monster</a></h1>
            </hgroup>
            
            <p class="header-subtitle">我らが征くは星の大海</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="/jqh0819@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa CSDN" target="_blank" href="https://mp.csdn.net/console/article" title="CSDN"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-test1" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/14/test1/" class="article-date">
      <time datetime="2020-09-14T10:25:30.000Z" itemprop="datePublished">2020-09-14</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/14/test1/">test1</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-主流ETL清洗工具" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/12/%E4%B8%BB%E6%B5%81ETL%E6%B8%85%E6%B4%97%E5%B7%A5%E5%85%B7/" class="article-date">
      <time datetime="2020-09-12T05:55:24.000Z" itemprop="datePublished">2020-09-12</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/12/%E4%B8%BB%E6%B5%81ETL%E6%B8%85%E6%B4%97%E5%B7%A5%E5%85%B7/">主流ETL清洗工具</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-OLAP和OLTP" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/12/OLAP%E5%92%8COLTP/" class="article-date">
      <time datetime="2020-09-12T05:55:06.000Z" itemprop="datePublished">2020-09-12</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/12/OLAP%E5%92%8COLTP/">OLAP和OLTP</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-主流OLAP系统对比总结" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/12/%E4%B8%BB%E6%B5%81OLAP%E7%B3%BB%E7%BB%9F%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93/" class="article-date">
      <time datetime="2020-09-12T05:53:37.000Z" itemprop="datePublished">2020-09-12</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/12/%E4%B8%BB%E6%B5%81OLAP%E7%B3%BB%E7%BB%9F%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93/">主流OLAP系统对比总结</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-基础SQL题（来自牛客网）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/09/%E5%9F%BA%E7%A1%80SQL%E9%A2%98%EF%BC%88%E6%9D%A5%E8%87%AA%E7%89%9B%E5%AE%A2%E7%BD%91%EF%BC%89/" class="article-date">
      <time datetime="2020-09-09T13:37:10.000Z" itemprop="datePublished">2020-09-09</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/09/%E5%9F%BA%E7%A1%80SQL%E9%A2%98%EF%BC%88%E6%9D%A5%E8%87%AA%E7%89%9B%E5%AE%A2%E7%BD%91%EF%BC%89/">基础SQL题（来自牛客网）</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="基础SQL"><a href="#基础SQL" class="headerlink" title="基础SQL"></a>基础SQL</h1><h2 id="查找最晚入职员工的所有信息"><a href="#查找最晚入职员工的所有信息" class="headerlink" title="查找最晚入职员工的所有信息"></a>查找最晚入职员工的所有信息</h2><p>查找最晚入职员工的所有信息，为了减轻入门难度，目前所有的数据里员工入职的日期都不是同一天(sqlite里面的注释为–,mysql为comment)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;employees&#96; (</span><br><span class="line">&#96;emp_no&#96; int(11) NOT NULL, -- &#39;员工编号&#39;</span><br><span class="line">&#96;birth_date&#96; date NOT NULL,</span><br><span class="line">&#96;first_name&#96; varchar(14) NOT NULL,</span><br><span class="line">&#96;last_name&#96; varchar(16) NOT NULL,</span><br><span class="line">&#96;gender&#96; char(1) NOT NULL,</span><br><span class="line">&#96;hire_date&#96; date NOT NULL,</span><br><span class="line">PRIMARY KEY (&#96;emp_no&#96;));</span><br></pre></td></tr></table></figure>

<h4 id="输入描述"><a href="#输入描述" class="headerlink" title="输入描述"></a>输入描述</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">无</span><br></pre></td></tr></table></figure>

<h4 id="输出描述"><a href="#输出描述" class="headerlink" title="输出描述"></a>输出描述</h4><p>示例</p>
<table>
<thead>
<tr>
<th>emp_no</th>
<th>birth_date</th>
<th>first_name</th>
<th>last_name</th>
<th>gender</th>
<th>hire_date</th>
</tr>
</thead>
<tbody><tr>
<td>10008</td>
<td>1958-02-19</td>
<td>Saniya</td>
<td>Kalloufi</td>
<td>M</td>
<td>1994-09-15</td>
</tr>
</tbody></table>
<h3 id="我的答案"><a href="#我的答案" class="headerlink" title="我的答案"></a>我的答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from employees where hire_date &#x3D; (select max(hire_date) from employees );</span><br></pre></td></tr></table></figure>

<p>运行时间: 17ms 占用内存: 3320KB</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from employees order by hire_date desc limit 1</span><br></pre></td></tr></table></figure>

<p>运行时间: 11ms 占用内存: 3320KB</p>
<h3 id="最优答案"><a href="#最优答案" class="headerlink" title="最优答案"></a>最优答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE hire_date &#x3D; (SELECT MAX(hire_date) FROM employees)</span><br></pre></td></tr></table></figure>

<p>用户：ktktktkt 运行时间: 10ms 占用内存: 3192KB</p>
<h2 id="查找入职员工时间排名倒数第三的员工所有信息"><a href="#查找入职员工时间排名倒数第三的员工所有信息" class="headerlink" title="查找入职员工时间排名倒数第三的员工所有信息"></a>查找入职员工时间排名倒数第三的员工所有信息</h2><p>查找入职员工时间排名倒数第三的员工所有信息，为了减轻入门难度，目前所有的数据里员工入职的日期都不是同一天</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;employees&#96; (</span><br><span class="line">&#96;emp_no&#96; int(11) NOT NULL,</span><br><span class="line">&#96;birth_date&#96; date NOT NULL,</span><br><span class="line">&#96;first_name&#96; varchar(14) NOT NULL,</span><br><span class="line">&#96;last_name&#96; varchar(16) NOT NULL,</span><br><span class="line">&#96;gender&#96; char(1) NOT NULL,</span><br><span class="line">&#96;hire_date&#96; date NOT NULL,</span><br><span class="line">PRIMARY KEY (&#96;emp_no&#96;));</span><br></pre></td></tr></table></figure>

<h4 id="输入描述-1"><a href="#输入描述-1" class="headerlink" title="输入描述"></a>输入描述</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">无</span><br></pre></td></tr></table></figure>

<h4 id="输出描述-1"><a href="#输出描述-1" class="headerlink" title="输出描述"></a>输出描述</h4><p>示例1</p>
<table>
<thead>
<tr>
<th>emp_no</th>
<th>birth_date</th>
<th>first_name</th>
<th>last_name</th>
<th>gender</th>
<th>hire_date</th>
</tr>
</thead>
<tbody><tr>
<td>10005</td>
<td>1955-01-21</td>
<td>Kyoichi</td>
<td>Maliniak</td>
<td>M</td>
<td>1989-09-12</td>
</tr>
</tbody></table>
<h3 id="我的答案-1"><a href="#我的答案-1" class="headerlink" title="我的答案"></a>我的答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select * from employees </span><br><span class="line">where hire_date &#x3D; (select hire_date from employees order by hire_date desc limit 2,1</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>运行时间: 12ms 占用内存: 3364KB</p>
<h3 id="最优答案-1"><a href="#最优答案-1" class="headerlink" title="最优答案"></a>最优答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select *</span><br><span class="line"> &#96;&#96;from employees</span><br><span class="line"> &#96;&#96;order by hire_date desc</span><br><span class="line"> &#96;&#96;limit &#96;&#96;2&#96;&#96;,&#96;&#96;1&#96;&#96;;</span><br></pre></td></tr></table></figure>

<p>用户：Howedata 运行时间: 10ms 占用内存: 3284KB</p>
<h2 id="查找当前薪水详情以及部门编号"><a href="#查找当前薪水详情以及部门编号" class="headerlink" title="查找当前薪水详情以及部门编号"></a>查找当前薪水详情以及部门编号</h2><p>查找最晚入职员工的所有信息，为了减轻入门难度，目前所有的数据里员工入职的日期都不是同一天(sqlite里面的注释为–,mysql为comment)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;employees&#96; (</span><br><span class="line">&#96;emp_no&#96; int(11) NOT NULL, -- &#39;员工编号&#39;</span><br><span class="line">&#96;birth_date&#96; date NOT NULL,</span><br><span class="line">&#96;first_name&#96; varchar(14) NOT NULL,</span><br><span class="line">&#96;last_name&#96; varchar(16) NOT NULL,</span><br><span class="line">&#96;gender&#96; char(1) NOT NULL,</span><br><span class="line">&#96;hire_date&#96; date NOT NULL,</span><br><span class="line">PRIMARY KEY (&#96;emp_no&#96;));</span><br></pre></td></tr></table></figure>

<h4 id="输入描述-2"><a href="#输入描述-2" class="headerlink" title="输入描述"></a>输入描述</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">无</span><br></pre></td></tr></table></figure>

<h4 id="输出描述-2"><a href="#输出描述-2" class="headerlink" title="输出描述"></a>输出描述</h4><p>示例</p>
<table>
<thead>
<tr>
<th>emp_no</th>
<th>salary</th>
<th>from_date</th>
<th>to_date</th>
<th>dept_no</th>
</tr>
</thead>
<tbody><tr>
<td>10002</td>
<td>72527</td>
<td>2001-08-02</td>
<td>9999-01-01</td>
<td>d001</td>
</tr>
<tr>
<td>10004</td>
<td>74057</td>
<td>2001-11-27</td>
<td>9999-01-01</td>
<td>d004</td>
</tr>
<tr>
<td>10005</td>
<td>94692</td>
<td>2001-09-09</td>
<td>9999-01-01</td>
<td>d003</td>
</tr>
<tr>
<td>10006</td>
<td>43311</td>
<td>2001-08-02</td>
<td>9999-01-01</td>
<td>d002</td>
</tr>
<tr>
<td>10010</td>
<td>94409</td>
<td>2001-11-23</td>
<td>9999-01-01</td>
<td>d006</td>
</tr>
</tbody></table>
<h3 id="我的答案-2"><a href="#我的答案-2" class="headerlink" title="我的答案"></a>我的答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select sa.emp_no , sa.salary ,sa.from_date ,sa.to_date ,de.dept_no</span><br><span class="line">from </span><br><span class="line">salaries sa join dept_manager de on </span><br><span class="line">sa.emp_no &#x3D; de.emp_no</span><br><span class="line">where</span><br><span class="line">sa.to_date&#x3D;&#39;9999-01-01&#39; and de.to_date&#x3D;&#39;9999-01-01&#39;</span><br><span class="line">order by </span><br><span class="line">sa.emp_no;</span><br></pre></td></tr></table></figure>

<p>运行时间:12ms 占用内存: 3344KB</p>
<h3 id="最优答案-2"><a href="#最优答案-2" class="headerlink" title="最优答案"></a>最优答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select salaries.*, dept_manager.dept_no from </span><br><span class="line">salaries,dept_manager on salaries.emp_no &#x3D; dept_manager.emp_no </span><br><span class="line">where salaries.to_date&#x3D;&#39;9999-01-01&#39; and dept_manager.to_date&#x3D;&#39;9999-01-01&#39;;</span><br></pre></td></tr></table></figure>

<p>用户：牛客326549353号 运行时间: 11ms 占用内存: 3248KB</p>
<h2 id="查找所有已经分配部门的员工的last-name和first-name以及dept-no"><a href="#查找所有已经分配部门的员工的last-name和first-name以及dept-no" class="headerlink" title="查找所有已经分配部门的员工的last_name和first_name以及dept_no"></a>查找所有已经分配部门的员工的last_name和first_name以及dept_no</h2><p>查找最晚入职员工的所有信息，为了减轻入门难度，目前所有的数据里员工入职的日期都不是同一天(sqlite里面的注释为–,mysql为comment)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;employees&#96; (</span><br><span class="line">&#96;emp_no&#96; int(11) NOT NULL, -- &#39;员工编号&#39;</span><br><span class="line">&#96;birth_date&#96; date NOT NULL,</span><br><span class="line">&#96;first_name&#96; varchar(14) NOT NULL,</span><br><span class="line">&#96;last_name&#96; varchar(16) NOT NULL,</span><br><span class="line">&#96;gender&#96; char(1) NOT NULL,</span><br><span class="line">&#96;hire_date&#96; date NOT NULL,</span><br><span class="line">PRIMARY KEY (&#96;emp_no&#96;));</span><br></pre></td></tr></table></figure>

<h4 id="输入描述-3"><a href="#输入描述-3" class="headerlink" title="输入描述"></a>输入描述</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">无</span><br></pre></td></tr></table></figure>

<h4 id="输出描述-3"><a href="#输出描述-3" class="headerlink" title="输出描述"></a>输出描述</h4><p>示例</p>
<table>
<thead>
<tr>
<th>last_name</th>
<th>first_name</th>
<th>dept_no</th>
</tr>
</thead>
<tbody><tr>
<td>Facello</td>
<td>Georgi</td>
<td>d001</td>
</tr>
<tr>
<td>省略</td>
<td>省略</td>
<td>省略</td>
</tr>
<tr>
<td>Piveteau</td>
<td>Duangkaew</td>
<td>d006</td>
</tr>
</tbody></table>
<h3 id="我的答案-3"><a href="#我的答案-3" class="headerlink" title="我的答案"></a>我的答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select employees.last_name,employees.first_name,dept_emp.dept_no </span><br><span class="line">from </span><br><span class="line">employees inner join dept_emp </span><br><span class="line">on employees.emp_no&#x3D;dept_emp.emp_no</span><br></pre></td></tr></table></figure>

<p>运行时间:12ms 占用内存: 3300KB</p>
<h3 id="最优答案-3"><a href="#最优答案-3" class="headerlink" title="最优答案"></a>最优答案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select employees.last_name,employees.first_name,dept_emp.dept_no </span><br><span class="line">from employees inner join dept_emp</span><br><span class="line">on employees.emp_no&#x3D;dept_emp.emp_no</span><br></pre></td></tr></table></figure>

<p>用户：牛客180011609号 运行时间: 10ms 占用内存: 3300KB</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SQL%E5%9F%BA%E7%A1%80/" rel="tag">SQL基础</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Oozie" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/06/Oozie/" class="article-date">
      <time datetime="2020-09-06T06:44:01.087Z" itemprop="datePublished">2020-09-06</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/06/Oozie/">Oozie</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="第1章-Oozie简介"><a href="#第1章-Oozie简介" class="headerlink" title="第1章 Oozie简介"></a>第1章 Oozie简介</h1><p>Oozie英文翻译为：驯象人。一个基于工作流引擎的开源框架，由Cloudera公司贡献给Apache，提供对Hadoop<br>MapReduce、Pig Jobs的任务调度与协调。Oozie需要部署到Java<br>Servlet容器中运行。主要用于定时调度任务，多任务可以按照执行的逻辑顺序调度。</p>
<h1 id="第2章-Oozie的功能模块介绍"><a href="#第2章-Oozie的功能模块介绍" class="headerlink" title="第2章 Oozie的功能模块介绍"></a>第2章 Oozie的功能模块介绍</h1><h2 id="2-1模块"><a href="#2-1模块" class="headerlink" title="2.1模块"></a>2.1模块</h2><p><strong>1) Workflow</strong></p>
<p>顺序执行流程节点，支持fork（分支多个节点），join（合并多个节点为一个）</p>
<p><strong>2) Coordinator</strong></p>
<p>定时触发workflow</p>
<p><strong>3) Bundle</strong></p>
<p>绑定多个Coordinator</p>
<h2 id="2-2-Workflow常用节点"><a href="#2-2-Workflow常用节点" class="headerlink" title="2.2 Workflow常用节点"></a>2.2 Workflow常用节点</h2><p><strong>1) 控制流节点（Control Flow Nodes）</strong></p>
<p>控制流节点一般都是定义在工作流开始或者结束的位置，比如start,end,kill等。以及提供工作流的执行路径机制，如decision，fork，join等。</p>
<p><strong>2) 动作节点（Action Nodes）</strong></p>
<p>负责执行具体动作的节点，比如：拷贝文件，执行某个Shell脚本等等。</p>
<h1 id="第3章-Oozie的部署"><a href="#第3章-Oozie的部署" class="headerlink" title="第3章 Oozie的部署"></a>第3章 Oozie的部署</h1><h2 id="3-1-部署Hadoop（CDH版本的）"><a href="#3-1-部署Hadoop（CDH版本的）" class="headerlink" title="3.1 部署Hadoop（CDH版本的）"></a>3.1 部署Hadoop（CDH版本的）</h2><h3 id="3-1-2-修改Hadoop配置"><a href="#3-1-2-修改Hadoop配置" class="headerlink" title="3.1.2 修改Hadoop配置"></a>3.1.2 修改Hadoop配置</h3><p><strong>core-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Oozie Server的Hostname --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.red.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 允许被Oozie代理的用户组 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.red.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>mapred-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置 MapReduce JobHistory Server 地址 ，默认端口10020 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置 MapReduce JobHistory Server web ui 地址， 默认端口19888</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>yarn-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 任务历史服务 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>完成后：记得scp同步到其他机器节点</p>
<h3 id="3-1-3-启动Hadoop集群"><a href="#3-1-3-启动Hadoop集群" class="headerlink" title="3.1.3 启动Hadoop集群"></a>3.1.3 启动Hadoop集群</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hadoop-2.5.0-cdh5.3.6]$ sbin&#x2F;start-dfs.sh</span><br><span class="line"></span><br><span class="line">[red@hadoop103 hadoop-2.5.0-cdh5.3.6]$ sbin&#x2F;start-yarn.sh</span><br><span class="line"></span><br><span class="line">[red@hadoop102 hadoop-2.5.0-cdh5.3.6]$</span><br><span class="line">sbin&#x2F;mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>

<p>注意：需要开启JobHistoryServer, 最好执行一个MR任务进行测试。</p>
<h2 id="3-2-部署Oozie"><a href="#3-2-部署Oozie" class="headerlink" title="3.2 部署Oozie"></a>3.2 部署Oozie</h2><h3 id="3-2-1-解压Oozie"><a href="#3-2-1-解压Oozie" class="headerlink" title="3.2.1 解压Oozie"></a>3.2.1 解压Oozie</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 software]$ tar -zxvf</span><br><span class="line">&#x2F;opt&#x2F;software&#x2F;cdh&#x2F;oozie-4.0.0-cdh5.3.6.tar.gz -C &#x2F;opt&#x2F;module</span><br></pre></td></tr></table></figure>



<h3 id="3-2-2-在oozie根目录下解压oozie-hadooplibs-4-0-0-cdh5-3-6-tar-gz"><a href="#3-2-2-在oozie根目录下解压oozie-hadooplibs-4-0-0-cdh5-3-6-tar-gz" class="headerlink" title="3.2.2 在oozie根目录下解压oozie-hadooplibs-4.0.0-cdh5.3.6.tar.gz"></a>3.2.2 在oozie根目录下解压oozie-hadooplibs-4.0.0-cdh5.3.6.tar.gz</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ tar -zxvf</span><br><span class="line">oozie-hadooplibs-4.0.0-cdh5.3.6.tar.gz -C ..&#x2F;</span><br></pre></td></tr></table></figure>

<p>完成后Oozie目录下会出现hadooplibs目录。</p>
<h3 id="3-2-3-在Oozie目录下创建libext目录"><a href="#3-2-3-在Oozie目录下创建libext目录" class="headerlink" title="3.2.3 在Oozie目录下创建libext目录"></a>3.2.3 在Oozie目录下创建libext目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ mkdir libext&#x2F;</span><br></pre></td></tr></table></figure>



<h3 id="3-2-4-拷贝依赖的Jar包"><a href="#3-2-4-拷贝依赖的Jar包" class="headerlink" title="3.2.4 拷贝依赖的Jar包"></a>3.2.4 拷贝依赖的Jar包</h3><p>1）将hadooplibs里面的jar包，拷贝到libext目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ cp -ra</span><br><span class="line">hadooplibs&#x2F;hadooplib-2.5.0-cdh5.3.6.oozie-4.0.0-cdh5.3.6&#x2F;* libext&#x2F;</span><br></pre></td></tr></table></figure>

<p>2）拷贝Mysql驱动包到libext目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ cp -a</span><br><span class="line">&#x2F;opt&#x2F;software&#x2F;mysql-connector-java-5.1.27&#x2F;mysql-connector-java-5.1.27-bin.jar</span><br><span class="line">.&#x2F;libext&#x2F;</span><br></pre></td></tr></table></figure>



<h3 id="3-2-5-将ext-2-2-zip拷贝到libext-目录下"><a href="#3-2-5-将ext-2-2-zip拷贝到libext-目录下" class="headerlink" title="3.2.5 将ext-2.2.zip拷贝到libext/目录下"></a>3.2.5 将ext-2.2.zip拷贝到libext/目录下</h3><p>ext是一个js框架，用于展示oozie前端页面：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ cp -a</span><br><span class="line">&#x2F;opt&#x2F;software&#x2F;cdh&#x2F;ext-2.2.zip libext&#x2F;</span><br></pre></td></tr></table></figure>



<h3 id="3-2-6-修改Oozie配置文件"><a href="#3-2-6-修改Oozie配置文件" class="headerlink" title="3.2.6 修改Oozie配置文件"></a>3.2.6 修改Oozie配置文件</h3><p><strong>oozie-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">属性：oozie.service.JPAService.jdbc.driver</span><br><span class="line"></span><br><span class="line">属性值：com.mysql.jdbc.Driver</span><br><span class="line"></span><br><span class="line">解释：JDBC的驱动</span><br><span class="line"></span><br><span class="line">属性：oozie.service.JPAService.jdbc.url</span><br><span class="line"></span><br><span class="line">属性值：jdbc:mysql://hadoop102:3306/oozie</span><br><span class="line"></span><br><span class="line">解释：oozie所需的数据库地址</span><br><span class="line"></span><br><span class="line">属性：oozie.service.JPAService.jdbc.username</span><br><span class="line"></span><br><span class="line">属性值：root</span><br><span class="line"></span><br><span class="line">解释：数据库用户名</span><br><span class="line"></span><br><span class="line">属性：oozie.service.JPAService.jdbc.password</span><br><span class="line"></span><br><span class="line">属性值：123456</span><br><span class="line"></span><br><span class="line">解释：数据库密码</span><br><span class="line"></span><br><span class="line">属性：oozie.service.HadoopAccessorService.hadoop.configurations</span><br><span class="line"></span><br><span class="line">属性值：*= /opt/module/cdh/hadoop-2.5.0-cdh5.3.6/etc/hadoop</span><br><span class="line"></span><br><span class="line">解释：让Oozie引用Hadoop的配置文件</span><br></pre></td></tr></table></figure>



<h3 id="3-2-7-在Mysql中创建Oozie的数据库"><a href="#3-2-7-在Mysql中创建Oozie的数据库" class="headerlink" title="3.2.7 在Mysql中创建Oozie的数据库"></a>3.2.7 在Mysql中创建Oozie的数据库</h3><p>进入Mysql并创建oozie数据库：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -uroot -p123456</span><br><span class="line"></span><br><span class="line">mysql&gt; create database oozie;</span><br></pre></td></tr></table></figure>



<h3 id="3-2-8-初始化Oozie"><a href="#3-2-8-初始化Oozie" class="headerlink" title="3.2.8 初始化Oozie"></a>3.2.8 初始化Oozie</h3><p><strong>1) 上传Oozie目录下的yarn.tar.gz文件到HDFS：</strong></p>
<p>提示：yarn.tar.gz文件会自行解压</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozie-setup.sh</span><br><span class="line">sharelib create -fs hdfs:&#x2F;&#x2F;hadoop102:8020 -locallib</span><br><span class="line">oozie-sharelib-4.0.0-cdh5.3.6-yarn.tar.gz</span><br></pre></td></tr></table></figure>

<p>执行成功之后，去50070检查对应目录有没有文件生成。</p>
<p><strong>2) 创建oozie.sql文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;ooziedb.sh create -sqlfile oozie.sql -run</span><br></pre></td></tr></table></figure>

<p><strong>3) 打包项目，生成war包</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozie-setup.sh prepare-war</span><br></pre></td></tr></table></figure>



<h3 id="3-2-9-Oozie的启动与关闭"><a href="#3-2-9-Oozie的启动与关闭" class="headerlink" title="3.2.9 Oozie的启动与关闭"></a>3.2.9 Oozie的启动与关闭</h3><p>启动命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozied.sh start</span><br></pre></td></tr></table></figure>

<p>关闭命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozied.sh stop</span><br></pre></td></tr></table></figure>



<h3 id="3-2-10-访问Oozie的Web页面"><a href="#3-2-10-访问Oozie的Web页面" class="headerlink" title="3.2.10 访问Oozie的Web页面"></a>3.2.10 访问Oozie的Web页面</h3><p><a href="http://hadoop102:11000/oozie" target="_blank" rel="noopener">http://hadoop102:11000/oozie</a></p>
<h1 id="第4章-Oozie的使用"><a href="#第4章-Oozie的使用" class="headerlink" title="第4章 Oozie的使用"></a>第4章 Oozie的使用</h1><h2 id="4-1-案例一：Oozie调度shell脚本"><a href="#4-1-案例一：Oozie调度shell脚本" class="headerlink" title="4.1 案例一：Oozie调度shell脚本"></a>4.1 案例一：Oozie调度shell脚本</h2><p>目标：使用Oozie调度Shell脚本</p>
<p>分步实现：</p>
<p>1）创建工作目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ mkdir -p oozie-apps&#x2F;shell</span><br></pre></td></tr></table></figure>

<p>2）在oozie-apps/shell目录下创建两个文件——job.properties和workflow.xml文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 shell]$ touch workflow.xml</span><br><span class="line"></span><br><span class="line">[red@hadoop102 shell]$ touch job.properties</span><br></pre></td></tr></table></figure>

<p>3）编辑job.properties和workflow.xml文件</p>
<p><strong>job.properties</strong></p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#HDFS地址</span></span><br><span class="line"></span><br><span class="line"><span class="attr">nameNode</span>=<span class="string">hdfs://hadoop102:8020</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ResourceManager地址</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobTracker</span>=<span class="string">hadoop103:8032</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#队列名称</span></span><br><span class="line"></span><br><span class="line"><span class="attr">queueName</span>=<span class="string">default</span></span><br><span class="line"></span><br><span class="line"><span class="attr">examplesRoot</span>=<span class="string">oozie-apps</span></span><br><span class="line"></span><br><span class="line"><span class="meta">oozie.wf.application.path</span>=<span class="string">$&#123;nameNode&#125;/user/$&#123;user.name&#125;/$&#123;examplesRoot&#125;/shell</span></span><br></pre></td></tr></table></figure>

<p><strong>workflow.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">workflow-app</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:workflow:0.4"</span> <span class="attr">name</span>=<span class="string">"shell-wf"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--开始节点--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">start</span> <span class="attr">to</span>=<span class="string">"shell-node"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--动作节点--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">action</span> <span class="attr">name</span>=<span class="string">"shell-node"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--shell动作--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">shell</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:shell-action:0.2"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">job-tracker</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="name">job-tracker</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name-node</span>&gt;</span>$&#123;nameNode&#125;<span class="tag">&lt;/<span class="name">name-node</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.queue.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--要执行的脚本--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">exec</span>&gt;</span>mkdir<span class="tag">&lt;/<span class="name">exec</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">argument</span>&gt;</span>/opt/software/d<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">capture-output</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">shell</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">ok</span> <span class="attr">to</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">error</span> <span class="attr">to</span>=<span class="string">"fail"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--kill节点--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">kill</span> <span class="attr">name</span>=<span class="string">"fail"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">message</span>&gt;</span>Shell action failed, error</span><br><span class="line">message[$&#123;wf:errorMessage(wf:lastErrorNode())&#125;]<span class="tag">&lt;/<span class="name">message</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">kill</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--结束节点--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">end</span> <span class="attr">name</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">workflow-app</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>4）上传任务配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;cdh&#x2F;hadoop-2.5.0-cdh5.3.6&#x2F;bin&#x2F;hadoop fs -put oozie-apps&#x2F;</span><br><span class="line">&#x2F;user&#x2F;red</span><br></pre></td></tr></table></figure>

<p>5）执行任务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozie job -oozie http:&#x2F;&#x2F;hadoop102:11000&#x2F;oozie -config oozie-apps&#x2F;shell&#x2F;job.properties -run</span><br></pre></td></tr></table></figure>

<p>6）杀死某个任务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozie job -oozie http:&#x2F;&#x2F;hadoop102:11000&#x2F;oozie -kill 0000004-170425105153692-oozie-z-W</span><br></pre></td></tr></table></figure>



<h2 id="4-2-案例二：Oozie逻辑调度执行多个Job"><a href="#4-2-案例二：Oozie逻辑调度执行多个Job" class="headerlink" title="4.2 案例二：Oozie逻辑调度执行多个Job"></a>4.2 案例二：Oozie逻辑调度执行多个Job</h2><p>目标：使用Oozie执行多个Job调度</p>
<p>分步执行：</p>
<p>1）编辑job.properties和workflow.xml文件</p>
<p><strong>job.properties</strong></p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nameNode</span>=<span class="string">hdfs://hadoop102:8020</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobTracker</span>=<span class="string">hadoop103:8032</span></span><br><span class="line"></span><br><span class="line"><span class="attr">queueName</span>=<span class="string">default</span></span><br><span class="line"></span><br><span class="line"><span class="attr">examplesRoot</span>=<span class="string">oozie-apps</span></span><br><span class="line"></span><br><span class="line"><span class="meta">oozie.wf.application.path</span>=<span class="string">$&#123;nameNode&#125;/user/$&#123;user.name&#125;/$&#123;examplesRoot&#125;/shells</span></span><br></pre></td></tr></table></figure>

<p><strong>workflow.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">workflow-app</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:workflow:0.4"</span> <span class="attr">name</span>=<span class="string">"shells-wf"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">start</span> <span class="attr">to</span>=<span class="string">"p1-shell-node"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">action</span> <span class="attr">name</span>=<span class="string">"p1-shell-node"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">shell</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:shell-action:0.2"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">job-tracker</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="name">job-tracker</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name-node</span>&gt;</span>$&#123;nameNode&#125;<span class="tag">&lt;/<span class="name">name-node</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.queue.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">exec</span>&gt;</span>mkdir<span class="tag">&lt;/<span class="name">exec</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">argument</span>&gt;</span>/opt/software/d1<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">capture-output</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">shell</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">ok</span> <span class="attr">to</span>=<span class="string">"p2-shell-node"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">error</span> <span class="attr">to</span>=<span class="string">"fail"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">action</span> <span class="attr">name</span>=<span class="string">"p2-shell-node"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">shell</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:shell-action:0.2"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">job-tracker</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="name">job-tracker</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name-node</span>&gt;</span>$&#123;nameNode&#125;<span class="tag">&lt;/<span class="name">name-node</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.queue.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">exec</span>&gt;</span>mkdir<span class="tag">&lt;/<span class="name">exec</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">argument</span>&gt;</span>/opt/software/d2<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">capture-output</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">shell</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">ok</span> <span class="attr">to</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">error</span> <span class="attr">to</span>=<span class="string">"fail"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">kill</span> <span class="attr">name</span>=<span class="string">"fail"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">message</span>&gt;</span>Shell action failed, error</span><br><span class="line">message[$&#123;wf:errorMessage(wf:lastErrorNode())&#125;]<span class="tag">&lt;/<span class="name">message</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">kill</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">end</span> <span class="attr">name</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">workflow-app</span>&gt;</span></span><br><span class="line"></span><br><span class="line">补充：fork节点和join节点</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">fork</span> <span class="attr">name</span>=<span class="string">"forking"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">path</span> <span class="attr">start</span>=<span class="string">"firstparalleljob"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">path</span> <span class="attr">start</span>=<span class="string">"secondparalleljob"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">fork</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">join</span> <span class="attr">name</span>=<span class="string">"joining"</span> <span class="attr">to</span>=<span class="string">"nextaction"</span>/&gt;</span></span><br></pre></td></tr></table></figure>

<p>2）上传任务配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ bin&#x2F;hadoop fs -rmr &#x2F;user&#x2F;red&#x2F;oozie-apps&#x2F;</span><br><span class="line"></span><br><span class="line">$ bin&#x2F;hadoop fs -put oozie-apps&#x2F;shells &#x2F;user&#x2F;red&#x2F;oozie-apps</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>执行任务</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozie job -oozie http:&#x2F;&#x2F;hadoop102:11000&#x2F;oozie -config oozie-apps&#x2F;shells&#x2F;job.properties -run</span><br></pre></td></tr></table></figure>



<h2 id="4-3-案例三：Oozie调度MapReduce任务"><a href="#4-3-案例三：Oozie调度MapReduce任务" class="headerlink" title="4.3 案例三：Oozie调度MapReduce任务"></a>4.3 案例三：Oozie调度MapReduce任务</h2><p>目标：使用Oozie调度MapReduce任务</p>
<p>分步执行：</p>
<p>1）找到一个可以运行的mapreduce任务的jar包（可以用官方的，也可以是自己写的）</p>
<p>2）拷贝官方模板到oozie-apps</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ cp -r &#x2F;opt&#x2F;module&#x2F;oozie-4.0.0-cdh5.3.6&#x2F;examples&#x2F;apps&#x2F;map-reduce&#x2F; oozie-apps&#x2F;</span><br></pre></td></tr></table></figure>

<p><strong>3)测试一下wordcount在yarn中的运行</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;cdh&#x2F;hadoop-2.5.0-cdh5.3.6&#x2F;bin&#x2F;yarn jar</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;cdh&#x2F;hadoop-2.5.0-cdh5.3.6&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar</span><br><span class="line">wordcount &#x2F;input&#x2F; &#x2F;output&#x2F;</span><br></pre></td></tr></table></figure>

<p><strong>4) 配置map-reduce任务的job.properties以及workflow.xml</strong></p>
<p><strong>job.properties</strong></p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nameNode</span>=<span class="string">hdfs://hadoop102:8020</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobTracker</span>=<span class="string">hadoop103:8032</span></span><br><span class="line"></span><br><span class="line"><span class="attr">queueName</span>=<span class="string">default</span></span><br><span class="line"></span><br><span class="line"><span class="attr">examplesRoot</span>=<span class="string">oozie-apps</span></span><br><span class="line"></span><br><span class="line"><span class="meta">oozie.wf.application.path</span>=<span class="string">$&#123;nameNode&#125;/user/$&#123;user.name&#125;/$&#123;examplesRoot&#125;/map-reduce/workflow.xml</span></span><br></pre></td></tr></table></figure>

<p><strong>workflow.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">workflow-app</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:workflow:0.2"</span> <span class="attr">name</span>=<span class="string">"map-reduce-wf"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">start</span> <span class="attr">to</span>=<span class="string">"mr-node"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">action</span> <span class="attr">name</span>=<span class="string">"mr-node"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">map-reduce</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">job-tracker</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="name">job-tracker</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name-node</span>&gt;</span>$&#123;nameNode&#125;<span class="tag">&lt;/<span class="name">name-node</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">prepare</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">delete</span> <span class="attr">path</span>=<span class="string">"$&#123;nameNode&#125;/output/"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">prepare</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.queue.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置调度MR任务时，使用新的API --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.mapper.new-api<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.reducer.new-api<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Job Key输出类型 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.output.key.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.io.Text<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Job Value输出类型 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.output.value.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.io.IntWritable<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定输入路径 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.input.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/input/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定输出路径 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.output.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/output/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Map类 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.map.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.examples.WordCount$TokenizerMapper<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Reduce类 --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.reduce.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.examples.WordCount$IntSumReducer<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.map.tasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">map-reduce</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">ok</span> <span class="attr">to</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">error</span> <span class="attr">to</span>=<span class="string">"fail"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">kill</span> <span class="attr">name</span>=<span class="string">"fail"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">message</span>&gt;</span>Map/Reduce failed, error</span><br><span class="line">message[$&#123;wf:errorMessage(wf:lastErrorNode())&#125;]<span class="tag">&lt;/<span class="name">message</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">kill</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">end</span> <span class="attr">name</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">workflow-app</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>5）拷贝待执行的jar包到map-reduce的lib目录下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ cp -a &#x2F;opt</span><br><span class="line">&#x2F;module&#x2F;cdh&#x2F;hadoop-2.5.0-cdh5.3.6&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar</span><br><span class="line">oozie-apps&#x2F;map-reduce&#x2F;lib</span><br></pre></td></tr></table></figure>

<p>6）上传配置好的app文件夹到HDFS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;cdh&#x2F;hadoop-2.5.0-cdh5.3.6&#x2F;bin&#x2F;hdfs dfs -put</span><br><span class="line">oozie-apps&#x2F;map-reduce&#x2F; &#x2F;user&#x2F;admin&#x2F;oozie-apps</span><br></pre></td></tr></table></figure>

<p>7）执行任务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozie job -oozie</span><br><span class="line">http:&#x2F;&#x2F;hadoop102:11000&#x2F;oozie -config</span><br><span class="line">oozie-apps&#x2F;map-reduce&#x2F;job.properties -run</span><br></pre></td></tr></table></figure>



<h2 id="4-4-案例四：Oozie定时任务-循环任务"><a href="#4-4-案例四：Oozie定时任务-循环任务" class="headerlink" title="4.4 案例四：Oozie定时任务/循环任务"></a>4.4 案例四：Oozie定时任务/循环任务</h2><p>目标：Coordinator定时的周期性调度任务</p>
<p>分步实现：</p>
<ol>
<li><p>配置Linux时区以及时间服务器</p>
</li>
<li><p>检查系统当前时区：</p>
</li>
</ol>
<blockquote>
<h1 id="date-R"><a href="#date-R" class="headerlink" title="date -R"></a>date -R</h1></blockquote>
<p>注意：如果显示的时区不是+0800，删除localtime文件夹后，再关联一个正确时区的链接过去，命令如下：</p>
<blockquote>
<h1 id="rm-rf-etc-localtime"><a href="#rm-rf-etc-localtime" class="headerlink" title="rm -rf /etc/localtime"></a>rm -rf /etc/localtime</h1><p>ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</p>
</blockquote>
<p>同步时间：</p>
<blockquote>
<p>ntpdate pool.ntp.org</p>
</blockquote>
<p>修改NTP配置文件：</p>
<blockquote>
<p>vi /etc/ntp.conf</p>
</blockquote>
<p>去掉下面这行前面的# ,并把网段修改成自己的网段：</p>
<blockquote>
<p>restrict 192.168.122.0 mask 255.255.255.0 nomodify notrap</p>
</blockquote>
<p>注释掉以下几行：</p>
<blockquote>
<p>#server 0.centos.pool.ntp.org</p>
<p>#server 1.centos.pool.ntp.org</p>
<p>#server 2.centos.pool.ntp.org</p>
</blockquote>
<p>把下面两行前面的#号去掉,如果没有这两行内容,需要手动添加</p>
<blockquote>
<p>server 127.127.1.0 # local clock</p>
<p>fudge 127.127.1.0 stratum 10</p>
</blockquote>
<p>重启NTP服务：</p>
<blockquote>
<p>systemctl start ntpd.service，</p>
</blockquote>
<p>注意，如果是centOS7以下的版本，使用命令：service ntpd start</p>
<blockquote>
<p>systemctl enable ntpd.service，</p>
</blockquote>
<p>注意，如果是centOS7以下的版本，使用命令：chkconfig ntpd on</p>
<p>集群其他节点去同步这台时间服务器时间：</p>
<p>首先需要关闭这两台计算机的ntp服务</p>
<blockquote>
<p>systemctl stop ntpd.service，</p>
</blockquote>
<p>centOS7以下，则：service ntpd stop</p>
<blockquote>
<p>systemctl disable ntpd.service，</p>
</blockquote>
<p>centOS7以下，则：chkconfig ntpd off</p>
<blockquote>
<p>systemctl status ntpd，查看ntp服务状态</p>
<p>pgrep ntpd，查看ntp服务进程id</p>
</blockquote>
<p>同步第一台服务器linux01的时间：</p>
<blockquote>
<p>ntpdate hadoop102</p>
</blockquote>
<p>使用root用户制定计划任务,周期性同步时间：</p>
<blockquote>
<p>crontab -e */10 * * * * /usr/sbin/ntpdate hadoop102</p>
</blockquote>
<p>重启定时任务：</p>
<blockquote>
<p>systemctl restart crond.service，</p>
</blockquote>
<p>centOS7以下使用：service crond restart，</p>
<p>其他台机器的配置同理。</p>
<ol start="3">
<li>配置 oozie-site.xml文件</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">属性：oozie.processing.timezone</span><br><span class="line"></span><br><span class="line">属性值：GMT+0800</span><br></pre></td></tr></table></figure>

<p>解释：修改时区为东八区区时</p>
<p>注：该属性去oozie-default.xml中找到即可</p>
<ol start="4">
<li>修改js框架中的关于时间设置的代码(页面修改以后，省略此步骤，建议在页面修改)</li>
</ol>
<blockquote>
<p>$ vi<br>/opt/module/oozie-4.0.0-cdh5.3.6/oozie-server/webapps/oozie/oozie-console.js</p>
</blockquote>
<p>修改如下：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getTimeZone</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">Ext.state.Manager.setProvider(<span class="keyword">new</span> Ext.state.CookieProvider());</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> Ext.state.Manager.get(<span class="string">"TimezoneId"</span>,<span class="string">"GMT"</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>5）重启oozie服务，并重启浏览器（一定要注意清除缓存）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozied.sh stop</span><br><span class="line"></span><br><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozied.sh start</span><br></pre></td></tr></table></figure>

<p>6）拷贝官方模板配置定时任务</p>
<blockquote>
<p>$ cp -r examples/apps/cron/ oozie-apps/</p>
</blockquote>
<p>7）修改模板job.properties和coordinator.xml以及workflow.xml</p>
<p><strong>job.properties</strong></p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">pnameNode</span>=<span class="string">hdfs://hadoop102:8020</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobTracker</span>=<span class="string">hadoop103:8032</span></span><br><span class="line"></span><br><span class="line"><span class="attr">queueName</span>=<span class="string">default</span></span><br><span class="line"></span><br><span class="line"><span class="attr">examplesRoot</span>=<span class="string">oozie-apps</span></span><br><span class="line"></span><br><span class="line"><span class="meta">oozie.coord.application.path</span>=<span class="string">$&#123;nameNode&#125;/user/$&#123;user.name&#125;/$&#123;examplesRoot&#125;/cron</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#start：必须设置为未来时间，否则任务失败</span></span><br><span class="line"></span><br><span class="line"><span class="attr">start</span>=<span class="string">2019-11-01T11:05+0800</span></span><br><span class="line"></span><br><span class="line"><span class="attr">end</span>=<span class="string">2019-11-01T12:05+0800</span></span><br><span class="line"><span class="attr">workflowAppUri</span>=<span class="string">$&#123;nameNode&#125;/user/$&#123;user.name&#125;/$&#123;examplesRoot&#125;/cron</span></span><br></pre></td></tr></table></figure>

<p><strong>coordinator.xml（最小频率5分钟）</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">coordinator-app</span> <span class="attr">name</span>=<span class="string">"cron-coord"</span> <span class="attr">frequency</span>=<span class="string">"$&#123;coord:minutes(5)&#125;"</span></span></span><br><span class="line"><span class="tag"><span class="attr">start</span>=<span class="string">"$&#123;start&#125;"</span> <span class="attr">end</span>=<span class="string">"$&#123;end&#125;"</span> <span class="attr">timezone</span>=<span class="string">"GMT+0800"</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns</span>=<span class="string">"uri:oozie:coordinator:0.2"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">action</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">workflow</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">app-path</span>&gt;</span>$&#123;workflowAppUri&#125;<span class="tag">&lt;/<span class="name">app-path</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>jobTracker<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>nameNode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;nameNode&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>queueName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">workflow</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">coordinator-app</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>workflow.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">workflow-app</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:workflow:0.5"</span> <span class="attr">name</span>=<span class="string">"one-op-wf"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">start</span> <span class="attr">to</span>=<span class="string">"shell-node"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">action</span> <span class="attr">name</span>=<span class="string">"shell-node"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">shell</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:shell-action:0.2"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">job-tracker</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="name">job-tracker</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name-node</span>&gt;</span>$&#123;nameNode&#125;<span class="tag">&lt;/<span class="name">name-node</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.queue.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">exec</span>&gt;</span>p1.sh<span class="tag">&lt;/<span class="name">exec</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">capture-output</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">shell</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">ok</span> <span class="attr">to</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">error</span> <span class="attr">to</span>=<span class="string">"fail"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">kill</span> <span class="attr">name</span>=<span class="string">"fail"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">message</span>&gt;</span>Shell action failed, error</span><br><span class="line">message[$&#123;wf:errorMessage(wf:lastErrorNode())&#125;]<span class="tag">&lt;/<span class="name">message</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">kill</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">end</span> <span class="attr">name</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">workflow-app</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>8）上传配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;cdh&#x2F;hadoop-2.5.0-cdh5.3.6&#x2F;bin&#x2F;hdfs dfs -put oozie-apps&#x2F;cron&#x2F;</span><br><span class="line">&#x2F;user&#x2F;red&#x2F;oozie-apps</span><br></pre></td></tr></table></figure>

<p>9）启动任务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 oozie-4.0.0-cdh5.3.6]$ bin&#x2F;oozie job -oozie</span><br><span class="line">http:&#x2F;&#x2F;hadoop102:11000&#x2F;oozie -config oozie-apps&#x2F;cron&#x2F;job.properties -run</span><br></pre></td></tr></table></figure>

<p>注意：oozie允许的最小执行任务的频率是5分钟</p>
<h1 id="第5章-常见问题总结"><a href="#第5章-常见问题总结" class="headerlink" title="第5章 常见问题总结"></a>第5章 常见问题总结</h1><p>1）Mysql权限配置</p>
<p>授权所有主机可以使用root用户操作所有数据库和数据表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; grant all on *.* to root@&#39;%&#39; identified by &#39;123456;</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line"></span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure>

<p>2）workflow.xml配置的时候不要忽略file属性</p>
<p>3）jps查看进程时，注意有没有bootstrap</p>
<p>4）关闭oozie</p>
<p>如果bin/oozied.sh stop无法关闭，则可以使用kill -9<br>[pid]，之后oozie-server/temp/xxx.pid文件一定要删除。</p>
<p>5）Oozie重新打包时，一定要注意先关闭进程，删除对应文件夹下面的pid文件。（可以参考第4条目）</p>
<p>6）配置文件一定要生效</p>
<p>起始标签和结束标签无对应则不生效，配置文件的属性写错了，那么则执行默认的属性。</p>
<p>7）libext下边的jar存放于某个文件夹中，导致share/lib创建不成功。</p>
<p>8）调度任务时，找不到指定的脚本，可能是oozie-site.xml里面的Hadoop配置文件没有关联上。</p>
<p>9）修改Hadoop配置文件，需要重启集群。一定要记得scp到其他节点。</p>
<p>10）JobHistoryServer必须开启，集群要重启的。</p>
<p>11）Mysql配置如果没有生效的话，默认使用derby数据库。</p>
<p>12）在本地修改完成的job配置，必须重新上传到HDFS。</p>
<p>13）将HDFS中上传的oozie配置文件下载下来查看是否有错误。</p>
<p>14）Linux用户名和Hadoop的用户名不一致。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-my-test-blog" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/06/my-test-blog/" class="article-date">
      <time datetime="2020-09-05T17:19:45.000Z" itemprop="datePublished">2020-09-06</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/06/my-test-blog/">my test blog</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>就是试一下联网 一直都是单机23333333</p>
<p>看看有没有成功！</p>
<p>————刚刚tags忘空格了，再来一次————</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B0%9D%E8%AF%95/" rel="tag">尝试</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Sockecket入门介绍" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/08/26/Sockecket%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/" class="article-date">
      <time datetime="2020-08-26T04:38:42.000Z" itemprop="datePublished">2020-08-26</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/08/26/Sockecket%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/">Socket入门介绍</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>下面进行MS-Windows、HP-Unix网络编程的实践过程中总结出来的一些经验，仅供大家参考。本文所谈到的Socket函数如果没有特别说明，都是指的Windows Socket API。</p>
<h1 id="Socket-API简介"><a href="#Socket-API简介" class="headerlink" title="Socket API简介"></a>Socket API简介</h1><p>Windows Socket是从UNIX Socket继承发展而来，最新的版本是2.2。进行Windows网络编程，需要在程序中包含WINSOCK2.H或MSWSOCK.H，同时需要添加引入库WS2_32. LIB或WSOCK32.LIB。</p>
<p>网络中用一个三元组可以在全局唯一标志一个进程： （协议，本地地址，本地端口号） ，这样一个三元组，叫做一个半相关（half-association），它指定连接的每半部分。 </p>
<h1 id="套接字类型"><a href="#套接字类型" class="headerlink" title="套接字类型"></a>套接字类型</h1><p>TCP/IP的socket提供下列三种类型套接字。 </p>
<h2 id="流式套接字（SOCK-STREAM）"><a href="#流式套接字（SOCK-STREAM）" class="headerlink" title="流式套接字（SOCK_STREAM）"></a>流式套接字（SOCK_STREAM）</h2><p>提供了一个面向连接、可靠的数据传输服务，数据无差错、无重复地发送，且按发送顺序接收。内设流量控制，避免数据流超限；数据被看作是字节流，无长度限制。文件传送协议（FTP）即使用流式套接字。 </p>
<h2 id="数据报式套接字（SOCK-DGRAM）"><a href="#数据报式套接字（SOCK-DGRAM）" class="headerlink" title="数据报式套接字（SOCK_DGRAM）"></a>数据报式套接字（SOCK_DGRAM）</h2><p>提供了一个无连接服务。数据包以独立包形式被发送，不提供无错保证，数据可能丢失或重复，并且接收顺序混乱。网络文件系统（NFS）使用数据报式套接字。 </p>
<h2 id="原始式套接字（SOCK-RAW）"><a href="#原始式套接字（SOCK-RAW）" class="headerlink" title="原始式套接字（SOCK_RAW）"></a>原始式套接字（SOCK_RAW）</h2><p>该接口允许对较低层协议，如IP、ICMP直接访问。常用于检验新的协议实现或访问现有服务中配置的新设备。 </p>
<h3 id="一、WSAStartup函数"><a href="#一、WSAStartup函数" class="headerlink" title="一、WSAStartup函数"></a>一、WSAStartup函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">WSAStartup</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">WORD wVersionRequested,         <span class="comment">//使用的Socket版本</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">LPWSADATA lpWSAData         <span class="comment">//返回请求的Socket的版本信息</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>使用Socket的程序在使用Socket之前必须调用WSAStartup函数。该函数的第一个参数指明程序请求使用的Socket版本，其中高位字节指明副版本、低位字节指明主版本；操作系统利用第二个参数返回请求的Socket的版本信息。当一个应用程序调用WSAStartup函数时，操作系统根据请求的Socket版本来搜索相应的Socket库，然后绑定找到的Socket库到该应用程序中。以后应用程序就可以调用所请求的Socket库中的其它Socket函数了。该函数执行成功后返回0。</p>
<p>例：假如一个程序要使用2.1版本的Socket,那么程序代码如下</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wVersionRequested = MAKEWORD( <span class="number">2</span>, <span class="number">1</span> ); </span><br><span class="line"></span><br><span class="line">err = WSAStartup( wVersionRequested, &amp;wsaData );</span><br></pre></td></tr></table></figure>



<h3 id="二、WSACleanup函数"><a href="#二、WSACleanup函数" class="headerlink" title="二、WSACleanup函数"></a>二、WSACleanup函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">WSACleanup</span> <span class="params">(<span class="keyword">void</span>)</span></span>;</span><br></pre></td></tr></table></figure>

<p>应用程序在完成对请求的Socket库的使用后，要调用WSACleanup函数来解除与Socket库的绑定并且释放Socket库所占用的系统资源。 </p>
<h3 id="三、socket函数"><a href="#三、socket函数" class="headerlink" title="三、socket函数"></a>三、socket函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">SOCKET <span class="title">socket</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> af,          <span class="comment">//指定应用程序使用的通信协议的协议族，对于TCP/IP协议族，该参数置AF_INET; UNIX系统支持的地址族有：AF_UNIX、AF_INET、AF_NS等，而DOS、WINDOWS中仅支持AF_INET，它是网际网区域。</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> type,         <span class="comment">//套接字类型</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> protocol        <span class="comment">//应用程序所使用的通信协议</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>应用程序调用socket函数来创建一个能够进行网络通信的套接字。第一个参数指定应用程序使用的通信协议的协议族，对于TCP/IP协议族，该参数置PF_INET;第二个参数指定要创建的套接字类型，流套接字类型为SOCK_STREAM、数据报套接字类型为SOCK_DGRAM；第三个参数指定应用程序所使用的通信协议。该函数如果调用成功就返回新创建的套接字的描述符，如果失败就返回INVALID_SOCKET。套接字描述符是一个整数类型的值。每个进程的进程空间里都有一个套接字描述符表，该表中存放着套接字描述符和套接字数据结构的对应关系。该表中有一个字段存放新创建的套接字的描述符，另一个字段存放套接字数据结构的地址，因此根据套接字描述符就可以找到其对应的套接字数据结构。每个进程在自己的进程空间里都有一个套接字描述符表但是套接字数据结构都是在操作系统的内核缓冲里。下面是一个创建流套接字的例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">struct</span> <span class="title">protoent</span> *<span class="title">ppe</span>;</span> </span><br><span class="line"></span><br><span class="line">ppe=getprotobyname(<span class="string">"tcp"</span>); </span><br><span class="line"></span><br><span class="line">SOCKET ListenSocket=socket(PF_INET,SOCK_STREAM,ppe-&gt;p_proto);</span><br></pre></td></tr></table></figure>



<h3 id="四、closesocket函数"><a href="#四、closesocket函数" class="headerlink" title="四、closesocket函数"></a>四、closesocket函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">closesocket</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">SOCKET s </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>closesocket函数用来关闭一个描述符为s的套接字。由于每个进程中都有一个套接字描述符表，表中的每个套接字描述符都对应了一个位于操作系统缓冲区中的套接字数据结构，因此有可能有几个套接字描述符指向同一个套接字数据结构。套接字数据结构中专门有一个字段存放该结构的被引用次数，即有多少个套接字描述符指向该结构。当调用closesocket函数时，操作系统先检查套接字数据结构中的该字段的值，如果为1，就表明只有一个套接字描述符指向它，因此操作系统就先把s在套接字描述符表中对应的那条表项清除，并且释放s对应的套接字数据结构；如果该字段大于1，那么操作系统仅仅清除s在套接字描述符表中的对应表项，并且把s对应的套接字数据结构的引用次数减1。 </p>
<p>closesocket函数如果执行成功就返回0，否则返回SOCKET_ERROR。 </p>
<h3 id="五、send函数"><a href="#五、send函数" class="headerlink" title="五、send函数"></a>五、send函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">send</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">SOCKET s,                   <span class="comment">//指定发送端套接字描述符</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> <span class="keyword">char</span> FAR *buf,         <span class="comment">//一个存放应用程序要发送数据的缓冲区</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> len,              <span class="comment">//实际要发送的数据的字节数</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> flags </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>不论是客户还是服务器应用程序都用send函数来向TCP连接的另一端发送数据。客户程序一般用send函数向服务器发送请求，而服务器则通常用send函数来向客户程序发送应答。该函数的第一个参数指定发送端套接字描述符；第二个参数指明一个存放应用程序要发送数据的缓冲区；第三个参数指明实际要发送的数据的字节数；第四个参数一般置0。这里只描述同步Socket的send函数的执行流程。当调用该函数时，send先比较待发送数据的长度len和套接字s的发送缓冲区的长度，如果len大于s的发送缓冲区的长度，该函数返回SOCKET_ERROR；如果len小于或者等于s的发送缓冲区的长度，那么send先检查协议是否正在发送s的发送缓冲中的数据，如果是就等待协议把数据发送完，如果协议还没有开始发送s的发送缓冲中的数据或者s的发送缓冲中没有数据，那么send就比较s的发送缓冲区的剩余空间和len，如果len大于剩余空间大小send就一直等待协议把s的发送缓冲中的数据发送完，如果len小于剩余空间大小send就仅仅把buf中的数据copy到剩余空间里（注意并不是send把s的发送缓冲中的数据传到连接的另一端的，而是协议传的，send仅仅是把buf中的数据copy到s的发送缓冲区的剩余空间里）。如果send函数copy数据成功，就返回实际copy的字节数，如果send在copy数据时出现错误，那么send就返回SOCKET_ERROR；如果send在等待协议传送数据时网络断开的话，那么send函数也返回SOCKET_ERROR。要注意send函数把buf中的数据成功copy到s的发送缓冲的剩余空间里后它就返回了，但是此时这些数据并不一定马上被传到连接的另一端。如果协议在后续的传送过程中出现网络错误的话，那么下一个Socket函数就会返回SOCKET_ERROR。（每一个除send外的Socket函数在执行的最开始总要先等待套接字的发送缓冲中的数据被协议传送完毕才能继续，如果在等待时出现网络错误，那么该Socket函数就返回SOCKET_ERROR）<br>注意：在Unix系统下，如果send在等待协议传送数据时网络断开的话，调用send的进程会接收到一个SIGPIPE信号，进程对该信号的默认处理是进程终止。 </p>
<h3 id="六、recv函数"><a href="#六、recv函数" class="headerlink" title="六、recv函数"></a>六、recv函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">recv</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">SOCKET s, </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">char</span> FAR *buf, </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> len, </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> flags </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>不论是客户还是服务器应用程序都用recv函数从TCP连接的另一端接收数据。该函数的第一个参数指定接收端套接字描述符；第二个参数指明一个缓冲区，该缓冲区用来存放recv函数接收到的数据；第三个参数指明buf的长度；第四个参数一般置0。这里只描述同步Socket的recv函数的执行流程。当应用程序调用recv函数时，recv先等待s的发送缓冲中的数据被协议传送完毕，如果协议在传送s的发送缓冲中的数据时出现网络错误，那么recv函数返回SOCKET_ERROR，如果s的发送缓冲中没有数据或者数据被协议成功发送完毕后，recv先检查套接字s的接收缓冲区，如果s接收缓冲区中没有数据或者协议正在接收数据，那么recv就一直等待，只到协议把数据接收完毕。当协议把数据接收完毕，recv函数就把s的接收缓冲中的数据copy到buf中（注意协议接收到的数据可能大于buf的长度，所以在这种情况下要调用几次recv函数才能把s的接收缓冲中的数据copy完。recv函数仅仅是copy数据，真正的接收数据是协议来完成的），recv函数返回其实际copy的字节数。如果recv在copy时出错，那么它返回SOCKET_ERROR；如果recv函数在等待协议接收数据时网络中断了，那么它返回0。 </p>
<p>注意：在Unix系统下，如果recv函数在等待协议接收数据时网络断开了，那么调用recv的进程会接收到一个SIGPIPE信号，进程对该信号的默认处理是进程终止。 </p>
<h3 id="七、bind函数"><a href="#七、bind函数" class="headerlink" title="七、bind函数"></a>七、bind函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">bind</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">SOCKET s, </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> struct sockaddr FAR *name, </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> namelen </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>当创建了一个Socket以后，套接字数据结构中有一个默认的IP地址和默认的端口号。一个服务程序必须调用bind函数来给其绑定一个IP地址和一个特定的端口号。客户程序一般不必调用bind函数来为其Socket绑定IP地址和断口号。该函数的第一个参数指定待绑定的Socket描述符；第二个参数指定一个sockaddr结构，该结构是这样定义的： </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr</span> &#123;</span></span><br><span class="line"></span><br><span class="line">u_short sa_family;            <span class="comment">//地址族 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> sa_data[<span class="number">14</span>];             <span class="comment">// 14字节协议地址</span></span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>sa_family指定地址族，对于TCP/IP协议族的套接字，给其置AF_INET。当对TCP/IP协议族的套接字进行绑定时，我们通常使用另一个地址结构：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> &#123;</span>          <span class="comment">// ("in" 代表 "Internet"。)</span></span><br><span class="line"></span><br><span class="line">short sin_family; </span><br><span class="line"></span><br><span class="line">u_short sin_port;         <span class="comment">// 16位端口号，网络字节顺序</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">in_addr</span> <span class="title">sin_addr</span>;</span>       <span class="comment">// 32位IP地址，网络字节顺序</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> sin_zero[<span class="number">8</span>];          <span class="comment">//保留</span></span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其中sin_family置AF_INET；sin_port指明端口号；sin_addr结构体中只有一个唯一的字段s_addr，表示IP地址，该字段是一个整数，一般用函数inet_addr（）把字符串形式的IP地址转换成unsigned long型的整数值后再置给s_addr。有的服务器是多宿主机，至少有两个网卡，那么运行在这样的服务器上的服务程序在为其Socket绑定IP地址时可以把htonl(INADDR_ANY)置给s_addr，这样做的好处是不论哪个网段上的客户程序都能与该服务程序通信；如果只给运行在多宿主机上的服务程序的Socket绑定一个固定的IP地址，那么就只有与该IP地址处于同一个网段上的客户程序才能与该服务程序通信。我们用0来填充sin_zero数组，目的是让sockaddr_in结构的大小与sockaddr结构的大小一致。下面是一个bind函数调用的例子： </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">saddr</span>； </span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">saddr</span>.<span class="title">sin_family</span> = <span class="title">AF_INET</span>;</span> </span><br><span class="line"></span><br><span class="line">saddr.sin_port = htons(<span class="number">8888</span>);     <span class="comment">// Host to Network Short</span></span><br><span class="line"></span><br><span class="line">saddr.sin_addr.s_addr = htonl(INADDR_ANY); <span class="comment">//使用htonl将IP地址转换为网络格式，INADDR_ANY自动填上它所运行的机器的 IP 地址</span></span><br><span class="line"></span><br><span class="line">bind(ListenSocket,(struct sockaddr *)&amp;saddr,<span class="keyword">sizeof</span>(saddr))；</span><br></pre></td></tr></table></figure>

<p>注意：不同的计算机存放多字节值的顺序不同，有的机器在起始地址存放低位字节（低价先存），有的存高位字节（高价先存）。为保证数据的正确性，在网络协议中须指定网络字节顺序。TCP/IP协议使用16位整数和32位整数的高价先存格式，它们均含在协议头文件中。</p>
<p>在调用 bind() 的时候，要小心的另一件事情是：不要采用小于 1024的端口号。所有小于1024的端口号都被系统保留！可以选择从1024 到65535的端口(如果它们没有被别的程序使用的话)。</p>
<h3 id="八、listen函数"><a href="#八、listen函数" class="headerlink" title="八、listen函数"></a>八、listen函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">listen</span><span class="params">( SOCKET s, <span class="keyword">int</span> backlog )</span></span>;</span><br></pre></td></tr></table></figure>

<p>服务程序可以调用listen函数使其流套接字s处于监听状态。处于监听状态的流套接字s将维护一个客户连接请求队列，该队列最多容纳backlog个客户连接请求。假如该函数执行成功，则返回0；如果执行失败，则返回SOCKET_ERROR。 </p>
<h3 id="九、accept函数"><a href="#九、accept函数" class="headerlink" title="九、accept函数"></a>九、accept函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">SOCKET <span class="title">accept</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">SOCKET s, </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">struct sockaddr FAR *addr,          <span class="comment">//返回新创建的套接字的地址结构</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> FAR *addrlen              <span class="comment">//新创建的套接字的地址结构的长度</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>服务程序调用accept函数从处于监听状态的流套接字s的客户连接请求队列中取出排在最前的一个客户请求，并且创建一个新的套接字来与客户套接字创建连接通道，如果连接成功，就返回新创建的套接字的描述符，以后与客户套接字交换数据的是新创建的套接字；如果失败就返回INVALID_SOCKET。该函数的第一个参数指定处于监听状态的流套接字；操作系统利用第二个参数来返回新创建的套接字的地址结构；操作系统利用第三个参数来返回新创建的套接字的地址结构的长度。下面是一个调用accept的例子： </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">ServerSocketAddr</span>;</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> addrlen; </span><br><span class="line"></span><br><span class="line">addrlen=<span class="keyword">sizeof</span>(ServerSocketAddr); </span><br><span class="line"></span><br><span class="line">ServerSocket=accept(ListenSocket,(struct sockaddr *)&amp;ServerSocketAddr,&amp;addrlen);</span><br></pre></td></tr></table></figure>



<h3 id="十、connect函数"><a href="#十、connect函数" class="headerlink" title="十、connect函数"></a>十、connect函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">connect</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">SOCKET s, </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> struct sockaddr FAR *name,</span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> namelen </span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>客户程序调用connect函数来使客户Socket s与监听于name所指定的计算机的特定端口上的服务Socket进行连接。如果连接成功，connect返回0；如果失败则返回SOCKET_ERROR。下面是一个例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">daddr</span>;</span> </span><br><span class="line"></span><br><span class="line"><span class="built_in">memset</span>((<span class="keyword">void</span> *)&amp;daddr,<span class="number">0</span>,<span class="keyword">sizeof</span>(daddr)); </span><br><span class="line"></span><br><span class="line">daddr.sin_family=AF_INET; </span><br><span class="line"></span><br><span class="line">daddr.sin_port=htons(<span class="number">8888</span>); </span><br><span class="line"></span><br><span class="line">daddr.sin_addr.s_addr=inet_addr(<span class="string">"133.197.22.4"</span>);  <span class="comment">//函数inet_addr(),将IP地址从 点数格式转换成无符号长整型， inet_addr()返回的地址已经是网络字节格式</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">connect</span>(ClientSocket,(struct sockaddr *)&amp;daddr,<span class="keyword">sizeof</span>(daddr));</span><br></pre></td></tr></table></figure>



<h1 id="实例基本步骤"><a href="#实例基本步骤" class="headerlink" title="实例基本步骤"></a>实例基本步骤</h1><p>设计一个基本的网络服务器有以下几个步骤：</p>
<p>1、初始化Windows Socket</p>
<p>2、创建一个监听的Socket</p>
<p>3、设置服务器地址信息，并将监听端口绑定到这个地址上</p>
<p>4、开始监听</p>
<p>5、接受客户端连接</p>
<p>6、和客户端通信</p>
<p>7、结束服务并清理Windows Socket和相关数据，或者返回第4步</p>
<h1 id="入门代码"><a href="#入门代码" class="headerlink" title="入门代码"></a>入门代码</h1><p>下面是简单的服务器和客户端源代码。（阻塞模式下的，供初学者理解）</p>
<h3 id="TCPServer"><a href="#TCPServer" class="headerlink" title="TCPServer"></a>TCPServer</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;winsock2.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  WSADATA        wsaData;</span><br><span class="line"></span><br><span class="line">  SOCKET        ListeningSocket;</span><br><span class="line"></span><br><span class="line">  SOCKET        NewConnection;</span><br><span class="line"></span><br><span class="line">  SOCKADDR_IN      ServerAddr;</span><br><span class="line"></span><br><span class="line">  SOCKADDR_IN      ClientAddr;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span>          Port = <span class="number">5150</span>;</span><br><span class="line"></span><br><span class="line">  WSAStartup(MAKEWORD(<span class="number">2</span>,<span class="number">2</span>), &amp;wsaData); <span class="comment">// 初始化Windows Socket 2.2</span></span><br><span class="line"></span><br><span class="line">  ListeningSocket = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); <span class="comment">// 创建一个新的Socket来响应客户端的连接请求</span></span><br><span class="line"></span><br><span class="line">  ServerAddr.sin_family = AF_INET; <span class="comment">// 填写服务器地址信息</span></span><br><span class="line"></span><br><span class="line">  ServerAddr.sin_port = htons(Port);   <span class="comment">// 端口为5150</span></span><br><span class="line"></span><br><span class="line">  ServerAddr.sin_addr.s_addr = htonl(INADDR_ANY); <span class="comment">// IP地址为INADDR_ANY，注意使用htonl将IP地址转换为网络格式</span></span><br><span class="line"></span><br><span class="line">  bind(ListeningSocket, (SOCKADDR *)&amp;ServerAddr, <span class="keyword">sizeof</span>(ServerAddr)); <span class="comment">// 绑定监听端口 listen(ListeningSocket, 5); // 开始监听，指定最大同时连接数为5 </span></span><br><span class="line"></span><br><span class="line">  NewConnection = accept(ListeningSocket, (SOCKADDR *) &amp;ClientAddr,&amp;ClientAddrLen)); <span class="comment">// 接受新的连接</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 新的连接建立后，就可以互相通信了，在这个简单的例子中，我们直接关闭连接，</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 并关闭监听Socket，然后退出应用程序</span></span><br><span class="line"></span><br><span class="line">  closesocket(NewConnection);</span><br><span class="line"></span><br><span class="line">  closesocket(ListeningSocket);</span><br><span class="line"></span><br><span class="line">  WSACleanup();<span class="comment">// 释放Windows Socket DLL的相关资源</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="TCPClient"><a href="#TCPClient" class="headerlink" title="TCPClient"></a>TCPClient</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;winsock2.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  WSADATA        wsaData;</span><br><span class="line"></span><br><span class="line">  SOCKET        s;</span><br><span class="line"></span><br><span class="line">  SOCKADDR_IN      ServerAddr;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span>          Port = <span class="number">5150</span>;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">  WSAStartup(MAKEWORD(<span class="number">2</span>,<span class="number">2</span>), &amp;wsaData);  <span class="comment">//初始化Windows Socket 2.2</span></span><br><span class="line"></span><br><span class="line">  s = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);  <span class="comment">// 创建一个新的Socket来连接服务器</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 填写客户端地址信息</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 端口为5150</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 服务器IP地址为"136.149.3.29"，注意使用inet_addr将IP地址转换为网络格式</span></span><br><span class="line"></span><br><span class="line">  ServerAddr.sin_family = AF_INET;</span><br><span class="line"></span><br><span class="line">   ServerAddr.sin_port = htons(Port);   </span><br><span class="line"></span><br><span class="line">   ServerAddr.sin_addr.s_addr = inet_addr(<span class="string">"136.149.3.29"</span>);</span><br><span class="line"></span><br><span class="line">   <span class="built_in">connect</span>(s, (SOCKADDR *) &amp;ServerAddr, <span class="keyword">sizeof</span>(ServerAddr));    <span class="comment">// 向服务器发出连接请求</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 新的连接建立后，就可以互相通信了，在这个简单的例子中，我们直接关闭连接，</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 并关闭监听Socket，然后退出应用程序</span></span><br><span class="line"></span><br><span class="line">   closesocket(s);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 释放Windows Socket DLL的相关资源</span></span><br><span class="line"></span><br><span class="line">   WSACleanup();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/computernetwork/">计算机网络</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/socket/" rel="tag">socket</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-SparkStreaming" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/11/SparkStreaming/" class="article-date">
      <time datetime="2020-03-11T08:45:00.000Z" itemprop="datePublished">2020-03-11</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/11/SparkStreaming/">SparkStreaming</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><img src="/2020/03/11/SparkStreaming/SparkStreaming-logo.jpg" alt="SparkStreaming-logo"></p>
<p>[TOC]</p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Spark Streaming是微批次处理方式，批处理间隔是Spark Streaming是的核心概念和关键参数。</p>
<p>Spark Streaming需要单独一个节点来接收数据，所以Spark Streaming 至少需要两个节点才能运行</p>
<h2 id="Spark-Streaming是什么"><a href="#Spark-Streaming是什么" class="headerlink" title="Spark Streaming是什么"></a>Spark Streaming是什么</h2><p>Spark流使得构建可扩展的容错流应用程序变得更加容易。</p>
<p>Spark Streaming用于流式数据的处理。Spark Streaming支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ和简单的TCP套接字等等。数据输入后可以用Spark的高度抽象原语如：map、reduce、join、window等进行运算。而结果也能保存在很多地方，如HDFS，数据库等。</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming%E5%9B%BE.jpg" alt="SparkStreaming图"></p>
<p>和Spark基于RDD的概念很相似，Spark Streaming使用离散化流(discretized stream)作为抽象表示，叫作DStream。DStream 是随时间推移而收到的数据的序列。<strong>在内部，每个时间区间收到的数据都作为 RDD 存在，而DStream是由这些RDD所组成的序列(因此得名“离散化”)。</strong></p>
<p>离散流反义词就是连续流。</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming%E5%9B%BE%E8%A7%A3.png" alt="SparkStreaming图解"></p>
<h2 id="Spark-Streaming的特点"><a href="#Spark-Streaming的特点" class="headerlink" title="Spark Streaming的特点"></a>Spark Streaming的特点</h2><p><strong>易用</strong></p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming5.jpg" alt="SparkStreaming5"></p>
<p><strong>容错</strong></p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming6.jpg" alt="SparkStreaming6"></p>
<p> <strong>易整合到Spark体系</strong><img src="/2020/03/11/SparkStreaming/SparkStreaming7.jpg" alt="SparkStreaming7"></p>
<h2 id="Spark-Streaming架构"><a href="#Spark-Streaming架构" class="headerlink" title="Spark Streaming架构"></a>Spark Streaming架构</h2><p>最基本的架构：底层就是spark-core。数据采集和封装之后传给Driver，Driver拿到相应的RDD，再形成一个一个Task然后传给Executor执行。。</p>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p> 整体架构图</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming8.jpg" alt="SparkStreaming8"></p>
<p>​                                        spark1.5之前</p>
<p><img src="/2020/03/11/SparkStreaming/spark1.5%E4%B9%8B%E5%90%8E%E6%9E%B6%E6%9E%84.png" alt="spark1.5之后架构"></p>
<p>​                                       spark1.5之后</p>
<p>SparkStreaming架构图</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming9.jpg" alt="SparkStreaming9"></p>
<h3 id="背压机制"><a href="#背压机制" class="headerlink" title="背压机制"></a>背压机制</h3><p>背压(back pressure)机制主要用于解决流处理系统中，业务流量在短时间内剧增，造成巨大的流量毛刺，数据流入速度远高于数据处理速度，对流处理系统构成巨大的负载压力的问题。</p>
<p>如果不能处理流量毛刺或者持续的数据过高速率输入，可能导致Executor端出现OOM的情况或者任务崩溃。</p>
<h4 id="Spark-1-5以前版本"><a href="#Spark-1-5以前版本" class="headerlink" title="Spark 1.5以前版本"></a>Spark 1.5以前版本</h4><p>用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“spark.streaming.receiver.maxRate”的值来实现（限制每个receiver没每秒最大可以接收的数据量）。此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。</p>
<p>direct-approach方式接收数据，可以配置 “spark.streaming.kafka.maxRatePerPartition”参数来限制每个kafka分区最多读取的数据量。</p>
<p>缺点：</p>
<p>​          1、实现需要进行压测，来设置最大值。参数的设置必须合理，如果集群处理能力高于配置的速率，则会造成资源的浪费。</p>
<p>​          2、参数需要手动设置，设置过后必须重启streaming服务。</p>
<h4 id="Spark-1-5以后版本"><a href="#Spark-1-5以后版本" class="headerlink" title="Spark 1.5以后版本"></a>Spark 1.5以后版本</h4><p>为了更好的协调数据接收速率与资源处理能力，1.5版本开始Spark Streaming可以动态控制数据接收速率来适配集群数据处理能力（能够根据当前数据量以及集群状态来预估下个批次最优速率）。背压机制（即Spark Streaming Backpressure）: 根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。</p>
<p>通过属性“spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用。</p>
<p><strong><u>以下背压机制spark1.5之后流程以及配置均摘抄自：<a href="https://blog.csdn.net/may_fly/article/details/103922862" target="_blank" rel="noopener">https://blog.csdn.net/may_fly/article/details/103922862</a></u></strong></p>
<p>新版具体流程如下：<img src="/2020/03/11/SparkStreaming/SparkStreaming3.png" alt="SparkStreaming3"></p>
<p>新版的背压机制主要通过<code>RateController</code>组件来实现。<code>RateController</code>继承了接口<code>StreamingListener</code>并实现了<code>onBatchCompleted</code>方法。</p>
<p>结合direct-approach方式的源码来理解</p>
<ol>
<li>首先创建一个kafka流。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> kafkaDStream: <span class="type">InputDStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>,<span class="type">String</span>,<span class="type">StringDecoder</span>,<span class="type">StringDecoder</span>,(<span class="type">String</span>,<span class="type">String</span>)](streamingContext, kafkaParams, getOffsets(topics,kc,kafkaParams),messageHandler)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<ol>
<li>createDirectStream方法创建并返回一个DirectKafkaInputDStream对象</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Create an input stream that directly pulls messages from Kafka Brokers</span></span><br><span class="line"><span class="comment">   * without using any receiver. This stream can guarantee that each message</span></span><br><span class="line"><span class="comment">   * from Kafka is included in transformations exactly once (see points below).</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Points to note:</span></span><br><span class="line"><span class="comment">   *  - No receivers: This stream does not use any receiver. It directly queries Kafka</span></span><br><span class="line"><span class="comment">   *  - Offsets: This does not use Zookeeper to store offsets. The consumed offsets are tracked</span></span><br><span class="line"><span class="comment">   *    by the stream itself. For interoperability with Kafka monitoring tools that depend on</span></span><br><span class="line"><span class="comment">   *    Zookeeper, you have to update Kafka/Zookeeper yourself from the streaming application.</span></span><br><span class="line"><span class="comment">   *    You can access the offsets used in each batch from the generated RDDs (see</span></span><br><span class="line"><span class="comment">   *    [[org.apache.spark.streaming.kafka.HasOffsetRanges]]).</span></span><br><span class="line"><span class="comment">   *  - Failure Recovery: To recover from driver failures, you have to enable checkpointing</span></span><br><span class="line"><span class="comment">   *    in the `StreamingContext`. The information on consumed offset can be</span></span><br><span class="line"><span class="comment">   *    recovered from the checkpoint. See the programming guide for details (constraints, etc.).</span></span><br><span class="line"><span class="comment">   *  - End-to-end semantics: This stream ensures that every records is effectively received and</span></span><br><span class="line"><span class="comment">   *    transformed exactly once, but gives no guarantees on whether the transformed data are</span></span><br><span class="line"><span class="comment">   *    outputted exactly once. For end-to-end exactly-once semantics, you have to either ensure</span></span><br><span class="line"><span class="comment">   *    that the output operation is idempotent, or use transactions to output records atomically.</span></span><br><span class="line"><span class="comment">   *    See the programming guide for more details.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param ssc StreamingContext object</span></span><br><span class="line"><span class="comment">   * @param kafkaParams Kafka &lt;a href="http://kafka.apache.org/documentation.html#configuration"&gt;</span></span><br><span class="line"><span class="comment">   *    configuration parameters&lt;/a&gt;. Requires "metadata.broker.list" or "bootstrap.servers"</span></span><br><span class="line"><span class="comment">   *    to be set with Kafka broker(s) (NOT zookeeper servers) specified in</span></span><br><span class="line"><span class="comment">   *    host1:port1,host2:port2 form.</span></span><br><span class="line"><span class="comment">   * @param fromOffsets Per-topic/partition Kafka offsets defining the (inclusive)</span></span><br><span class="line"><span class="comment">   *    starting point of the stream</span></span><br><span class="line"><span class="comment">   * @param messageHandler Function for translating each message and metadata into the desired type</span></span><br><span class="line"><span class="comment">   * @tparam K type of Kafka message key</span></span><br><span class="line"><span class="comment">   * @tparam V type of Kafka message value</span></span><br><span class="line"><span class="comment">   * @tparam KD type of Kafka message key decoder</span></span><br><span class="line"><span class="comment">   * @tparam VD type of Kafka message value decoder</span></span><br><span class="line"><span class="comment">   * @tparam R type returned by messageHandler</span></span><br><span class="line"><span class="comment">   * @return DStream of R</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createDirectStream</span></span>[</span><br><span class="line">    <span class="type">K</span>: <span class="type">ClassTag</span>,</span><br><span class="line">    <span class="type">V</span>: <span class="type">ClassTag</span>,</span><br><span class="line">    <span class="type">KD</span> &lt;: <span class="type">Decoder</span>[<span class="type">K</span>]: <span class="type">ClassTag</span>,</span><br><span class="line">    <span class="type">VD</span> &lt;: <span class="type">Decoder</span>[<span class="type">V</span>]: <span class="type">ClassTag</span>,</span><br><span class="line">    <span class="type">R</span>: <span class="type">ClassTag</span>] (</span><br><span class="line">      ssc: <span class="type">StreamingContext</span>,</span><br><span class="line">      kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</span><br><span class="line">      fromOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>],</span><br><span class="line">      messageHandler: <span class="type">MessageAndMetadata</span>[<span class="type">K</span>, <span class="type">V</span>] =&gt; <span class="type">R</span></span><br><span class="line">  ): <span class="type">InputDStream</span>[<span class="type">R</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> cleanedHandler = ssc.sc.clean(messageHandler)</span><br><span class="line">    <span class="keyword">new</span> <span class="type">DirectKafkaInputDStream</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">KD</span>, <span class="type">VD</span>, <span class="type">R</span>](</span><br><span class="line">      ssc, kafkaParams, fromOffsets, cleanedHandler)</span><br><span class="line">  &#125;</span><br><span class="line"><span class="number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152</span></span><br></pre></td></tr></table></figure>

<ol>
<li>DirectKafkaInputDStream类继承了抽象类InputDStream，并重载了rateController方法。创建了DirectKafkaRateController类，并传入了一个速率估计类。如果设置RateController.isBackPressureEnabled为true也就是开启背压则开始计算下一次的最优速率</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Asynchronously maintains &amp; sends new rate limits to the receiver through the receiver tracker.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">protected</span>[streaming] <span class="keyword">val</span> rateController: <span class="type">Option</span>[<span class="type">RateController</span>] = &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="type">RateController</span>.isBackPressureEnabled(ssc.conf)) &#123;</span><br><span class="line">      <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">DirectKafkaRateController</span>(id,</span><br><span class="line">        <span class="type">RateEstimator</span>.create(ssc.conf, context.graph.batchDuration)))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="type">None</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>

<ol>
<li>DirectKafkaRateController内部实现了一个私有类来计算速率，publish方法使用lambda表达式调用了RateController中唯一一个公有的方法onBatchCompleted获取计算结果</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A RateController to retrieve the rate from RateEstimator.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span>[streaming] <span class="class"><span class="keyword">class</span> <span class="title">DirectKafkaRateController</span>(<span class="params">id: <span class="type">Int</span>, estimator: <span class="type">RateEstimator</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">RateController</span>(<span class="params">id, estimator</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">publish</span></span>(rate: <span class="type">Long</span>): <span class="type">Unit</span> = ()</span><br><span class="line">  &#125;</span><br><span class="line"><span class="number">1234567</span></span><br></pre></td></tr></table></figure>

<ol>
<li>onBatchCompleted获取三个时间一个数据量：处理结束时间，处理时间，等待时间，当前处理数据量，并调用computeAndPublish方法计算下次最优的数据量</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onBatchCompleted</span></span>(batchCompleted: <span class="type">StreamingListenerBatchCompleted</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> elements = batchCompleted.batchInfo.streamIdToInputInfo</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">      processingEnd &lt;- batchCompleted.batchInfo.processingEndTime</span><br><span class="line">      workDelay &lt;- batchCompleted.batchInfo.processingDelay</span><br><span class="line">      waitDelay &lt;- batchCompleted.batchInfo.schedulingDelay</span><br><span class="line">      elems &lt;- elements.get(streamUID).map(_.numRecords)</span><br><span class="line">    &#125; computeAndPublish(processingEnd, elems, workDelay, waitDelay)</span><br><span class="line">  &#125;</span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>

<ol>
<li>computeAndPublish调用rateEstimator.compute方法计算速率</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Compute the new rate limit and publish it asynchronously.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">computeAndPublish</span></span>(time: <span class="type">Long</span>, elems: <span class="type">Long</span>, workDelay: <span class="type">Long</span>, waitDelay: <span class="type">Long</span>): <span class="type">Unit</span> =</span><br><span class="line">    <span class="type">Future</span>[<span class="type">Unit</span>] &#123;</span><br><span class="line">      <span class="keyword">val</span> newRate = rateEstimator.compute(time, elems, workDelay, waitDelay)</span><br><span class="line">      newRate.foreach &#123; s =&gt;</span><br><span class="line">        rateLimit.set(s.toLong)</span><br><span class="line">        publish(getLatestRate())</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Computes the number of records the stream attached to this `RateEstimator`</span></span><br><span class="line"><span class="comment">   * should ingest per second, given an update on the size and completion</span></span><br><span class="line"><span class="comment">   * times of the latest batch.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param time The timestamp of the current batch interval that just finished</span></span><br><span class="line"><span class="comment">   * @param elements The number of records that were processed in this batch</span></span><br><span class="line"><span class="comment">   * @param processingDelay The time in ms that took for the job to complete</span></span><br><span class="line"><span class="comment">   * @param schedulingDelay The time in ms that the job spent in the scheduling queue</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(</span><br><span class="line">      time: <span class="type">Long</span>,</span><br><span class="line">      elements: <span class="type">Long</span>,</span><br><span class="line">      processingDelay: <span class="type">Long</span>,</span><br><span class="line">      schedulingDelay: <span class="type">Long</span>): <span class="type">Option</span>[<span class="type">Double</span>]</span><br><span class="line"><span class="number">123456789101112131415161718192021222324252627</span></span><br></pre></td></tr></table></figure>

<ol>
<li>compute方法的具体实现，需要来看3中<code>RateEstimator.create(ssc.conf, context.graph.batchDuration)))</code>传入的RateEstimator类。由源码可知，默认调用pid速率估计器，是 <code>RateEstimator</code>的唯一实现 ，具体计算逻辑要看pid速率估计器的compute方法</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RateEstimator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Return a new `RateEstimator` based on the value of</span></span><br><span class="line"><span class="comment">   * `spark.streaming.backpressure.rateEstimator`.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The only known and acceptable estimator right now is `pid`.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @return An instance of RateEstimator</span></span><br><span class="line"><span class="comment">   * @throws IllegalArgumentException if the configured RateEstimator is not `pid`.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">create</span></span>(conf: <span class="type">SparkConf</span>, batchInterval: <span class="type">Duration</span>): <span class="type">RateEstimator</span> =</span><br><span class="line">    conf.get(<span class="string">"spark.streaming.backpressure.rateEstimator"</span>, <span class="string">"pid"</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">"pid"</span> =&gt;</span><br><span class="line">        <span class="keyword">val</span> proportional = conf.getDouble(<span class="string">"spark.streaming.backpressure.pid.proportional"</span>, <span class="number">1.0</span>)</span><br><span class="line">        <span class="keyword">val</span> integral = conf.getDouble(<span class="string">"spark.streaming.backpressure.pid.integral"</span>, <span class="number">0.2</span>)</span><br><span class="line">        <span class="keyword">val</span> derived = conf.getDouble(<span class="string">"spark.streaming.backpressure.pid.derived"</span>, <span class="number">0.0</span>)</span><br><span class="line">        <span class="keyword">val</span> minRate = conf.getDouble(<span class="string">"spark.streaming.backpressure.pid.minRate"</span>, <span class="number">100</span>)</span><br><span class="line">        <span class="keyword">new</span> <span class="type">PIDRateEstimator</span>(batchInterval.milliseconds, proportional, integral, derived, minRate)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> estimator =&gt;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s"Unknown rate estimator: <span class="subst">$estimator</span>"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="number">123456789101112131415161718192021222324</span></span><br></pre></td></tr></table></figure>

<ol>
<li>pid速率估计器的compute方法如下。具体流程不再细述，有时间举个例子推一下</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(</span><br><span class="line">      time: <span class="type">Long</span>, <span class="comment">// in milliseconds</span></span><br><span class="line">      numElements: <span class="type">Long</span>,</span><br><span class="line">      processingDelay: <span class="type">Long</span>, <span class="comment">// in milliseconds</span></span><br><span class="line">      schedulingDelay: <span class="type">Long</span> <span class="comment">// in milliseconds</span></span><br><span class="line">    ): <span class="type">Option</span>[<span class="type">Double</span>] = &#123;</span><br><span class="line">    logTrace(<span class="string">s"\ntime = <span class="subst">$time</span>, # records = <span class="subst">$numElements</span>, "</span> +</span><br><span class="line">      <span class="string">s"processing time = <span class="subst">$processingDelay</span>, scheduling delay = <span class="subst">$schedulingDelay</span>"</span>)</span><br><span class="line">    <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">      <span class="keyword">if</span> (time &gt; latestTime &amp;&amp; numElements &gt; <span class="number">0</span> &amp;&amp; processingDelay &gt; <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// in seconds, should be close to batchDuration</span></span><br><span class="line">        <span class="keyword">val</span> delaySinceUpdate = (time - latestTime).toDouble / <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// in elements/second</span></span><br><span class="line">        <span class="keyword">val</span> processingRate = numElements.toDouble / processingDelay * <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// In our system `error` is the difference between the desired rate and the measured rate</span></span><br><span class="line">        <span class="comment">// based on the latest batch information. We consider the desired rate to be latest rate,</span></span><br><span class="line">        <span class="comment">// which is what this estimator calculated for the previous batch.</span></span><br><span class="line">        <span class="comment">// in elements/second</span></span><br><span class="line">        <span class="keyword">val</span> error = latestRate - processingRate</span><br><span class="line"></span><br><span class="line">        <span class="comment">// The error integral, based on schedulingDelay as an indicator for accumulated errors.</span></span><br><span class="line">        <span class="comment">// A scheduling delay s corresponds to s * processingRate overflowing elements. Those</span></span><br><span class="line">        <span class="comment">// are elements that couldn't be processed in previous batches, leading to this delay.</span></span><br><span class="line">        <span class="comment">// In the following, we assume the processingRate didn't change too much.</span></span><br><span class="line">        <span class="comment">// From the number of overflowing elements we can calculate the rate at which they would be</span></span><br><span class="line">        <span class="comment">// processed by dividing it by the batch interval. This rate is our "historical" error,</span></span><br><span class="line">        <span class="comment">// or integral part, since if we subtracted this rate from the previous "calculated rate",</span></span><br><span class="line">        <span class="comment">// there wouldn't have been any overflowing elements, and the scheduling delay would have</span></span><br><span class="line">        <span class="comment">// been zero.</span></span><br><span class="line">        <span class="comment">// (in elements/second)</span></span><br><span class="line">        <span class="keyword">val</span> historicalError = schedulingDelay.toDouble * processingRate / batchIntervalMillis</span><br><span class="line"></span><br><span class="line">        <span class="comment">// in elements/(second ^ 2)</span></span><br><span class="line">        <span class="keyword">val</span> dError = (error - latestError) / delaySinceUpdate</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> newRate = (latestRate - proportional * error -</span><br><span class="line">                                    integral * historicalError -</span><br><span class="line">                                    derivative * dError).max(minRate)</span><br><span class="line">        logTrace(<span class="string">s""</span><span class="string">"</span></span><br><span class="line"><span class="string">            | latestRate = $latestRate, error = $error</span></span><br><span class="line"><span class="string">            | latestError = $latestError, historicalError = $historicalError</span></span><br><span class="line"><span class="string">            | delaySinceUpdate = $delaySinceUpdate, dError = $dError</span></span><br><span class="line"><span class="string">            "</span><span class="string">""</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">        latestTime = time</span><br><span class="line">        <span class="keyword">if</span> (firstRun) &#123;</span><br><span class="line">          latestRate = processingRate</span><br><span class="line">          latestError = <span class="number">0</span>D</span><br><span class="line">          firstRun = <span class="literal">false</span></span><br><span class="line">          logTrace(<span class="string">"First run, rate estimation skipped"</span>)</span><br><span class="line">          <span class="type">None</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          latestRate = newRate</span><br><span class="line">          latestError = error</span><br><span class="line">          logTrace(<span class="string">s"New rate = <span class="subst">$newRate</span>"</span>)</span><br><span class="line">          <span class="type">Some</span>(newRate)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        logTrace(<span class="string">"Rate estimation skipped"</span>)</span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="number">123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566</span></span><br></pre></td></tr></table></figure>

<ol>
<li>虽然通过这个公式计算出了一个速率，但最终的速率并不一定是计算出的结果。由代码可知，如果设置了参数spark.streaming.kafka.maxRatePerPartition，则每个分区所取数据最大量为计算出的结果以及设置参数的最小值，否则直接使用计算出的值</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span>[streaming] <span class="function"><span class="keyword">def</span> <span class="title">maxMessagesPerPartition</span></span>(</span><br><span class="line">      offsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>]): <span class="type">Option</span>[<span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>]] = &#123;</span><br><span class="line">    <span class="keyword">val</span> estimatedRateLimit = rateController.map(_.getLatestRate())</span><br><span class="line"></span><br><span class="line">    <span class="comment">// calculate a per-partition rate limit based on current lag</span></span><br><span class="line">    <span class="keyword">val</span> effectiveRateLimitPerPartition = estimatedRateLimit.filter(_ &gt; <span class="number">0</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(rate) =&gt;</span><br><span class="line">        <span class="keyword">val</span> lagPerPartition = offsets.map &#123; <span class="keyword">case</span> (tp, offset) =&gt;</span><br><span class="line">          tp -&gt; <span class="type">Math</span>.max(offset - currentOffsets(tp), <span class="number">0</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">val</span> totalLag = lagPerPartition.values.sum</span><br><span class="line"></span><br><span class="line">        lagPerPartition.map &#123; <span class="keyword">case</span> (tp, lag) =&gt;</span><br><span class="line">          <span class="keyword">val</span> backpressureRate = <span class="type">Math</span>.round(lag / totalLag.toFloat * rate)</span><br><span class="line">          tp -&gt; (<span class="keyword">if</span> (maxRateLimitPerPartition &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="type">Math</span>.min(backpressureRate, maxRateLimitPerPartition)&#125; <span class="keyword">else</span> backpressureRate)</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; offsets.map &#123; <span class="keyword">case</span> (tp, offset) =&gt; tp -&gt; maxRateLimitPerPartition &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> maxRateLimitPerPartition: <span class="type">Long</span> = context.sparkContext.getConf.getLong(</span><br><span class="line">      <span class="string">"spark.streaming.kafka.maxRatePerPartition"</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">12345678910111213141516171819202122</span></span><br></pre></td></tr></table></figure>

<p>一些相关的参数：</p>
<ol>
<li>开启背压机制：设置<strong>spark.streaming.backpressure.enabled</strong> 为true，默认为false</li>
<li>启用反压机制时每个接收器接收第一批数据的初始最大速率。默认值没有设置 <strong>spark.streaming.backpressure.initialRate</strong></li>
<li>速率估算器类，默认值为 pid ，目前 Spark 只支持这个，大家可以根据自己的需要实现 <strong>spark.streaming.backpressure.rateEstimator</strong></li>
<li>用于响应错误的权重（最后批次和当前批次之间的更改）。默认值为1，只能设置成非负值。<em>weight for response to “error” (change between last batch and this batch)</em> <strong>spark.streaming.backpressure.pid.proportional</strong></li>
<li>错误积累的响应权重，具有抑制作用（有效阻尼）。默认值为 0.2 ，只能设置成非负值。<em>weight for the response to the accumulation of error. This has a dampening effect.</em> <strong>spark.streaming.backpressure.pid.integral</strong></li>
<li>对错误趋势的响应权重。 这可能会引起 batch size 的波动，可以帮助快速增加/减少容量。默认值为0，只能设置成非负值。<em>weight for the response to the trend in error. This can cause arbitrary/noise-induced fluctuations in batch size, but can also help react quickly to increased/reduced capacity.</em> <strong>spark.streaming.backpressure.pid.derived</strong></li>
<li>可以估算的最低费率是多少。默认值为 100，只能设置成非负值。 <strong>spark.streaming.backpressure.pid.minRate</strong></li>
</ol>
<p>参考：</p>
<p><a href="https://blog.csdn.net/wangpei1949/article/details/90727805" target="_blank" rel="noopener">https://blog.csdn.net/wangpei1949/article/details/90727805</a></p>
<p><a href="https://blog.csdn.net/zengxiaosen/article/details/72822869" target="_blank" rel="noopener">https://blog.csdn.net/zengxiaosen/article/details/72822869</a></p>
<p><a href="https://www.cnblogs.com/barrenlake/p/5349949.html" target="_blank" rel="noopener">https://www.cnblogs.com/barrenlake/p/5349949.html</a></p>
<p><a href="https://www.iteblog.com/archives/2323.html?from=related" target="_blank" rel="noopener">https://www.iteblog.com/archives/2323.html?from=related</a></p>
<h1 id="Dstream入门"><a href="#Dstream入门" class="headerlink" title="Dstream入门"></a>Dstream入门</h1><h2 id="WordCount案例实操"><a href="#WordCount案例实操" class="headerlink" title="WordCount案例实操"></a>WordCount案例实操</h2><p>需求：使用netcat工具向9999端口不断的发送数据，通过SparkStreaming读取端口数据并统计不同单词出现的次数</p>
<p>1) 添加依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>2) 编写代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming_Wordcount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Todo 1.配置对象</span></span><br><span class="line">    <span class="comment">//初始化Spark配置信息</span></span><br><span class="line">    <span class="comment">//Spark Streaming需要单独一个节点来接收数据，所以Spark Streaming 至少需要两个节点才能运行（local至少要两个节点）</span></span><br><span class="line">    <span class="keyword">val</span> sparkconf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Todo 2.环境对象</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    class StreamingContext private[streaming]加了包权限（私有） 所以主构不能用</span></span><br><span class="line"><span class="comment">    def this(sparkContext: SparkContext, batchDuration: Duration) 辅助构建方法可用（Spark配置信息，批处理持续时间）</span></span><br><span class="line"><span class="comment">    case class Duration (private val millis: Long)样例类 直接用 但是不方便 要自己算毫秒</span></span><br><span class="line"><span class="comment">    new StreamingContext(sparkconf , Duration(1000 * 3))</span></span><br><span class="line"><span class="comment">    所以直接使用伴生对象Seconds()</span></span><br><span class="line"><span class="comment">     object Seconds &#123;</span></span><br><span class="line"><span class="comment">        def apply(seconds: Long): Duration = new Duration(seconds * 1000)</span></span><br><span class="line"><span class="comment">      &#125;</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 初始化SparkStreamingContext</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkconf , <span class="type">Seconds</span>(<span class="number">3</span>)) <span class="comment">// 创建对象的第二个参数表示数据的采集周期</span></span><br><span class="line">    <span class="comment">//Todo 3.数据处理</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 从数据源采集数据</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2 //内存和磁盘有两个序列化副本（socketStream默认的存储级别）</span></span><br><span class="line"><span class="comment">    ReceiverInputDStream[String]  Receiver:接收器 Input:输入  DStream:离散化流   */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span> , <span class="number">9999</span> )</span><br><span class="line">    <span class="comment">//TODO 将采集数据进行WordCount的处理</span></span><br><span class="line">    <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = socketDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map((_ , <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKey(_+_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在控制台上打印结果</span></span><br><span class="line"><span class="comment">/*    可以看出底层还是RDD</span></span><br><span class="line"><span class="comment">def print(num: Int): Unit = ssc.withScope &#123;</span></span><br><span class="line"><span class="comment">      def foreachFunc: (RDD[T], Time) =&gt; Unit = &#123;</span></span><br><span class="line"><span class="comment">        (rdd: RDD[T], time: Time) =&gt; &#123;</span></span><br><span class="line"><span class="comment">          val firstNum = rdd.take(num + 1)</span></span><br><span class="line"><span class="comment">          // scalastyle:off println</span></span><br><span class="line"><span class="comment">          println("-------------------------------------------")</span></span><br><span class="line"><span class="comment">          println(s"Time: $time")</span></span><br><span class="line"><span class="comment">          println("-------------------------------------------")</span></span><br><span class="line"><span class="comment">          firstNum.take(num).foreach(println)</span></span><br><span class="line"><span class="comment">          if (firstNum.length &gt; num) println("...")</span></span><br><span class="line"><span class="comment">          println()</span></span><br><span class="line"><span class="comment">          // scalastyle:on println</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">      &#125;</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    wordToCountDS.print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Todo 4.开启连接环境</span></span><br><span class="line">   <span class="comment">/*</span></span><br><span class="line"><span class="comment">    和spark、scala不同的是：最后并不关闭连接环境（除非程序升级或者出现故障的时候，因为数据采集是要7*24）</span></span><br><span class="line"><span class="comment">    并且不能让driver程序结束，需要让driver程序等待,等待数据处理的停止或异常时，才会继续执行</span></span><br><span class="line"><span class="comment">      def awaitTermination() &#123;</span></span><br><span class="line"><span class="comment">        waiter.waitForStopOrError()  //等待停止或者异常，如果没有停止和异常现象 程序不结束</span></span><br><span class="line"><span class="comment">      &#125;</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    ssc.start();</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>3) 启动程序并通过netcat发送数据：</p>
<blockquote>
<p>nc -lk 9999</p>
<p>hello red</p>
<p>hello world</p>
</blockquote>
<h2 id="WordCount解析"><a href="#WordCount解析" class="headerlink" title="WordCount解析"></a>WordCount解析</h2><p>Discretized Stream是Spark Streaming的基础抽象，代表持续性的数据流和经过各种Spark原语操作后的结果数据流。在内部实现上，<strong>DStream是一系列连续的RDD来表示</strong>。<u>每个RDD含有一段时间间隔内的数据（段时间内所有数据在一个RDD里）。</u><img src="/2020/03/11/SparkStreaming/SparkStreaming10.jpg" alt="SparkStreaming10"></p>
<p>对数据的操作也是按照RDD为单位来进行的</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming11.jpg" alt="SparkStreaming11"></p>
<p>计算过程由Spark Engine来完成</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming12.jpg" alt="SparkStreaming12"></p>
<h1 id="DStream创建"><a href="#DStream创建" class="headerlink" title="DStream创建"></a>DStream创建</h1><h2 id="RDD队列"><a href="#RDD队列" class="headerlink" title="RDD队列"></a>RDD队列</h2><h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue()"></a>Queue()</h3><h4 id="用法及说明"><a href="#用法及说明" class="headerlink" title="用法及说明"></a>用法及说明</h4><p><font color="red">测试过程</font>中，可以通过使用ssc.queueStream(queueOfRDDs)来创建DStream，每一个推送到这个队列中的RDD，都会作为一个DStream处理。</p>
<h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><p>需求：循环创建几个RDD，将RDD放入队列。通过SparkStream创建Dstream，计算WordCount</p>
<p>1) 编写代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RDDStream</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//1.初始化Spark配置信息</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"RDDStream"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//2.初始化SparkStreamingContext</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//3.创建RDD队列</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> rddQueue = <span class="keyword">new</span> mutable.<span class="type">Queue</span>[<span class="type">RDD</span>[<span class="type">Int</span>]]()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//4.创建QueueInputDStream</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> inputStream = ssc.queueStream(rddQueue,oneAtATime = <span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//5.处理队列中的RDD数据</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> mappedStream = inputStream.map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> reducedStream = mappedStream.reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//6.打印结果</span></span><br><span class="line"></span><br><span class="line">  reducedStream.print()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//7.启动任务</span></span><br><span class="line"></span><br><span class="line">  ssc.start()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">//8.循环创建并向RDD队列中放入RDD</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">5</span>) &#123;</span><br><span class="line"></span><br><span class="line">   rddQueue += ssc.sparkContext.makeRDD(<span class="number">1</span> to <span class="number">300</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">   <span class="type">Thread</span>.sleep(<span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2) 结果展示</p>
<blockquote>
<p>-——————————————</p>
<p>Time: 1539075280000 ms</p>
<p>-——————————————</p>
<p>(4,60)</p>
<p>(0,60)</p>
<p>(6,60)</p>
<p>(8,60)</p>
<p>(2,60)</p>
<p>(1,60)</p>
<p>(3,60)</p>
<p>(7,60)</p>
<p>(9,60)</p>
<p>(5,60)</p>
<p>-——————————————</p>
<p>Time: 1539075284000 ms</p>
<p>-——————————————</p>
<p>(4,60)</p>
<p>(0,60)</p>
<p>(6,60)</p>
<p>(8,60)</p>
<p>(2,60)</p>
<p>(1,60)</p>
<p>(3,60)</p>
<p>(7,60)</p>
<p>(9,60)</p>
<p>(5,60)</p>
<p>-——————————————</p>
<p>Time: 1539075288000 ms</p>
<p>-——————————————</p>
<p>(4,30)</p>
<p>(0,30)</p>
<p>(6,30)</p>
<p>(8,30)</p>
<p>(2,30)</p>
<p>(1,30)</p>
<p>(3,30)</p>
<p>(7,30)</p>
<p>(9,30)</p>
<p>(5,30)</p>
<p>-——————————————</p>
<p>Time: 1539075292000 ms</p>
<p>-——————————————</p>
</blockquote>
<h3 id="file"><a href="#file" class="headerlink" title="file()"></a>file()</h3><h4 id="用法及说明-1"><a href="#用法及说明-1" class="headerlink" title="用法及说明"></a>用法及说明</h4><p><font color="red">测试过程</font>中，可以通过使用ssc.textFileStream(“in”)来创建DStream，监控文件夹的变化。</p>
<p>从文件夹中读取新的文件数据（拽过去的文件可能读不到），功能不稳定 ，所以不推荐使用</p>
<p>flume更加专业，所以生产环境，监控文件或目录的变化，采集数据都使用flume</p>
<h4 id="案例实操-1"><a href="#案例实操-1" class="headerlink" title="案例实操"></a>案例实操</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming03_DStream_File</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 配置对象</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 环境对象</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 数据处理</span></span><br><span class="line">    <span class="comment">// 从文件夹中读取新的文件数据，功能不稳定 ，所以不推荐使用</span></span><br><span class="line">    <span class="comment">// flume更加专业，所以生产环境，监控文件或目录的变化，采集数据都使用flume</span></span><br><span class="line">    <span class="keyword">val</span> fileDS: <span class="type">DStream</span>[<span class="type">String</span>] = ssc.textFileStream(<span class="string">"in"</span>)</span><br><span class="line">    <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = fileDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map( (_, <span class="number">1</span>) )</span><br><span class="line">    <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKey(_+_)</span><br><span class="line">    wordToCountDS.print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 关闭连接环境</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>






<h2 id="自定义数据源"><a href="#自定义数据源" class="headerlink" title="自定义数据源"></a>自定义数据源</h2><h3 id="用法及说明-2"><a href="#用法及说明-2" class="headerlink" title="用法及说明"></a>用法及说明</h3><p>需要继承Receiver，并实现onStart、onStop方法来自定义数据源采集。</p>
<h3 id="案例实操-2"><a href="#案例实操-2" class="headerlink" title="案例实操"></a>案例实操</h3><p>需求：自定义数据源，实现监控某个端口号，获取该端口号内容。</p>
<p>1) 自定义数据源</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  自定义数据采集器</span></span><br><span class="line"><span class="comment">    自定义数据采集器</span></span><br><span class="line"><span class="comment">    模仿spark自带的socket采集器</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  abstract class Receiver[T](val storageLevel: StorageLevel) extends Serializable</span></span><br><span class="line"><span class="comment">  StorageLevel :存储级别 MEMORY_ONLY DISK_ONLY MEMORY_AND_DISK</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  步骤： 1. 继承Receiver ,设定泛型（采集数据的类型）, 传递参数</span></span><br><span class="line"><span class="comment">         2. 重写方法</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyRecevier</span>(<span class="params">host : <span class="type">String</span> , port : <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Receiver</span>[<span class="type">String</span>](<span class="params"><span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span></span>)</span>&#123;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">   socketTextStream:  socketStream[String](hostname, port, SocketReceiver.bytesToLines, storageLevel)</span></span><br><span class="line"><span class="comment">    socketStream：  new SocketInputDStream[T](this, hostname, port, converter, storageLevel)</span></span><br><span class="line"><span class="comment">    SocketInputDStream:  new SocketReceiver(host, port, bytesToObjects, storageLevel)</span></span><br><span class="line"><span class="comment">    SocketReceiver：extends Receiver[T](storageLevel) with Logging</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> socket: <span class="type">Socket</span> = _</span><br><span class="line">    <span class="comment">// SocketReceiver：socket.getInputStream()</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">      <span class="comment">//我们需要字符串，所以将字节流转换为缓冲字符流</span></span><br><span class="line">      <span class="keyword">val</span> reader = <span class="keyword">new</span> <span class="type">BufferedReader</span>(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">InputStreamReader</span>(</span><br><span class="line">          <span class="comment">//获取从网络中传递来的数据（字节流）</span></span><br><span class="line">          socket.getInputStream,</span><br><span class="line">          <span class="string">"UTF-8"</span></span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      <span class="keyword">var</span> s:<span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">     <span class="comment">/*</span></span><br><span class="line"><span class="comment">      这个“s = reader.readLine())!= null”语句是错误的，因为在网络编程中获取的数据是没有null的概念</span></span><br><span class="line"><span class="comment">      文件读取时，如果读到结束的时候，获取的结果为null（文件读取这样是对的）</span></span><br><span class="line"><span class="comment">      但是在网络中我可以现在传递一些数据  过一段就再传一次，所以null是无法判断的</span></span><br><span class="line"><span class="comment">      网络编程中，需要明确告知服务器，客户端不再传数据，需要发送特殊的指令</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">      <span class="keyword">while</span>(( s = reader.readLine())!= <span class="literal">null</span>)&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需要发送特殊的指令</span></span><br><span class="line">        <span class="keyword">if</span>(s != <span class="string">"-END-"</span>)&#123;</span><br><span class="line">          <span class="comment">//采集到数据后，进行封装(存储)</span></span><br><span class="line">              store(s)</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">          <span class="comment">// stop</span></span><br><span class="line">          <span class="comment">// close</span></span><br><span class="line">          <span class="comment">// 重启</span></span><br><span class="line">          <span class="comment">//restart("")</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 启动采集器</span></span><br><span class="line">    <span class="comment">// 采集 &amp; 封装</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      socket = <span class="keyword">new</span> <span class="type">Socket</span>(host , port)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">new</span> <span class="type">Thread</span>(<span class="string">"Socket Receiver"</span>) &#123;</span><br><span class="line">        setDaemon(<span class="literal">true</span>)<span class="comment">//守护线程</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">          receive() &#125;</span><br><span class="line">      &#125;.start()<span class="comment">//start()会回调run()方法</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStop</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (socket != <span class="literal">null</span>)&#123;</span><br><span class="line">        socket.close()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>2) 使用自定义的数据源采集数据</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreamig_DIY</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// TODO 配置对象</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span>  <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"DIY采集器"</span>)</span><br><span class="line">    <span class="comment">// TODO 环境对象</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf , <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">    <span class="comment">// TODO 数据处理</span></span><br><span class="line">    <span class="comment">// 自定义数据采集器</span></span><br><span class="line">    <span class="keyword">val</span> myDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.receiverStream(<span class="keyword">new</span> <span class="type">MyRecevier</span>(<span class="string">"localhost"</span> , <span class="number">9999</span>))</span><br><span class="line">    <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = myDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map((_ , <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKey(_+_)</span><br><span class="line">    wordToCountDS.print()</span><br><span class="line">    <span class="comment">// TODO 开启连接环境</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>



<h2 id="Kafka数据源"><a href="#Kafka数据源" class="headerlink" title="Kafka数据源"></a>Kafka数据源</h2><h3 id="版本选型"><a href="#版本选型" class="headerlink" title="版本选型"></a>版本选型</h3><p><strong>ReceiverAPI</strong>：需要一个专门的Executor去接收数据，然后发送给其他的Executor做计算。存在的问题，接收数据的Executor和计算的Executor速度会有所不同，特别在接收数据的Executor速度大于计算的Executor速度，会导致计算数据的节点内存溢出。</p>
<p><strong>DirectAPI</strong>：是由计算的Executor来主动消费Kafka的数据，速度由自身控制。</p>
<p> <img src="/2020/03/11/SparkStreaming/SparkStreaming13.jpg" alt="SparkStreaming13"></p>
<h3 id="Kafka-0-8-Receiver模式"><a href="#Kafka-0-8-Receiver模式" class="headerlink" title="Kafka 0-8 Receiver模式"></a>Kafka 0-8 Receiver模式</h3><p>1） 需求：通过SparkStreaming从Kafka读取数据，并将读取过来的数据做简单计算，最终打印到控制台。</p>
<p>2）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-8_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>3）编写代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.red.kafka</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">ReceiverInputDStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming_Kafka</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// TODO 配置对象</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span>  <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"DIY采集器"</span>)</span><br><span class="line">    <span class="comment">// TODO 环境对象</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf , <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">    <span class="comment">// TODO 数据处理 - 读取Kafka数据创建DStream(基于Receive方式)</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    def createStream(</span></span><br><span class="line"><span class="comment">                      ssc : org.apache.spark.streaming.StreamingContext,</span></span><br><span class="line"><span class="comment">                      zkQuorum : scala.Predef.String, //zookeeper</span></span><br><span class="line"><span class="comment">                      groupId : scala.Predef.String, //消费者组</span></span><br><span class="line"><span class="comment">                      topics : scala.Predef.Map[scala.Predef.String, scala.Int],//分区数</span></span><br><span class="line"><span class="comment">                      storageLevel : org.apache.spark.storage.StorageLevel = &#123;  compiled code  &#125;</span></span><br><span class="line"><span class="comment">                    ) : org.apache.spark.streaming.dstream.ReceiverInputDStream[scala.Tuple2[scala.Predef.String, scala.Predef.String]] = &#123;  compiled code  &#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kafkaDS: <span class="type">ReceiverInputDStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">KafkaUtils</span>.createStream(</span><br><span class="line">      ssc,</span><br><span class="line">      <span class="string">"linux1:2181,linux2:2181,linux3:2181"</span>,</span><br><span class="line">      <span class="string">"red0819"</span>,</span><br><span class="line">      <span class="type">Map</span>(<span class="string">"red0819"</span> -&gt; <span class="number">3</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">// Kafka消息传递的时候以k-v对</span></span><br><span class="line">    <span class="comment">// k - 传值的时候提供的，默认为null,主要用于分区</span></span><br><span class="line">    <span class="comment">// v - message</span></span><br><span class="line">    kafkaDS.map((_._2)).print()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="Kafka-0-8-Direct模式"><a href="#Kafka-0-8-Direct模式" class="headerlink" title="Kafka 0-8 Direct模式"></a>Kafka 0-8 Direct模式</h3><p>1）需求：通过SparkStreaming从Kafka读取数据，并将读取过来的数据做简单计算，最终打印到控制台。</p>
<p>2）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-8_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>3）编写代码</p>
<h4 id="自动维护offset"><a href="#自动维护offset" class="headerlink" title="自动维护offset"></a>自动维护offset</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerConfig</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DirectAPIAuto02</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="keyword">val</span> getSSC1: () =&gt; <span class="type">StreamingContext</span> = () =&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ReceiverWordCount"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">  ssc</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">getSSC</span></span>: <span class="type">StreamingContext</span> = &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//1.创建SparkConf</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ReceiverWordCount"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//2.创建StreamingContext</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//设置CK</span></span><br><span class="line"></span><br><span class="line">  ssc.checkpoint(<span class="string">"./ck2"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//3.定义Kafka参数</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> kafkaPara: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line"></span><br><span class="line">   <span class="type">ConsumerConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span> -&gt; <span class="string">"linux1:9092,linux2:9092,linux3:9092"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="type">ConsumerConfig</span>.<span class="type">GROUP_ID_CONFIG</span> -&gt; <span class="string">"red"</span></span><br><span class="line"></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//4.读取Kafka数据</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> kafkaDStream: <span class="type">InputDStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc,</span><br><span class="line"></span><br><span class="line">   kafkaPara,</span><br><span class="line"></span><br><span class="line">   <span class="type">Set</span>(<span class="string">"red"</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//5.计算WordCount</span></span><br><span class="line"></span><br><span class="line">  kafkaDStream.map(_._2)</span><br><span class="line"></span><br><span class="line">   .flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">   .map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">   .reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">   .print()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//6.返回数据</span></span><br><span class="line"></span><br><span class="line">  ssc</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取SSC</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc: <span class="type">StreamingContext</span> = <span class="type">StreamingContext</span>.getActiveOrCreate(<span class="string">"./ck2"</span>, () =&gt; getSSC)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//开启任务</span></span><br><span class="line"></span><br><span class="line">  ssc.start()</span><br><span class="line"></span><br><span class="line">  ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="手动维护offset"><a href="#手动维护offset" class="headerlink" title="手动维护offset"></a>手动维护offset</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.common.<span class="type">TopicAndPartition</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.message.<span class="type">MessageAndMetadata</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerConfig</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.&#123;<span class="type">HasOffsetRanges</span>, <span class="type">KafkaUtils</span>, <span class="type">OffsetRange</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DirectAPIHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//1.创建SparkConf</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ReceiverWordCount"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//2.创建StreamingContext</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//3.Kafka参数</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> kafkaPara: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line"></span><br><span class="line">   <span class="type">ConsumerConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span> -&gt; <span class="string">"hadoop102:9092,hadoop103:9092,hadoop104:9092"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="type">ConsumerConfig</span>.<span class="type">GROUP_ID_CONFIG</span> -&gt; <span class="string">"red"</span></span><br><span class="line"></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//4.获取上一次启动最后保留的Offset=&gt;getOffset(MySQL)</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> fromOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>] = <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>](<span class="type">TopicAndPartition</span>(<span class="string">"red"</span>, <span class="number">0</span>) -&gt; <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//5.读取Kafka数据创建DStream</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> kafkaDStream: <span class="type">InputDStream</span>[<span class="type">String</span>] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>, <span class="type">String</span>](ssc,</span><br><span class="line"></span><br><span class="line">   kafkaPara,</span><br><span class="line"></span><br><span class="line">   fromOffsets,</span><br><span class="line"></span><br><span class="line">   (m: <span class="type">MessageAndMetadata</span>[<span class="type">String</span>, <span class="type">String</span>]) =&gt; m.message())</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//6.创建一个数组用于存放当前消费数据的offset信息</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> offsetRanges = <span class="type">Array</span>.empty[<span class="type">OffsetRange</span>]</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//7.获取当前消费数据的offset信息</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> wordToCountDStream: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = kafkaDStream.transform &#123; rdd =&gt;</span><br><span class="line"></span><br><span class="line">   offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line"></span><br><span class="line">   rdd</span><br><span class="line"></span><br><span class="line">  &#125;.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">   .map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">   .reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//8.打印Offset信息</span></span><br><span class="line"></span><br><span class="line">  wordToCountDStream.foreachRDD(rdd =&gt; &#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (o &lt;- offsetRanges) &#123;</span><br><span class="line"></span><br><span class="line">    println(<span class="string">s"<span class="subst">$&#123;o.topic&#125;</span>:<span class="subst">$&#123;o.partition&#125;</span>:<span class="subst">$&#123;o.fromOffset&#125;</span>:<span class="subst">$&#123;o.untilOffset&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   rdd.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="comment">//9.开启任务</span></span><br><span class="line"></span><br><span class="line">  ssc.start()</span><br><span class="line"></span><br><span class="line">  ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Kafka-0-10-Direct模式"><a href="#Kafka-0-10-Direct模式" class="headerlink" title="Kafka 0-10 Direct模式"></a>Kafka 0-10 Direct模式</h3><p>1）需求：通过SparkStreaming从Kafka读取数据，并将读取过来的数据做简单计算，最终打印到控制台。</p>
<p>2）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-10_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>3）编写代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.&#123;<span class="type">ConsumerConfig</span>, <span class="type">ConsumerRecord</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.&#123;<span class="type">ConsumerStrategies</span>, <span class="type">KafkaUtils</span>, <span class="type">LocationStrategies</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DirectAPI</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//1.创建SparkConf</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ReceiverWordCount"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//2.创建StreamingContext</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//3.定义Kafka参数</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> kafkaPara: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>] = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line"></span><br><span class="line">   <span class="type">ConsumerConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span> -&gt; <span class="string">"linux1:9092,linux2:9092,linux3:9092"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="type">ConsumerConfig</span>.<span class="type">GROUP_ID_CONFIG</span> -&gt; <span class="string">"red"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="string">"key.deserializer"</span> -&gt; <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="string">"value.deserializer"</span> -&gt; <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line"></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//4.读取Kafka数据创建DStream</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> kafkaDStream: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](ssc,</span><br><span class="line"></span><br><span class="line">   <span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span>,</span><br><span class="line"></span><br><span class="line">   <span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="type">Set</span>(<span class="string">"red"</span>), kafkaPara))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//5.将每条消息的KV取出</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> valueDStream: <span class="type">DStream</span>[<span class="type">String</span>] = kafkaDStream.map(record =&gt; record.value())</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//6.计算WordCount</span></span><br><span class="line"></span><br><span class="line">  valueDStream.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">   .map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">   .reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">   .print()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//7.开启任务</span></span><br><span class="line"></span><br><span class="line">  ssc.start()</span><br><span class="line"></span><br><span class="line">  ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="消费Kafka数据模式总结"><a href="#消费Kafka数据模式总结" class="headerlink" title="消费Kafka数据模式总结"></a>消费Kafka数据模式总结</h3><h4 id="0-8"><a href="#0-8" class="headerlink" title="0-8"></a>0-8</h4><h5 id="ReceiverAPI"><a href="#ReceiverAPI" class="headerlink" title="ReceiverAPI"></a>ReceiverAPI</h5><p>1) 专门的Executor读取数据，速度不统一</p>
<p>  数据丢失：预写日志开启</p>
<p>2) 跨机器传输数据</p>
<p>3) Executor读取数据通过多个线程的方式，想要增加并行度，则需要多个流union</p>
<p>4) offset存储在zookeeper中</p>
<h5 id="DirectAPI"><a href="#DirectAPI" class="headerlink" title="DirectAPI"></a>DirectAPI</h5><p>1) Executor读取数据并计算</p>
<p>2) 增加Executor个数来增加消费的并行度</p>
<p>3) offset存储</p>
<p>a. CheckPoint(getActiveOrCreate方式创建StreamingContext)</p>
<p>从checkpoint中读取数据偏移量（不推荐使用）</p>
<blockquote>
<p>理由：</p>
<p>​        checkpoint还保存了计算逻辑，不适合扩展功能<br>​                checkpoint会延续计算，但是可能会压垮内存<br>​                checkpoint一般的存储路径为HDFS，所以会导致小文件过多</p>
</blockquote>
<p>b. 手动维护(有事务的存储系统)</p>
<p>4) 获取offset必须在第一个调用的算子中：</p>
<p>offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges</p>
<h4 id="0-10-DirectAPI"><a href="#0-10-DirectAPI" class="headerlink" title="0-10 DirectAPI"></a>0-10 DirectAPI</h4><p>1) Executor读取数据并计算</p>
<p>2) 增加Executor个数来增加消费的并行度</p>
<p>3) offset存储</p>
<p>a. __consumer_offsets系统主题中</p>
<p>b. 手动维护(有事务的存储系统)</p>
<h1 id="DStream转换"><a href="#DStream转换" class="headerlink" title="DStream转换"></a>DStream转换</h1><p>DStream上的操作与RDD的类似，分为Transformations（转换）和Output Operations（输出）两种，此外转换操作中还有一些比较特殊的原语，如：updateStateByKey()、transform()以及各种Window相关的原语。</p>
<h2 id="无状态转化操作"><a href="#无状态转化操作" class="headerlink" title="无状态转化操作"></a>无状态转化操作</h2><p>无状态转化操作就是把简单的RDD转化操作应用到每个批次上，也就是转化DStream中的每一个RDD。部分无状态转化操作列在了下表中。注意，针对键值对的DStream转化操作(比如 reduceByKey())要添加import StreamingContext._才能在Scala中使用。</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming14.jpg" alt="SparkStreaming14"></p>
<p>需要记住的是，尽管这些函数看起来像作用在整个流上一样，但事实上每个DStream在内部是由许多RDD（批次）组成，且无状态转化操作是分别应用到每个RDD上的。</p>
<p>例如：reduceByKey()会归约每个时间区间中的数据，但不会归约不同区间之间的数据。</p>
<h3 id="Transform"><a href="#Transform" class="headerlink" title="Transform"></a>Transform</h3><p>Transform允许DStream上执行任意的RDD-to-RDD函数。即使这些函数并没有在DStream的API中暴露出来，通过该函数可以方便的扩展Spark API。该函数每一批次调度一次。其实也就是对DStream中的RDD应用转换。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DStream_WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sparkconf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"queue"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkconf, <span class="type">Seconds</span>(<span class="number">5</span>));</span><br><span class="line">    <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span> , <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> resultDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = socketDS.transform(</span><br><span class="line">      rdd =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> flatRDD: <span class="type">RDD</span>[<span class="type">String</span>] = rdd.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">        <span class="keyword">val</span> mapRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = flatRDD.map((_, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">val</span> reduceRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = mapRDD.reduceByKey(_ + _)</span><br><span class="line">        reduceRDD</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    )</span><br><span class="line">    resultDS.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>两个流之间的join需要两个流的批次大小一致，这样才能做到同时触发计算。计算过程就是对当前批次的两个流中各自的RDD进行join，与两个RDD的join效果相同。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">JoinTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//1.创建SparkConf</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"JoinTest"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//2.创建StreamingContext</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//3.从端口获取数据创建流</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> lineDStream1: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"linux1"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> lineDStream2: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"linux2"</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//4.将两个流转换为KV类型</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> wordToOneDStream: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = lineDStream1.flatMap(_.split(<span class="string">" "</span>)).map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> wordToADStream: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] = lineDStream2.flatMap(_.split(<span class="string">" "</span>)).map((_, <span class="string">"a"</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//5.流的JOIN</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> joinDStream: <span class="type">DStream</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">String</span>))] = wordToOneDStream.join(wordToADStream)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//6.打印</span></span><br><span class="line"></span><br><span class="line">  joinDStream.print()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//7.启动任务</span></span><br><span class="line"></span><br><span class="line">  ssc.start()</span><br><span class="line"></span><br><span class="line">  ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="有状态转化操作"><a href="#有状态转化操作" class="headerlink" title="有状态转化操作"></a>有状态转化操作</h2><h3 id="UpdateStateByKey"><a href="#UpdateStateByKey" class="headerlink" title="UpdateStateByKey"></a>UpdateStateByKey</h3><p>UpdateStateByKey原语用于记录历史记录，有时，我们需要在DStream中跨批次维护状态(例如流计算中累加wordcount)。针对这种情况，updateStateByKey()为我们提供了对一个状态变量的访问，用于键值对形式的DStream。给定一个由(键，事件)对构成的 DStream，并传递一个指定如何根据新的事件更新每个键对应状态的函数，它可以构建出一个新的 DStream，其内部数据为(键，状态) 对。</p>
<p>updateStateByKey() 的结果会是一个新的DStream，其内部的RDD 序列是由每个时间区间对应的(键，状态)对组成的。</p>
<p>updateStateByKey操作使得我们可以在用新信息进行更新时保持任意的状态。为使用这个功能，需要做下面两步：</p>
<ol>
<li><p>定义状态，状态可以是一个任意的数据类型。</p>
</li>
<li><p>定义状态更新函数，用此函数阐明如何使用之前的状态和来自输入流的新值对状态进行更新。</p>
</li>
</ol>
<p>使用updateStateByKey需要对检查点目录进行配置，会使用检查点来保存状态。</p>
<p>更新版的wordcount</p>
<p>1) 编写代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DSream_State</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sparkconf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkconf , <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span> , <span class="number">9999</span>)</span><br><span class="line">    <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = socketDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map((_ , <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 使用有状态操作保存数据 updateStateByKey</span></span><br><span class="line">    ssc.checkpoint(<span class="string">"scp"</span>)</span><br><span class="line">    <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Long</span>)] = wordToOneDS.updateStateByKey[<span class="type">Long</span>](</span><br><span class="line">      <span class="comment">// TODO 第一个参数表示相同key的value数据集合</span></span><br><span class="line">      <span class="comment">// TODO 第二个参数表示相同key的缓冲区的数据</span></span><br><span class="line">      (seq: <span class="type">Seq</span>[<span class="type">Int</span>], opt: <span class="type">Option</span>[<span class="type">Long</span>]) =&gt; &#123;</span><br><span class="line">        <span class="comment">// TODO 返回值表示更新后的缓冲区的值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> newValue = opt.getOrElse(<span class="number">0</span>L) + seq.sum</span><br><span class="line">        <span class="type">Option</span>(newValue)</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">    wordToCountDS.print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2) 启动程序并向9999端口发送数据</p>
<blockquote>
<p>nc -lk 9999</p>
<p>Hello World</p>
<p>Hello Scala</p>
</blockquote>
<p>3) 结果展示</p>
<blockquote>
<p>-——————————————</p>
<p>Time: 1504685175000 ms</p>
<p>-——————————————</p>
<p>-——————————————</p>
<p>Time: 1504685181000 ms</p>
<p>-——————————————</p>
<p>(shi,1)</p>
<p>(shui,1)</p>
<p>(ni,1)</p>
<p>-——————————————</p>
<p>Time: 1504685187000 ms</p>
<p>-——————————————</p>
<p>(shi,1)</p>
<p>(ma,1)</p>
<p>(hao,1)</p>
<p>(shui,1)</p>
</blockquote>
<h3 id="WindowOperations"><a href="#WindowOperations" class="headerlink" title="WindowOperations"></a>WindowOperations</h3><p>Window Operations可以设置窗口的大小和滑动窗口的间隔来动态的获取当前Steaming的允许状态。所有基于窗口的操作都需要两个参数，分别为窗口时长以及滑动步长。</p>
<p>窗口时长：计算内容的时间范围；</p>
<p>滑动步长：隔多久触发一次计算。</p>
<p><font color="red"><strong>注意：这两者都必须为采集周期大小的整数倍。</strong></font></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WorldCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"NetworkWordCount"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">  ssc.checkpoint(<span class="string">"./ck"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">// Create a DStream that will connect to hostname:port, like localhost:9999</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"linux1"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">// Split each line into words</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment">// Count each word in each batch</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> wordCounts = pairs.reduceByKeyAndWindow((a:<span class="type">Int</span>,b:<span class="type">Int</span>) =&gt; (a + b),<span class="type">Seconds</span>(<span class="number">12</span>), <span class="type">Seconds</span>(<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">// Print the first ten elements of each RDD generated in this DStream to the console</span></span><br><span class="line"></span><br><span class="line">  wordCounts.print()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  ssc.start()       <span class="comment">// Start the computation</span></span><br><span class="line"></span><br><span class="line">  ssc.awaitTermination()  <span class="comment">// Wait for the computation to terminate</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h4><p><img src="/2020/03/11/SparkStreaming/image-20200914120823766.png" alt="image-20200914120823766"></p>
<h4 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h4><p><img src="/2020/03/11/SparkStreaming/image-20200914120922340.png" alt="image-20200914120922340"></p>
<p>关于Window的操作还有如下方法：</p>
<p>（1）window(windowLength, slideInterval): 基于对源DStream窗化的批次进行计算返回一个新的Dstream；</p>
<p>（2）countByWindow(windowLength, slideInterval): 返回一个滑动窗口计数流中的元素个数；</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//countByWindow</span></span><br><span class="line">ssc.checkpoint(<span class="string">"scp"</span>)</span><br><span class="line"><span class="keyword">val</span> countDS: <span class="type">DStream</span>[<span class="type">Long</span>] = socketDS.countByWindow(<span class="type">Seconds</span>(<span class="number">6</span>), <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">print(countDS)</span><br></pre></td></tr></table></figure>

<p>（3）reduceByWindow(func, windowLength, slideInterval): 通过使用自定义函数整合滑动区间流元素来创建一个新的单元素流；</p>
<p>（4）reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks]): 当在一个(K,V)对的DStream上调用此函数，会返回一个新(K,V)对的DStream，此处通过对滑动窗口中批次数据使用reduce函数来整合每个key的value值。(func 两两聚合)</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//reduceByKeyAndWindow</span></span><br><span class="line"><span class="keyword">val</span> wordToOne: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = socketDS.flatMap(_.split(<span class="string">" "</span>)).map((_ , <span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> reduceByKeyAndWindowDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOne.reduceByKeyAndWindow(</span><br><span class="line">  (x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; x + y, <span class="type">Seconds</span>(<span class="number">6</span>), <span class="type">Seconds</span>(<span class="number">3</span>)</span><br><span class="line">)</span><br><span class="line">reduceByKeyAndWindowDS.print()</span><br></pre></td></tr></table></figure>

<p>（5）reduceByKeyAndWindow(func, invFunc, windowLength, slideInterval, [numTasks]): 这个函数是上述函数的变化版本，每个窗口的reduce值都是通过用前一个窗的reduce值来递增计算。通过reduce进入到滑动窗口数据并”反向reduce”离开窗口的旧数据来实现这个操作。一个例子是随着窗口滑动对keys的“加”“减”计数。<strong>通过前边介绍可以想到，这个函数只适用于”可逆的reduce函数”，也就是这些reduce函数有相应的”反reduce”函数(以参数invFunc形式传入)。</strong>如前述函数，reduce任务的数量通过可选参数来配置。</p>
<p><img src="/2020/03/11/SparkStreaming/SparkStreaming15.jpg" alt="SparkStreaming15"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> ipDStream = accessLogsDStream.map(logEntry =&gt; (logEntry.getIpAddress(), <span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> ipCountDStream = ipDStream.reduceByKeyAndWindow(</span><br><span class="line"> &#123;(x, y) =&gt; x + y&#125;,</span><br><span class="line"> &#123;(x, y) =&gt; x - y&#125;,</span><br><span class="line"> <span class="type">Seconds</span>(<span class="number">30</span>),</span><br><span class="line"> <span class="type">Seconds</span>(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>


<p> //加上新进入窗口的批次中的元素 //移除离开窗口的老批次中的元素 //窗口时长// 滑动步长</p>
<p>countByWindow()和countByValueAndWindow()作为对数据进行计数操作的简写。countByWindow()返回一个表示每个窗口中元素个数的DStream，而countByValueAndWindow()返回的DStream则包含窗口中每个值的个数。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> ipDStream = accessLogsDStream.map&#123;entry =&gt; entry.getIpAddress()&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> ipAddressRequestCount = ipDStream.countByValueAndWindow(<span class="type">Seconds</span>(<span class="number">30</span>), <span class="type">Seconds</span>(<span class="number">10</span>)) </span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> requestCount = accessLogsDStream.countByWindow(<span class="type">Seconds</span>(<span class="number">30</span>), <span class="type">Seconds</span>(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>



<h1 id="DStream输出"><a href="#DStream输出" class="headerlink" title="DStream输出"></a>DStream输出</h1><p>输出操作指定了对流数据经转化操作得到的数据所要执行的操作(例如把结果推入外部数据库或输出到屏幕上)。与RDD中的惰性求值类似，如果一个DStream及其派生出的DStream都没有被执行输出操作，那么这些DStream就都不会被求值。如果StreamingContext中没有设定输出操作，整个context就都不会启动。</p>
<p>输出操作如下：</p>
<p><font color="blue">print()</font>：在运行流程序的驱动结点上打印DStream中每一批次数据的最开始10个元素。这用于开发和调试。在Python API中，同样的操作叫print()。</p>
<p><font color="blue">saveAsTextFiles(prefix, [suffix])</font>：以text文件形式存储这个DStream的内容。每一批次的存储文件名基于参数中的prefix和suffix。”prefix-Time_IN_MS[.suffix]”。</p>
<p><font color="blue">saveAsObjectFiles(prefix, [suffix])</font>：以Java对象序列化的方式将Stream中的数据保存为 SequenceFiles . 每一批次的存储文件名基于参数中的为”prefix-TIME_IN_MS[.suffix]”. Python中目前不可用。</p>
<p><font color="blue">saveAsHadoopFiles(prefix, [suffix])</font>：将Stream中的数据保存为 Hadoop files. 每一批次的存储文件名基于参数中的为”prefix-TIME_IN_MS[.suffix]”。Python API 中目前不可用。</p>
<p><font color="blue">foreachRDD(func)</font>：这是最通用的输出操作，即将函数 func 用于产生于 stream的每一个RDD。其中参数传入的函数func应该实现将每一个RDD中数据推送到外部系统，如将RDD存入文件或者通过网络将其写入数据库。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">ReceiverInputDStream</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DStream_Output</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sparkconf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkconf , <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span> , <span class="number">9999</span>)</span><br><span class="line">    <span class="comment">//将数据保存到mysql数据库中</span></span><br><span class="line">    socketDS.foreachRDD(</span><br><span class="line">      rdd =&gt;&#123;</span><br><span class="line">        rdd.foreach(</span><br><span class="line">          data =&gt;&#123;</span><br><span class="line">            <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = data.split(<span class="string">","</span>)</span><br><span class="line">            <span class="keyword">val</span> id: <span class="type">Int</span> = datas(<span class="number">0</span>).toInt</span><br><span class="line">            <span class="keyword">val</span> name: <span class="type">String</span> = datas(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">val</span> age: <span class="type">Int</span> = datas(<span class="number">0</span>).toInt</span><br><span class="line"></span><br><span class="line">            <span class="comment">//TODO 加载数据库驱动</span></span><br><span class="line">            <span class="type">Class</span>.forName(<span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">            <span class="comment">// TODO 建立链接和操作对象</span></span><br><span class="line">            <span class="keyword">val</span> conn: <span class="type">Connection</span> = <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">              <span class="string">"jdbc:mysql://3306/studenttest"</span>,</span><br><span class="line">              <span class="string">"root"</span>,</span><br><span class="line">              <span class="string">"000000"</span></span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">val</span> sql = <span class="string">"insert into student(id,name,age) values (?,?,?)"</span></span><br><span class="line">            <span class="keyword">val</span> statement: <span class="type">PreparedStatement</span> = conn.prepareStatement(sql)</span><br><span class="line">            statement.setInt(<span class="number">1</span>,id)</span><br><span class="line">            statement.setString(<span class="number">2</span>,name)</span><br><span class="line">            statement.setInt(<span class="number">3</span>,age)</span><br><span class="line"></span><br><span class="line">            <span class="comment">// TODO 操作数据</span></span><br><span class="line">            statement.executeUpdate()</span><br><span class="line"></span><br><span class="line">            <span class="comment">// TODO 关闭连接</span></span><br><span class="line">            statement.close()</span><br><span class="line">            conn.close()</span><br><span class="line"></span><br><span class="line">          &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong><font color="red">注：但是在真实场景中数据传播速度快，传递量大，所以上述代码并不适合用在实际操作中。</font></strong></p>
<p><strong><font color="red">原因：数据来一次建立一次链接，数据库链接创建太多，显然是不合理的。在数据量巨大的情况下用连接池也是不合理的，处理不过来。</font></strong></p>
<p>通用的输出操作foreachRDD()，它用来对DStream中的RDD运行任意计算。这和transform() 有些类似，都可以让我们访问任意RDD。在foreachRDD()中，可以重用我们在Spark中实现的所有行动操作。比如，常见的用例之一是把数据写到诸如MySQL的外部数据库中。 </p>
<p>注意：</p>
<p>1) 连接不能写在driver层面（序列化）</p>
<p>2) 如果写在foreach则每个RDD中的每一条数据都创建，得不偿失；</p>
<p>3) 增加foreachPartition，在分区创建（获取）。</p>
<p>rdd.foreachPartition()：以分区为单位进行遍历，不需要返回</p>
<p>rdd.foreachPartitions()：以分区为单位进行转换，需要返回</p>
<h1 id="优雅关闭"><a href="#优雅关闭" class="headerlink" title="优雅关闭"></a>优雅关闭</h1><p>流式任务需要7*24小时执行，但是有时涉及到升级代码需要主动停止程序，但是分布式程序，没办法做到一个个进程去杀死，所有配置优雅的关闭就显得至关重要了。</p>
<p>使用外部文件系统来控制内部程序关闭。</p>
<p>MonitorStop</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.net.<span class="type">URI</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.<span class="type">Configuration</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FileSystem</span>, <span class="type">Path</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">StreamingContext</span>, <span class="type">StreamingContextState</span>&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MonitorStop</span>(<span class="params">ssc: <span class="type">StreamingContext</span></span>) <span class="keyword">extends</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> fs: <span class="type">FileSystem</span> = <span class="type">FileSystem</span>.get(<span class="keyword">new</span> <span class="type">URI</span>(<span class="string">"hdfs://linux1:9000"</span>), <span class="keyword">new</span> <span class="type">Configuration</span>(), <span class="string">"red"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//优雅关闭判断条件</span></span><br><span class="line"><span class="comment">//stop方法不能放在driver的主线程中</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//一般标志不在Driver端，在第三方软件中 eg:redis/zk/mysql/hdfs</span></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">try</span></span><br><span class="line"></span><br><span class="line">    <span class="type">Thread</span>.sleep(<span class="number">5000</span>)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">catch</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">InterruptedException</span> =&gt;</span><br><span class="line"></span><br><span class="line">     e.printStackTrace()</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"><span class="comment">//获取当前线程状态</span></span><br><span class="line">   <span class="keyword">val</span> state: <span class="type">StreamingContextState</span> = ssc.getState</span><br><span class="line"> </span><br><span class="line"><span class="comment">// TODO 设置标记，让当前关闭线程可以访问，可以动态改变状态</span></span><br><span class="line">   <span class="keyword">val</span> bool: <span class="type">Boolean</span> = fs.exists(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">"hdfs://linux1:9000/stopSpark"</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">//为了防止有新线程了之后SparkStreaming直接关闭，所以应该加一个判断条件，</span></span><br><span class="line"><span class="comment">// 并且循环判断，避免判断一次之后不再判断</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (bool) &#123;</span><br><span class="line"><span class="comment">//判断当前状态，如果当前不是激活状态的话根本不用关闭</span></span><br><span class="line">    <span class="keyword">if</span> (state == <span class="type">StreamingContextState</span>.<span class="type">ACTIVE</span>) &#123;</span><br><span class="line"></span><br><span class="line">     ssc.stop(stopSparkContext = <span class="literal">true</span>, stopGracefully = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">     <span class="type">System</span>.exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>SparkTest</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">createSSC</span></span>(): _root_.org.apache.spark.streaming.<span class="type">StreamingContext</span> = &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> update: (<span class="type">Seq</span>[<span class="type">Int</span>], <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; <span class="type">Some</span>[<span class="type">Int</span>] = (values: <span class="type">Seq</span>[<span class="type">Int</span>], status: <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="comment">//当前批次内容的计算</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> sum: <span class="type">Int</span> = values.sum</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="comment">//取出状态信息中上一次状态</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> lastStatu: <span class="type">Int</span> = status.getOrElse(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   <span class="type">Some</span>(sum + lastStatu)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[4]"</span>).setAppName(<span class="string">"SparkTest"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">//****设置优雅的关闭*****</span></span><br><span class="line"></span><br><span class="line">  sparkConf.set(<span class="string">"spark.streaming.stopGracefullyOnShutdown"</span>, <span class="string">"true"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  ssc.checkpoint(<span class="string">"./ck"</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> line: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"linux1"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> word: <span class="type">DStream</span>[<span class="type">String</span>] = line.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> wordAndOne: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = word.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> wordAndCount: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordAndOne.updateStateByKey(update)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  wordAndCount.print()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  ssc</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ssc: <span class="type">StreamingContext</span> = <span class="type">StreamingContext</span>.getActiveOrCreate(<span class="string">"./ck"</span>, () =&gt; createSSC())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">new</span> <span class="type">Thread</span>(<span class="keyword">new</span> <span class="type">MonitorStop</span>(ssc)).start()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  ssc.start()</span><br><span class="line"></span><br><span class="line">  ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>优雅关闭是要判断当前有没有数据没有处理完，如果有，先把当前数据处理完再关闭。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">大数据</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkStreaming/" rel="tag">SparkStreaming</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Redis-Jedis" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/02/23/Redis-Jedis/" class="article-date">
      <time datetime="2020-02-23T12:33:25.000Z" itemprop="datePublished">2020-02-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/23/Redis-Jedis/">Redis和Jedis</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><table>
<thead>
<tr>
<th></th>
<th>MySQL</th>
<th>Redis</th>
</tr>
</thead>
<tbody><tr>
<td>连接</td>
<td>Connection</td>
<td>Jedis</td>
</tr>
<tr>
<td>连接池</td>
<td>C3P0等等</td>
<td>JedisPool</td>
</tr>
<tr>
<td>操作完成</td>
<td>关闭连接</td>
<td>关闭连接</td>
</tr>
</tbody></table>
<h2 id="Redis准备"><a href="#Redis准备" class="headerlink" title="Redis准备"></a>Redis准备</h2><h3 id="①Redis配置文件中bind配置项含义"><a href="#①Redis配置文件中bind配置项含义" class="headerlink" title="①Redis配置文件中bind配置项含义"></a>①Redis配置文件中bind配置项含义</h3><p>bind后面跟的ip地址是客户端访问Redis时使用的IP地址。</p>
<table>
<thead>
<tr>
<th>bind值</th>
<th>访问方式</th>
</tr>
</thead>
<tbody><tr>
<td>127.0.0.1</td>
<td>./redis-cli -h 127.0.0.1</td>
</tr>
<tr>
<td>192.168.200.100</td>
<td>./redis-cli -h 192.168.200.100</td>
</tr>
</tbody></table>
<h3 id="②查看Linux系统本机IP"><a href="#②查看Linux系统本机IP" class="headerlink" title="②查看Linux系统本机IP"></a>②查看Linux系统本机IP</h3><p>远程客户端访问Linux服务器时不能使用127.0.0.1，要使用网络上的实际IP。可以用ifconfig命令查看。</p>
<h3 id="③将Redis配置文件中的bind配置项设置为本机IP。"><a href="#③将Redis配置文件中的bind配置项设置为本机IP。" class="headerlink" title="③将Redis配置文件中的bind配置项设置为本机IP。"></a>③将Redis配置文件中的bind配置项设置为本机IP。</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bind [你的实际IP]</span><br><span class="line">bind 192.168.200.100</span><br></pre></td></tr></table></figure>

<h2 id="Jedis"><a href="#Jedis" class="headerlink" title="Jedis"></a>Jedis</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//指定Redis服务器的IP地址和端口号</span></span><br><span class="line">Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"192.168.200.100"</span>, <span class="number">6379</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//执行ping命令</span></span><br><span class="line">String ping = jedis.ping();</span><br><span class="line"></span><br><span class="line">System.out.println(ping);</span><br><span class="line"></span><br><span class="line"><span class="comment">//关闭连接</span></span><br><span class="line">jedis.close();</span><br></pre></td></tr></table></figure>

<h2 id="JedisPool"><a href="#JedisPool" class="headerlink" title="JedisPool"></a>JedisPool</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//声明Linux服务器IP地址</span></span><br><span class="line">String host = <span class="string">"192.168.200.100"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//声明Redis端口号</span></span><br><span class="line"><span class="keyword">int</span> port = Protocol.DEFAULT_PORT;</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建连接池对象</span></span><br><span class="line">JedisPool jedisPool = <span class="keyword">new</span> JedisPool(host, port);</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取Jedis对象连接Redis</span></span><br><span class="line">Jedis jedis = jedisPool.getResource();</span><br><span class="line"></span><br><span class="line"><span class="comment">//执行具体操作</span></span><br><span class="line">String ping = jedis.ping();</span><br><span class="line"></span><br><span class="line">System.out.println(ping);</span><br><span class="line"></span><br><span class="line"><span class="comment">//关闭连接</span></span><br><span class="line">jedisPool.close();</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">大数据</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Redis/" rel="tag">Redis</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2017-2020 Snow Monster
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = /background/taizichangqin.jpg;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
             tags: ".article-tag a", 
             categories: ".article-category a, a.tag-list-link", 
             articleNav: "#article-nav a, #post-nav-button a", 
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
             menu: ".header-menu a", 
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>