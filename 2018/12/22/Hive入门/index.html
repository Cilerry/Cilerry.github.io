<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Hive入门 | RedLeavesBlog</title><meta name="keywords" content="Hive"><meta name="author" content="Snow Monster"><meta name="copyright" content="Snow Monster"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="HIVE入门什么是HiveHive：由Facebook开源用于解决海量结构化日志的数据统计。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。 本质是：将HQL转化成MapReduce程序  1）Hive处理的数据存储在HDFS 2）Hive分析数据底层的实现是MapReduce 3）执行程序运行在Yarn上 Hive的优缺点优点1) 操作">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive入门">
<meta property="og:url" content="http://www.red0819.top/2018/12/22/Hive%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="RedLeavesBlog">
<meta property="og:description" content="HIVE入门什么是HiveHive：由Facebook开源用于解决海量结构化日志的数据统计。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。 本质是：将HQL转化成MapReduce程序  1）Hive处理的数据存储在HDFS 2）Hive分析数据底层的实现是MapReduce 3）执行程序运行在Yarn上 Hive的优缺点优点1) 操作">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.red0819.top/wordPic/Hive-logo.jpg">
<meta property="article:published_time" content="2018-12-22T12:59:01.000Z">
<meta property="article:modified_time" content="2020-09-14T21:05:09.965Z">
<meta property="article:author" content="Snow Monster">
<meta property="article:tag" content="Hive">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.red0819.top/wordPic/Hive-logo.jpg"><link rel="shortcut icon" href="/img/logo.png"><link rel="canonical" href="http://www.red0819.top/2018/12/22/Hive%E5%85%A5%E9%97%A8/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="yandex-verification" content="{&quot;theme_color&quot;:{&quot;enable&quot;:true,&quot;main&quot;:&quot;\t#191970&quot;,&quot;paginator&quot;:&quot;#00c4b6&quot;,&quot;button_hover&quot;:&quot;#FF7242&quot;,&quot;text_selection&quot;:&quot;#00c4b6&quot;,&quot;link_color&quot;:&quot;#99a9bf&quot;,&quot;meta_color&quot;:&quot;#858585&quot;,&quot;hr_color&quot;:&quot;#A4D8FA&quot;,&quot;code_foreground&quot;:&quot;#F47466&quot;,&quot;code_background&quot;:&quot;rgba(27, 31, 35, .05)&quot;,&quot;toc_color&quot;:&quot;#00c4b6&quot;,&quot;blockquote_padding_color&quot;:&quot;#49b1f5&quot;,&quot;blockquote_background_color&quot;:&quot;#49b1f5&quot;}}"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '4.2.1',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-09-15 05:05:09'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
  }
}

var autoChangeMode = 'false'
var t = saveToLocal.get('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (saveToLocal.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="RedLeavesBlog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/AF67D2ECB3B0F647193CD90F94294167.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">2</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#HIVE入门"><span class="toc-number">1.</span> <span class="toc-text">HIVE入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是Hive"><span class="toc-number">1.1.</span> <span class="toc-text">什么是Hive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive的优缺点"><span class="toc-number">1.2.</span> <span class="toc-text">Hive的优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#优点"><span class="toc-number">1.2.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#缺点"><span class="toc-number">1.2.2.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive架构原理"><span class="toc-number">1.3.</span> <span class="toc-text">Hive架构原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive和数据库比较"><span class="toc-number">1.4.</span> <span class="toc-text">Hive和数据库比较</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#查询语言"><span class="toc-number">1.4.1.</span> <span class="toc-text">查询语言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据存储位置"><span class="toc-number">1.4.2.</span> <span class="toc-text">数据存储位置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据更新"><span class="toc-number">1.4.3.</span> <span class="toc-text">数据更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#索引"><span class="toc-number">1.4.4.</span> <span class="toc-text">索引</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#执行"><span class="toc-number">1.4.5.</span> <span class="toc-text">执行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#执行延迟"><span class="toc-number">1.4.6.</span> <span class="toc-text">执行延迟</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#可扩展性"><span class="toc-number">1.4.7.</span> <span class="toc-text">可扩展性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据规模"><span class="toc-number">1.4.8.</span> <span class="toc-text">数据规模</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive安装"><span class="toc-number">2.</span> <span class="toc-text">Hive安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive安装地址"><span class="toc-number">2.1.</span> <span class="toc-text">Hive安装地址</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive安装部署"><span class="toc-number">2.2.</span> <span class="toc-text">Hive安装部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#将本地文件导入Hive案例"><span class="toc-number">2.3.</span> <span class="toc-text">将本地文件导入Hive案例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MySql安装"><span class="toc-number">2.4.</span> <span class="toc-text">MySql安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive元数据配置到MySql"><span class="toc-number">2.5.</span> <span class="toc-text">Hive元数据配置到MySql</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#驱动拷贝"><span class="toc-number">2.5.1.</span> <span class="toc-text">驱动拷贝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置Metastore到MySql"><span class="toc-number">2.5.2.</span> <span class="toc-text">配置Metastore到MySql</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多窗口启动Hive测试"><span class="toc-number">2.5.3.</span> <span class="toc-text">多窗口启动Hive测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HiveJDBC访问"><span class="toc-number">2.6.</span> <span class="toc-text">HiveJDBC访问</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#启动hiveserver2服务"><span class="toc-number">2.6.1.</span> <span class="toc-text">启动hiveserver2服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#启动beeline"><span class="toc-number">2.6.2.</span> <span class="toc-text">启动beeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#连接hiveserver2"><span class="toc-number">2.6.3.</span> <span class="toc-text">连接hiveserver2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive常用交互命令"><span class="toc-number">2.7.</span> <span class="toc-text">Hive常用交互命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive其他命令操作"><span class="toc-number">2.8.</span> <span class="toc-text">Hive其他命令操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive常见属性配置"><span class="toc-number">2.9.</span> <span class="toc-text">Hive常见属性配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive数据仓库位置配置"><span class="toc-number">2.9.1.</span> <span class="toc-text">Hive数据仓库位置配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#查询后信息显示配置"><span class="toc-number">2.9.2.</span> <span class="toc-text">查询后信息显示配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive运行日志信息配置"><span class="toc-number">2.9.3.</span> <span class="toc-text">Hive运行日志信息配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参数配置方式"><span class="toc-number">2.9.4.</span> <span class="toc-text">参数配置方式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive数据类型"><span class="toc-number">3.</span> <span class="toc-text">Hive数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#基本数据类型"><span class="toc-number">3.1.</span> <span class="toc-text">基本数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#集合数据类型"><span class="toc-number">3.2.</span> <span class="toc-text">集合数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#类型转化"><span class="toc-number">3.3.</span> <span class="toc-text">类型转化</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(/wordPic/Hive-logo.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">RedLeavesBlog</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Hive入门</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2018-12-22T12:59:01.000Z" title="undefined 2018-12-22 20:59:01">2018-12-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/bigdata/">大数据</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>24分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="HIVE入门"><a href="#HIVE入门" class="headerlink" title="HIVE入门"></a>HIVE入门</h1><h2 id="什么是Hive"><a href="#什么是Hive" class="headerlink" title="什么是Hive"></a>什么是Hive</h2><p>Hive：由Facebook开源用于解决海量结构化日志的数据统计。</p>
<p>Hive是基于Hadoop的一个<strong>数据仓库工具</strong>，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</p>
<p><strong>本质是：将HQL转化成MapReduce程序</strong></p>
<p><img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps1.png" alt="wps1"></p>
<p>1）Hive处理的数据存储在HDFS</p>
<p>2）Hive分析数据底层的实现是MapReduce</p>
<p>3）执行程序运行在Yarn上</p>
<h2 id="Hive的优缺点"><a href="#Hive的优缺点" class="headerlink" title="Hive的优缺点"></a>Hive的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1) 操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。</p>
<p>2) 避免了去写MapReduce，减少开发人员的学习成本。</p>
<p>3) Hive的<strong>执行延迟比较高</strong>，因此Hive常用于数据分析，对实时性要求不高的场合。</p>
<p>4) Hive优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高。</p>
<p>5) Hive<strong>支持用户自定义函数</strong>，用户可以根据自己的需求来实现自己的函数。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1．Hive的HQL表达能力有限</p>
<p>（1）迭代式算法无法表达</p>
<p>（2）数据挖掘方面不擅长</p>
<p>2．Hive的效率比较低</p>
<p>（1）Hive自动生成的MapReduce作业，通常情况下不够智能化</p>
<p>（2）Hive调优比较困难，粒度较粗</p>
<h2 id="Hive架构原理"><a href="#Hive架构原理" class="headerlink" title="Hive架构原理"></a>Hive架构原理</h2><p><img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps2.png" alt="wps2"></p>
<p>1．用户接口：Client</p>
<p>CLI（hive shell）、JDBC/ODBC(java访问hive)、WEBUI（浏览器访问hive）</p>
<p>2．元数据：Metastore</p>
<p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p>
<p><strong>默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore</strong></p>
<p>3．Hadoop</p>
<p>使用HDFS进行存储，使用MapReduce进行计算。</p>
<p>4．驱动器：Driver</p>
<p>（1）解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</p>
<p>（2）编译器（Physical Plan）：将AST编译生成逻辑执行计划。</p>
<p>（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。</p>
<p>（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。</p>
<p><img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps3.png" alt="wps3"></p>
<p>Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。</p>
<h2 id="Hive和数据库比较"><a href="#Hive和数据库比较" class="headerlink" title="Hive和数据库比较"></a>Hive和数据库比较</h2><p>由于 Hive 采用了类似SQL 的查询语言 HQL(Hive Query Language)，因此很容易将 Hive 理解为数据库。其实从结构上来看，Hive 和数据库除了拥有类似的查询语言，再无类似之处。本文将从多个方面来阐述 Hive 和数据库的差异。数据库可以用在 Online 的应用中，但是Hive 是为数据仓库而设计的，清楚这一点，有助于从应用角度理解 Hive 的特性。</p>
<h3 id="查询语言"><a href="#查询语言" class="headerlink" title="查询语言"></a>查询语言</h3><p>由于SQL被广泛的应用在数据仓库中，因此，专门针对Hive的特性设计了类SQL的查询语言HQL。熟悉SQL开发的开发者可以很方便的使用Hive进行开发。</p>
<h3 id="数据存储位置"><a href="#数据存储位置" class="headerlink" title="数据存储位置"></a>数据存储位置</h3><p>Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。</p>
<h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><p>由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，<strong>Hive中不建议对数据的改写</strong>，所有的数据都是在加载的时候确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO … VALUES 添加数据，使用 UPDATE … SET修改数据。</p>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>Hive在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些Key建立索引。<u>Hive要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。</u>由于 MapReduce 的引入，<u>Hive 可以并行访问数据</u>，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 Hive 不适合在线数据查询。</p>
<h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><p>Hive中大多数查询的执行是通过 Hadoop 提供的 MapReduce 来实现的。</p>
<p>数据库通常有自己的执行引擎。</p>
<h3 id="执行延迟"><a href="#执行延迟" class="headerlink" title="执行延迟"></a>执行延迟</h3><p>1）Hive执行延迟高</p>
<p>Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。</p>
<p>另一个导致 Hive 执行延迟高的因素是 MapReduce框架。由于MapReduce 本身具有较高的延迟，因此在利用MapReduce 执行Hive查询时，也会有较高的延迟。</p>
<p>2）数据库的执行延迟较低（相对而言）</p>
<p>数据规模较小时提现。</p>
<p>当数据规模大到超过数据库的处理能力的时候，Hive的并行计算显然能体现出优势。</p>
<h3 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h3><p>由于Hive是建立在Hadoop之上的，因此Hive的可扩展性是和Hadoop的可扩展性是一致的（世界上最大的Hadoop 集群在 Yahoo!，2009年的规模在4000 台节点左右）。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle在理论上的扩展能力也只有100台左右。</p>
<h3 id="数据规模"><a href="#数据规模" class="headerlink" title="数据规模"></a>数据规模</h3><p>由于Hive建立在集群上并可以利用MapReduce进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小。</p>
<h1 id="Hive安装"><a href="#Hive安装" class="headerlink" title="Hive安装"></a>Hive安装</h1><h2 id="Hive安装地址"><a href="#Hive安装地址" class="headerlink" title="Hive安装地址"></a>Hive安装地址</h2><p>1．Hive官网地址</p>
<p><a href="http://hive.apache.org/" target="_blank" rel="noopener">http://hive.apache.org/</a></p>
<p>2．文档查看地址</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p>
<p>3．下载地址</p>
<p><a href="http://archive.apache.org/dist/hive/" target="_blank" rel="noopener">http://archive.apache.org/dist/hive/</a></p>
<p>4．github地址</p>
<p><a href="https://github.com/apache/hive" target="_blank" rel="noopener">https://github.com/apache/hive</a></p>
<h2 id="Hive安装部署"><a href="#Hive安装部署" class="headerlink" title="Hive安装部署"></a>Hive安装部署</h2><p>1．Hive安装及配置</p>
<p>（1）把apache-hive-1.2.1-bin.tar.gz上传到linux的/opt/software目录下</p>
<p>（2）解压apache-hive-1.2.1-bin.tar.gz到/opt/module/目录下面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 software]$ tar -zxvf apache-hive-1.2.1-bin.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure>

<p>（3）修改apache-hive-1.2.1-bin.tar.gz的名称为hive</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 module]$ mv apache-hive-1.2.1-bin&#x2F; hive</span><br></pre></td></tr></table></figure>

<p>（4）修改/opt/module/hive/conf目录下的hive-env.sh.template名称为hive-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 conf]$ mv hive-env.sh.template hive-env.sh</span><br></pre></td></tr></table></figure>

<p>​    （5）配置hive-env.sh文件</p>
<p>​    （a）配置HADOOP_HOME路径</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br></pre></td></tr></table></figure>

<p>​    （b）配置HIVE_CONF_DIR路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_CONF_DIR=/opt/module/hive/conf</span><br></pre></td></tr></table></figure>

<p>2．Hadoop集群配置</p>
<p>（1）必须启动hdfs和yarn</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hadoop-2.7.2]$ sbin&#x2F;start-dfs.sh</span><br><span class="line"></span><br><span class="line">[red@hadoop103 hadoop-2.7.2]$ sbin&#x2F;start-yarn.sh</span><br></pre></td></tr></table></figure>

<p>（2）在HDFS上创建/tmp和/user/hive/warehouse两个目录并修改他们的同组权限可写</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hadoop-2.7.2]$ bin&#x2F;hadoop fs -mkdir &#x2F;tmp</span><br><span class="line"></span><br><span class="line">[red@hadoop102 hadoop-2.7.2]$ bin&#x2F;hadoop fs -mkdir -p &#x2F;user&#x2F;hive&#x2F;warehouse</span><br><span class="line"></span><br><span class="line">[red@hadoop102 hadoop-2.7.2]$ bin&#x2F;hadoop fs -chmod g+w &#x2F;tmp</span><br><span class="line"></span><br><span class="line">[red@hadoop102 hadoop-2.7.2]$ bin&#x2F;hadoop fs -chmod g+w &#x2F;user&#x2F;hive&#x2F;warehouse</span><br></pre></td></tr></table></figure>

<p>3．Hive基本操作</p>
<p>（1）启动hive</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hive</span><br></pre></td></tr></table></figure>

<p>（2）查看数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure>

<p>（3）打开默认数据库</p>
<p>hive&gt; use default;</p>
<p>（4）显示default数据库中的表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show tables;</span><br></pre></td></tr></table></figure>

<p>（5）创建一张表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create table student(id int, name string);</span><br></pre></td></tr></table></figure>

<p>（6）显示数据库中有几张表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show tables;</span><br></pre></td></tr></table></figure>

<p>（7）查看表的结构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc student;</span><br></pre></td></tr></table></figure>

<p>（8）向表中插入数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; insert into student values(1000,&quot;ss&quot;);</span><br></pre></td></tr></table></figure>

<p>（9）查询表中数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select * from student;</span><br></pre></td></tr></table></figure>

<p>（10）退出hive</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; quit;</span><br></pre></td></tr></table></figure>



<h2 id="将本地文件导入Hive案例"><a href="#将本地文件导入Hive案例" class="headerlink" title="将本地文件导入Hive案例"></a>将本地文件导入Hive案例</h2><p>需求</p>
<p>将本地/opt/module/datas/student.txt这个目录下的数据导入到hive的student(id int, name string)表中。</p>
<p>1．数据准备</p>
<p>在/opt/module/datas这个目录下准备数据</p>
<p>（1）在/opt/module/目录下创建datas</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 module]$ mkdir datas</span><br></pre></td></tr></table></figure>

<p>（2）在/opt/module/datas/目录下创建student.txt文件并添加数据（tab键间隔）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 datas]$ touch student.txt</span><br><span class="line"></span><br><span class="line">[red@hadoop102 datas]$ vi student.txt</span><br></pre></td></tr></table></figure>

<blockquote>
<p>1001    zhangshan</p>
<p>1002    lishi</p>
<p>1003    zhaoliu</p>
</blockquote>
<p>2．Hive实际操作</p>
<p>（1）启动hive</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hive</span><br></pre></td></tr></table></figure>

<p>（2）显示数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure>

<p>（3）使用default数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; use default;</span><br></pre></td></tr></table></figure>

<p>（4）显示default数据库中的表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show tables;</span><br></pre></td></tr></table></figure>

<p>（5）删除已创建的student表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; drop table student;</span><br></pre></td></tr></table></figure>

<p>（6）创建student表, 并声明文件分隔符’\t’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqlhive&gt; create table student(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;</span><br></pre></td></tr></table></figure>

<p>（7）加载/opt/module/datas/student.txt 文件到student数据库表中。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; load data local inpath '/opt/module/datas/student.txt' into table student;</span><br></pre></td></tr></table></figure>

<p>（8）Hive查询结果</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select * from student;</span><br><span class="line"></span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">1001	zhangshan</span><br><span class="line"></span><br><span class="line">1002	lishi</span><br><span class="line"></span><br><span class="line">1003	zhaoliu</span><br><span class="line"></span><br><span class="line">Time taken: 0.266 seconds, Fetched: 3 row(s)</span><br></pre></td></tr></table></figure>

<p>3．遇到的问题</p>
<p>再打开一个客户端窗口启动hive，会产生java.sql.SQLException异常。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">"main"</span> java.lang.RuntimeException: java.lang.RuntimeException:</span><br><span class="line"></span><br><span class="line"> Unable to instantiate</span><br><span class="line"></span><br><span class="line"> org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:<span class="number">522</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:<span class="number">677</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:<span class="number">621</span>)</span><br><span class="line"></span><br><span class="line">   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line"></span><br><span class="line">   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line"></span><br><span class="line">   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line"></span><br><span class="line">   at java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.util.RunJar.run(RunJar.java:<span class="number">221</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">136</span>)</span><br><span class="line"></span><br><span class="line">Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:<span class="number">1523</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:<span class="number">86</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:<span class="number">132</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:<span class="number">104</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:<span class="number">3005</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:<span class="number">3024</span>)</span><br><span class="line"></span><br><span class="line">   at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:<span class="number">503</span>)</span><br><span class="line"></span><br><span class="line">... <span class="number">8</span> more</span><br></pre></td></tr></table></figure>

<p>原因是，Metastore默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore;</p>
<h2 id="MySql安装"><a href="#MySql安装" class="headerlink" title="MySql安装"></a>MySql安装</h2><p>（1）检查当前系统是否安装过Mysql</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]$ rpm -qa|grep mysql</span><br><span class="line"></span><br><span class="line"> mysql-libs-5.1.73-7.el6.x86_64 &#x2F;&#x2F;如果存在通过如下命令卸载</span><br><span class="line"></span><br><span class="line">[root@hadoop102 ~]$ rpm -e --nodeps  mysql-libs &#x2F;&#x2F;用此命令卸载Mysql</span><br></pre></td></tr></table></figure>

<p>（2）将MySQL安装包拷贝到/opt/software目录下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> [root@hadoop102 software]# ll</span><br><span class="line"></span><br><span class="line">总用量 528384</span><br><span class="line"></span><br><span class="line">-rw-r--r--. 1 root root 541061120 11月 29 17:56 mysql-5.7.28-1.el6.x86_64.rpm-bundle.tar</span><br></pre></td></tr></table></figure>

<p>（3）解压MySQL安装包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -xf mysql-5.7.28-1.el6.x86_64.rpm-bundle.tar</span><br></pre></td></tr></table></figure>

<p><img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps4.jpg" alt="wps4"></p>
<p>（4）在安装目录下执行rpm安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-common-5.7.28-1.el6.x86_64.rpm</span><br><span class="line"></span><br><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-libs-5.7.28-1.el6.x86_64.rpm</span><br><span class="line"></span><br><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-client-5.7.28-1.el6.x86_64.rpm</span><br><span class="line"></span><br><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-server-5.7.28-1.el6.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>​     注意:按照顺序依次执行</p>
<p>（5）修改/etc/my.cnf文件,在[mysqld]节点下添加如下配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"></span><br><span class="line"> explicit_defaults_for_timestamp&#x3D;true  &#x2F;&#x2F;显示指定默认值为timestamp类型的字段</span><br></pre></td></tr></table></figure>

<p>（6）删除/etc/my.cnf文件中datadir指向的目录下的所有内容:</p>
<p> 查看datadir的值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"></span><br><span class="line">datadir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql</span><br></pre></td></tr></table></figure>

<p> 删除/var/lib/mysql目录下的所有内容:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql]# pwd</span><br><span class="line"></span><br><span class="line">&#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line"></span><br><span class="line">[root@hadoop102 mysql]# rm -rf *   &#x2F;&#x2F;注意执行命令的位置</span><br></pre></td></tr></table></figure>

<p>（7）初始化数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 opt]$ mysqld --initialize --user&#x3D;mysql</span><br></pre></td></tr></table></figure>

<p>（8）查看临时生成的root用户的密码 </p>
<p><img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps5.jpg" alt="wps5"></p>
<p>（9）启动MySQL服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 opt]$ service mysqld start</span><br></pre></td></tr></table></figure>

<p>（10）登录MySQL数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 opt]$ mysql -uroot -p</span><br><span class="line"></span><br><span class="line">Enter password:  输入临时生成的密码</span><br></pre></td></tr></table></figure>

<p> <img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps6.jpg" alt="wps6"></p>
<p> 登录成功.</p>
<p>（11）修改root用户的密码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set password &#x3D; password(&quot;新密码&quot;)</span><br></pre></td></tr></table></figure>

<p>（12）修改root用户支持任意IP连接</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use mysql ;</span><br><span class="line"></span><br><span class="line">	mysql&gt; update user set host&#x3D; ‘%’ where  user &#x3D; ‘root’;</span><br><span class="line"></span><br><span class="line">	mysql&gt; flush privileges ;</span><br></pre></td></tr></table></figure>



<h2 id="Hive元数据配置到MySql"><a href="#Hive元数据配置到MySql" class="headerlink" title="Hive元数据配置到MySql"></a>Hive元数据配置到MySql</h2><h3 id="驱动拷贝"><a href="#驱动拷贝" class="headerlink" title="驱动拷贝"></a>驱动拷贝</h3><p>1．拷贝mysql-connector-java-5.1.37-bin.jar到/opt/module/hive/lib/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cp mysql-connector-java-5.1.37-bin.jar &#x2F;opt&#x2F;module&#x2F;hive&#x2F;lib&#x2F;</span><br></pre></td></tr></table></figure>



<h3 id="配置Metastore到MySql"><a href="#配置Metastore到MySql" class="headerlink" title="配置Metastore到MySql"></a>配置Metastore到MySql</h3><p>1．在/opt/module/hive/conf目录下创建一个hive-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 conf]$ touch hive-site.xml</span><br><span class="line"></span><br><span class="line">[red@hadoop102 conf]$ vi hive-site.xml</span><br></pre></td></tr></table></figure>

<p>2．根据官方文档配置参数，拷贝数据到hive-site.xml文件中</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin</a></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​     jdbc:mysql://hadoop102:3306/metastore?createDatabaseIfNotExist=true</span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	 <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>3．配置完毕后，如果启动hive异常，可以重新启动虚拟机。（重启后，别忘了启动hadoop集群）</p>
<h3 id="多窗口启动Hive测试"><a href="#多窗口启动Hive测试" class="headerlink" title="多窗口启动Hive测试"></a>多窗口启动Hive测试</h3><p>1．先启动MySQL</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 mysql-libs]$ mysql -uroot -p000000</span><br></pre></td></tr></table></figure>

<p>查看有几个数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show databases;</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br><span class="line"></span><br><span class="line">| Database      |</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br><span class="line"></span><br><span class="line">| information_schema |</span><br><span class="line"></span><br><span class="line">| mysql       |</span><br><span class="line"></span><br><span class="line">| performance_schema |</span><br><span class="line"></span><br><span class="line">| test        |</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br></pre></td></tr></table></figure>

<p>2．再次打开多个窗口，分别启动hive</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hive</span><br></pre></td></tr></table></figure>

<p>3．启动hive后，回到MySQL窗口查看数据库，显示增加了metastore数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">	mysql&gt; show databases;</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br><span class="line"></span><br><span class="line">| Database      |</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br><span class="line"></span><br><span class="line">| information_schema |</span><br><span class="line"></span><br><span class="line">| metastore      |</span><br><span class="line"></span><br><span class="line">| mysql       |</span><br><span class="line"></span><br><span class="line">| performance_schema |</span><br><span class="line"></span><br><span class="line">| test        |</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br></pre></td></tr></table></figure>

<h2 id="HiveJDBC访问"><a href="#HiveJDBC访问" class="headerlink" title="HiveJDBC访问"></a>HiveJDBC访问</h2><h3 id="启动hiveserver2服务"><a href="#启动hiveserver2服务" class="headerlink" title="启动hiveserver2服务"></a>启动hiveserver2服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hiveserver2</span><br></pre></td></tr></table></figure>



<h3 id="启动beeline"><a href="#启动beeline" class="headerlink" title="启动beeline"></a>启动beeline</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;beeline</span><br><span class="line"></span><br><span class="line">Beeline version 1.2.1 by Apache Hive</span><br><span class="line"></span><br><span class="line">beeline&gt;</span><br></pre></td></tr></table></figure>



<h3 id="连接hiveserver2"><a href="#连接hiveserver2" class="headerlink" title="连接hiveserver2"></a>连接hiveserver2</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">beeline&gt; !connect jdbc:hive2:&#x2F;&#x2F;hadoop102:10000（回车）</span><br><span class="line"></span><br><span class="line">Connecting to jdbc:hive2:&#x2F;&#x2F;hadoop102:10000</span><br><span class="line"></span><br><span class="line">Enter username for jdbc:hive2:&#x2F;&#x2F;hadoop102:10000: red（回车）</span><br><span class="line"></span><br><span class="line">Enter password for jdbc:hive2:&#x2F;&#x2F;hadoop102:10000: （直接回车）</span><br><span class="line"></span><br><span class="line">Connected to: Apache Hive (version 1.2.1)</span><br><span class="line"></span><br><span class="line">Driver: Hive JDBC (version 1.2.1)</span><br><span class="line"></span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line"></span><br><span class="line">0: jdbc:hive2:&#x2F;&#x2F;hadoop102:10000&gt; show databases;</span><br><span class="line"></span><br><span class="line">+----------------+--+</span><br><span class="line"></span><br><span class="line">| database_name  |</span><br><span class="line"></span><br><span class="line">+----------------+--+</span><br><span class="line"></span><br><span class="line">| default     |</span><br><span class="line"></span><br><span class="line">| hive_db2    |</span><br><span class="line"></span><br><span class="line">+----------------+--+</span><br></pre></td></tr></table></figure>



<h2 id="Hive常用交互命令"><a href="#Hive常用交互命令" class="headerlink" title="Hive常用交互命令"></a>Hive常用交互命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hive -helpusage: hive -d,--define &lt;key&#x3D;value&gt;      Variable subsitution to apply to hive                   commands. e.g. -d A&#x3D;B or --define A&#x3D;B  --database &lt;databasename&gt;   Specify the database to use -e &lt;quoted-query-string&gt;     SQL from command line -f &lt;filename&gt;           SQL from files -H,--help             Print help information  --hiveconf &lt;property&#x3D;value&gt;  Use value for given property  --hivevar &lt;key&#x3D;value&gt;     Variable subsitution to apply to hive                  commands. e.g. --hivevar A&#x3D;B -i &lt;filename&gt;           Initialization SQL file -S,--silent            Silent mode in interactive shell -v,--verbose           Verbose mode (echo executed SQL to the console)</span><br></pre></td></tr></table></figure>

<p>1．“-e”不进入hive的交互窗口执行sql语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hive -e &quot;select id from student;&quot;</span><br></pre></td></tr></table></figure>

<p>2．“-f”执行脚本中sql语句</p>
<p>​    （1）在/opt/module/datas目录下创建hivef.sql文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 datas]$ touch hivef.sql</span><br></pre></td></tr></table></figure>

<p>​        文件中写入正确的sql语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select *from student;</span><br></pre></td></tr></table></figure>

<p>​    （2）执行文件中的sql语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hive -f &#x2F;opt&#x2F;module&#x2F;datas&#x2F;hivef.sql</span><br></pre></td></tr></table></figure>

<p>（3）执行文件中的sql语句并将结果写入文件中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 hive]$ bin&#x2F;hive -f &#x2F;opt&#x2F;module&#x2F;datas&#x2F;hivef.sql  &gt; &#x2F;opt&#x2F;module&#x2F;datas&#x2F;hive_result.txt</span><br></pre></td></tr></table></figure>



<h2 id="Hive其他命令操作"><a href="#Hive其他命令操作" class="headerlink" title="Hive其他命令操作"></a>Hive其他命令操作</h2><p>1．退出hive窗口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;exit;</span><br><span class="line"></span><br><span class="line">hive(default)&gt;quit;</span><br></pre></td></tr></table></figure>

<p>在新版的hive中没区别了，在以前的版本是有的：</p>
<p>exit:先隐性提交数据，再退出；</p>
<p>quit:不提交数据，退出；</p>
<p>2．在hive cli命令窗口中如何查看hdfs文件系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;dfs -ls &#x2F;;</span><br></pre></td></tr></table></figure>

<p>3．在hive cli命令窗口中如何查看本地文件系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;! ls &#x2F;opt&#x2F;module&#x2F;datas;</span><br></pre></td></tr></table></figure>

<p>4．查看在hive中输入的所有历史命令</p>
<p>​    （1）进入到当前用户的根目录/root或/home/red</p>
<p>​    （2）查看. hivehistory文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 ~]$ cat .hivehistory</span><br></pre></td></tr></table></figure>



<h2 id="Hive常见属性配置"><a href="#Hive常见属性配置" class="headerlink" title="Hive常见属性配置"></a>Hive常见属性配置</h2><h3 id="Hive数据仓库位置配置"><a href="#Hive数据仓库位置配置" class="headerlink" title="Hive数据仓库位置配置"></a>Hive数据仓库位置配置</h3><p>​    1）Default数据仓库的最原始位置是在hdfs上的：/user/hive/warehouse路径下。</p>
<p>​    2）在仓库目录下，没有对默认的数据库default创建文件夹。如果某张表属于default数据库，直接在数据仓库目录下创建一个文件夹。</p>
<p>​    3）修改default数据仓库原始位置（将hive-default.xml.template如下配置信息拷贝到hive-site.xml文件中）。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置同组用户有执行权限</p>
<p>bin/hdfs dfs -chmod g+w /user/hive/warehouse</p>
<h3 id="查询后信息显示配置"><a href="#查询后信息显示配置" class="headerlink" title="查询后信息显示配置"></a>查询后信息显示配置</h3><p>1）在hive-site.xml文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>​    2）重新启动hive，对比配置前后差异。</p>
<p>（1）配置前，如图6-2所示</p>
<p> <img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps7.jpg" alt="wps7"></p>
<p>图6-2 配置前</p>
<p>（2）配置后，如图6-3所示</p>
<p> <img src="/2018/12/22/Hive%E5%85%A5%E9%97%A8/wps8.jpg" alt="wps8"></p>
<p>图6-3 配置后</p>
<h3 id="Hive运行日志信息配置"><a href="#Hive运行日志信息配置" class="headerlink" title="Hive运行日志信息配置"></a>Hive运行日志信息配置</h3><p>1．Hive的log默认存放在/tmp/red/hive.log目录下（当前用户名下）</p>
<p>2．修改hive的log存放日志到/opt/module/hive/logs</p>
<p>​    （1）修改/opt/module/hive/conf/hive-log4j.properties.template文件名称为</p>
<blockquote>
<p>hive-log4j.properties</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop102 conf]$ pwd</span><br><span class="line"></span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;hive&#x2F;conf</span><br><span class="line"></span><br><span class="line">[red@hadoop102 conf]$ mv hive-log4j.properties.template hive-log4j.properties</span><br></pre></td></tr></table></figure>

<p>​    （2）在hive-log4j.properties文件中修改log存放位置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.log.dir&#x3D;&#x2F;opt&#x2F;module&#x2F;hive&#x2F;logs</span><br></pre></td></tr></table></figure>



<h3 id="参数配置方式"><a href="#参数配置方式" class="headerlink" title="参数配置方式"></a>参数配置方式</h3><p>1．查看当前所有的配置信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;set;</span><br></pre></td></tr></table></figure>

<p>2．参数的配置三种方式</p>
<p>​    （1）配置文件方式</p>
<p>默认配置文件：hive-default.xml </p>
<p>用户自定义配置文件：hive-site.xml</p>
<p>​    注意：用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。</p>
<p>（2）命令行参数方式</p>
<p>启动Hive时，可以在命令行添加-hiveconf param=value来设定参数。</p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[red@hadoop103 hive]$ bin&#x2F;hive -hiveconf mapred.reduce.tasks&#x3D;10;</span><br></pre></td></tr></table></figure>

<p>注意：仅对本次hive启动有效</p>
<p>查看参数设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br></pre></td></tr></table></figure>

<p>（3）参数声明方式</p>
<p>可以在HQL中使用SET关键字设定参数</p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks&#x3D;100;</span><br></pre></td></tr></table></figure>

<p>注意：仅对本次hive启动有效。</p>
<p>查看参数设置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br></pre></td></tr></table></figure>

<p>上述三种设定方式的优先级依次递增。即配置文件&lt;命令行参数&lt;参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>
<h1 id="Hive数据类型"><a href="#Hive数据类型" class="headerlink" title="Hive数据类型"></a>Hive数据类型</h1><h2 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h2><p>表6-1</p>
<table>
<thead>
<tr>
<th>Hive数据类型</th>
<th>Java数据类型</th>
<th>长度</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>TINYINT</td>
<td>byte</td>
<td>1byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>SMALINT</td>
<td>short</td>
<td>2byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>INT</td>
<td>int</td>
<td>4byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BIGINT</td>
<td>long</td>
<td>8byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BOOLEAN</td>
<td>boolean</td>
<td>布尔类型，true或者false</td>
<td>TRUE  FALSE</td>
</tr>
<tr>
<td>FLOAT</td>
<td>float</td>
<td>单精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>DOUBLE</td>
<td>double</td>
<td>双精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>STRING</td>
<td>string</td>
<td>字符系列。可以指定字符集。可以使用单引号或者双引号。</td>
<td>‘now is the time’ “for all good men”</td>
</tr>
<tr>
<td>TIMESTAMP</td>
<td></td>
<td>时间类型</td>
<td></td>
</tr>
<tr>
<td>BINARY</td>
<td></td>
<td>字节数组</td>
<td></td>
</tr>
</tbody></table>
<p>对于Hive的String类型相当于数据库的varchar类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储2GB的字符数。</p>
<h2 id="集合数据类型"><a href="#集合数据类型" class="headerlink" title="集合数据类型"></a>集合数据类型</h2><p>表6-2</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>描述</th>
<th>语法示例</th>
</tr>
</thead>
<tbody><tr>
<td>STRUCT</td>
<td>和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。</td>
<td>struct()</td>
</tr>
<tr>
<td>MAP</td>
<td>MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td>
<td>map()</td>
</tr>
<tr>
<td>ARRAY</td>
<td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。</td>
<td>Array()</td>
</tr>
</tbody></table>
<p>Hive有三种复杂数据类型ARRAY、MAP 和 STRUCT。ARRAY和MAP与Java中的Array和Map类似，而STRUCT与C语言中的Struct类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。</p>
<p>案例实操</p>
<p>1） 假设某表有如下一行，我们用JSON格式来表示其数据结构。在Hive下访问的格式为</p>
<blockquote>
<p>{  “name”: “songsong”,  “friends”: [“bingbing” , “lili”] ,    </p>
<p>//列表Array,   “children”: {            </p>
<p>//键值Map,    “xiao song”: 18 ,    “xiaoxiao song”: 19 </p>
<p>}  “address”: {            </p>
<p>//结构Struct,   </p>
<p>“street”: “hui long guan” ,    “city”: “beijing”   }}</p>
</blockquote>
<p>2）基于上述数据结构，我们在Hive里创建对应的表，并导入数据。 </p>
<p>创建本地测试文件test.txt</p>
<blockquote>
<p>songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijingyangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing</p>
</blockquote>
<p>注意：MAP，STRUCT和ARRAY里的元素间关系都可以用同一个字符表示，这里用“_”。</p>
<p>3）Hive上创建测试表test</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table test(name string,friends array&lt;string&gt;,children map&lt;string, int&gt;,address struct&lt;street:string, city:string&gt;)row format delimited fields terminated by &#39;,&#39;collection items terminated by &#39;_&#39;map keys terminated by &#39;:&#39;lines terminated by &#39;\n&#39;;</span><br></pre></td></tr></table></figure>

<p>字段解释：</p>
<p>row format delimited fields terminated by ‘,’  – 列分隔符</p>
<p>collection items terminated by ‘_’  –MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)</p>
<p>map keys terminated by ‘:’                – MAP中的key与value的分隔符</p>
<p>lines terminated by ‘\n’;                    – 行分隔符</p>
<p>4）导入文本数据到测试表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath ‘&#x2F;opt&#x2F;module&#x2F;datas&#x2F;test.txt’into table test</span><br></pre></td></tr></table></figure>

<p>5）访问三种集合列里的数据，以下分别是ARRAY，MAP，STRUCT的访问方式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select friends[1],children[&#39;xiao song&#39;],address.city from testwhere name&#x3D;&quot;songsong&quot;;</span><br><span class="line">OK_c0   _c1   citylili   18    beijingTime taken: 0.076 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>



<h2 id="类型转化"><a href="#类型转化" class="headerlink" title="类型转化"></a>类型转化</h2><p>Hive的原子数据类型是可以进行隐式转换的，类似于Java的类型转换，例如某表达式使用INT类型，TINYINT会自动转换为INT类型，但是Hive不会进行反向转化，例如，某表达式使用TINYINT类型，INT不会自动转换为TINYINT类型，它会返回错误，除非使用CAST操作。</p>
<p>1．隐式类型转换规则如下</p>
<p>（1）任何整数类型都可以隐式地转换为一个范围更广的类型，如TINYINT可以转换成INT，INT可以转换成BIGINT。</p>
<p>（2）所有整数类型、FLOAT和STRING类型都可以隐式地转换成DOUBLE。</p>
<p>（3）TINYINT、SMALLINT、INT都可以转换为FLOAT。</p>
<p>（4）BOOLEAN类型不可以转换为任何其它的类型。</p>
<p>2．可以使用CAST操作显示进行数据类型转换</p>
<p>例如CAST(‘1’ AS INT)将把字符串’1’ 转换成整数1；如果强制类型转换失败，如执行CAST(‘X’ AS INT)，表达式返回空值 NULL。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Snow Monster</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.red0819.top/2018/12/22/Hive%E5%85%A5%E9%97%A8/">http://www.red0819.top/2018/12/22/Hive%E5%85%A5%E9%97%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.red0819.top" target="_blank">RedLeavesBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hive/">Hive</a></div><div class="post_share"><div class="social-share" data-image="/wordPic/Hive-logo.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/02/05/Redis%E5%9F%BA%E7%A1%80/"><img class="prev-cover" src="/wordPic/redis-logo.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Redis基础</div></div></a></div><div class="next-post pull-right"><a href="/2017/09/03/testfile/"><img class="next-cover" src="/wordPic/timg.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">testfile</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer" style="background-image: url(/wordPic/Hive-logo.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2020 By Snow Monster</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener">Butterfly</a></div><div class="footer_custom_text">努力充实自己大脑中，欢迎投喂知识！</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: 'BlwHhRwsSAJShGHGJeX8d6qB-gzGzoHsz',
      appKey: 'fGlkNKWjBKmGkMSND7jvpsRI',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script></div></body></html>